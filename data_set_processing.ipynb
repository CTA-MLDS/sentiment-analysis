{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CTA-MLDS/sentiment-analysis/blob/01062024/data_set_processing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nkZLAbNbUInd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "31668729-4f14-43ed-802d-a2a448168337"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.36.2)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (2.16.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.0)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (10.0.1)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets) (0.6)\n",
            "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.7)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (1.5.3)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.4.1)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.15)\n",
            "Requirement already satisfied: fsspec[http]<=2023.10.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.9.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.2.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.4)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.11.17)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.3.post1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "! pip install transformers datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TFBeR-taUIng",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fa8181f9-146c-4a3c-cae5-a7f34647e34b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: fugashi in /usr/local/lib/python3.10/dist-packages (1.3.0)\n",
            "Requirement already satisfied: ipadic in /usr/local/lib/python3.10/dist-packages (1.0.0)\n"
          ]
        }
      ],
      "source": [
        "! pip install fugashi ipadic"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6qA72unnUInh"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7KtLWdhuUInh"
      },
      "outputs": [],
      "source": [
        "# Hugging Face (Transformers) 関連のモジュール\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "from transformers import TrainingArguments, Trainer\n",
        "from datasets import Dataset, load_metric"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0A7oeix9UIni",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "053bac5f-cb41-4d65-d909-9d9c5de388fb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "fonts-ipafont-gothic is already the newest version (00303-21ubuntu1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 24 not upgraded.\n",
            "rm: cannot remove '/root/.cache/matplotlib/fontlist-v310.json': No such file or directory\n"
          ]
        }
      ],
      "source": [
        "# [前準備] Matplotlib で日本語フォントを使用できるようにする\n",
        "# cf. https://blog.3qe.us/entry/2018/08/16/121457\n",
        "!apt-get -y install fonts-ipafont-gothic\n",
        "!rm /root/.cache/matplotlib/fontlist-v310.json\n",
        "# jupyter notebookで動くように書き換え↓\n",
        "# ! pip install matplotlib\n",
        "# ! pip install japanize-matplotlib\n",
        "\n",
        "# NOTE ここで、ランタイムを再起動"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z2SSxznCVFQ5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fa5006b2-4cb3-4a80-bcc8-26a55e47b20e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "fonts-ipafont-gothic is already the newest version (00303-21ubuntu1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 24 not upgraded.\n",
            "/usr/share/fonts: caching, new cache contents: 0 fonts, 2 dirs\n",
            "/usr/share/fonts/opentype: caching, new cache contents: 0 fonts, 2 dirs\n",
            "/usr/share/fonts/opentype/ipafont-gothic: caching, new cache contents: 2 fonts, 0 dirs\n",
            "/usr/share/fonts/opentype/ipafont-mincho: caching, new cache contents: 2 fonts, 0 dirs\n",
            "/usr/share/fonts/truetype: caching, new cache contents: 2 fonts, 2 dirs\n",
            "/usr/share/fonts/truetype/humor-sans: caching, new cache contents: 1 fonts, 0 dirs\n",
            "/usr/share/fonts/truetype/liberation: caching, new cache contents: 16 fonts, 0 dirs\n",
            "/usr/local/share/fonts: caching, new cache contents: 0 fonts, 0 dirs\n",
            "/root/.local/share/fonts: skipping, no such directory\n",
            "/root/.fonts: skipping, no such directory\n",
            "/usr/share/fonts/opentype: skipping, looped directory detected\n",
            "/usr/share/fonts/truetype: skipping, looped directory detected\n",
            "/usr/share/fonts/opentype/ipafont-gothic: skipping, looped directory detected\n",
            "/usr/share/fonts/opentype/ipafont-mincho: skipping, looped directory detected\n",
            "/usr/share/fonts/truetype/humor-sans: skipping, looped directory detected\n",
            "/usr/share/fonts/truetype/liberation: skipping, looped directory detected\n",
            "/var/cache/fontconfig: cleaning cache directory\n",
            "/root/.cache/fontconfig: not cleaning non-existent cache directory\n",
            "/root/.fontconfig: not cleaning non-existent cache directory\n",
            "fc-cache: succeeded\n",
            "rm: cannot remove '/root/.cache/matplotlib/fontlist-v310.json': No such file or directory\n"
          ]
        }
      ],
      "source": [
        "!sudo apt-get install fonts-ipafont-gothic\n",
        "!sudo fc-cache -fv\n",
        "!rm /root/.cache/matplotlib/fontlist-v310.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Eze6XSk0VOqd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c6ba4927-9cb7-43e6-d854-534affc1657d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: japanize-matplotlib in /usr/local/lib/python3.10/dist-packages (1.1.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from japanize-matplotlib) (3.7.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->japanize-matplotlib) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->japanize-matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->japanize-matplotlib) (4.47.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->japanize-matplotlib) (1.4.5)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from matplotlib->japanize-matplotlib) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->japanize-matplotlib) (23.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->japanize-matplotlib) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->japanize-matplotlib) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->japanize-matplotlib) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->japanize-matplotlib) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "! pip install japanize-matplotlib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wC4a9tDxUInj"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import japanize_matplotlib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "egwBaEh6UInj"
      },
      "outputs": [],
      "source": [
        "# if 'IPAGothic' not in plt.rcParams['font.family']:\n",
        "#     plt.rcParams['font.family'] = 'MS Gothic'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 158
        },
        "id": "nR0VWE4RUInj",
        "outputId": "710ac5e7-debf-4fdc-e624-60088ffe2948"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 500x100 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# 動作確認\n",
        "plt.figure(figsize=(5, 1))\n",
        "plt.title('日本語表示、テスト')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JyEZkLerUInj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c2bce9c5-a57e-4e69-bb32-b088c64b6a12"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-01-16 10:26:12--  https://github.com/ids-cv/wrime/raw/master/wrime-ver1.tsv\n",
            "Resolving github.com (github.com)... 20.27.177.113\n",
            "Connecting to github.com (github.com)|20.27.177.113|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/ids-cv/wrime/master/wrime-ver1.tsv [following]\n",
            "--2024-01-16 10:26:13--  https://raw.githubusercontent.com/ids-cv/wrime/master/wrime-ver1.tsv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 9487235 (9.0M) [text/plain]\n",
            "Saving to: ‘wrime-ver1.tsv.1’\n",
            "\n",
            "wrime-ver1.tsv.1    100%[===================>]   9.05M  30.6MB/s    in 0.3s    \n",
            "\n",
            "2024-01-16 10:26:13 (30.6 MB/s) - ‘wrime-ver1.tsv.1’ saved [9487235/9487235]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# GitHubよりWRIMEデータをダウンロードする\n",
        "#\n",
        "# WRIME dataset : https://github.com/ids-cv/wrime\n",
        "# 今回使用するのは ver1 （感情極性が付与されていない版）\n",
        "\n",
        "! wget https://github.com/ids-cv/wrime/raw/master/wrime-ver1.tsv\n",
        "\n",
        "# question to ask\n",
        "# tried to run the command through this cell, didn't work.\n",
        "# installed wget, but couldn't execute the file\n",
        "# manually moved the file to the system32 file of windows and ran the program through cmd (and worked??)\n",
        "\n",
        "# fugashiがインストールできない\n",
        "# -> mecab.hが認識されない -> 通常はincludeサブディレクトリにあるはずだが、代わりにsrcに入っている（そしてincludeは存在していない）\n",
        "# -> mecabを再度インストール -> mecabのバージョンをチェックしたいmecab --versionが、エラー（'mecab' is not recognized as an internal or external command,\n",
        "# operable program or batch file.）-> 環境変数にpathを追加 -> INCLUDE変数も追加 -> やっぱりmecab.hが認識されない\n",
        "# mecabのビルド済みバイナリをインストール　pip install mecab-python-binary　pip install mecab-python3　pip install mecab-python3 --global-option=\"--with-cflags=-IC:\\Users\\minaa\\OneDrive\\TCA\\mecab\\mecab\\mecab\\src\"\n",
        "# fugashiを諦めます\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zTVQyzpXUInk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 491
        },
        "outputId": "c7967594-927a-4fa9-f8b7-62e93338667f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                            Sentence  UserID  \\\n",
              "0                     ぼけっとしてたらこんな時間｡チャリあるから食べにでたいのに…       1   \n",
              "1  今日の月も白くて明るい。昨日より雲が少なくてキレイな? と立ち止まる帰り道｡チャリなし生活も...       1   \n",
              "\n",
              "           Datetime Train/Dev/Test  Writer_Joy  Writer_Sadness  \\\n",
              "0  2012/07/31 23:48          train           0               1   \n",
              "1  2012/08/02 23:09          train           3               0   \n",
              "\n",
              "   Writer_Anticipation  Writer_Surprise  Writer_Anger  Writer_Fear  ...  \\\n",
              "0                    2                1             1            0  ...   \n",
              "1                    3                0             0            0  ...   \n",
              "\n",
              "   Reader3_Disgust  Reader3_Trust  Avg. Readers_Joy  Avg. Readers_Sadness  \\\n",
              "0                1              0                 0                     2   \n",
              "1                0              1                 1                     0   \n",
              "\n",
              "   Avg. Readers_Anticipation  Avg. Readers_Surprise  Avg. Readers_Anger  \\\n",
              "0                          0                      0                   0   \n",
              "1                          0                      2                   0   \n",
              "\n",
              "   Avg. Readers_Fear  Avg. Readers_Disgust  Avg. Readers_Trust  \n",
              "0                  0                     0                   0  \n",
              "1                  0                     0                   0  \n",
              "\n",
              "[2 rows x 44 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a7d1612c-7bb6-491d-9df4-9b8ddc0f3c06\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sentence</th>\n",
              "      <th>UserID</th>\n",
              "      <th>Datetime</th>\n",
              "      <th>Train/Dev/Test</th>\n",
              "      <th>Writer_Joy</th>\n",
              "      <th>Writer_Sadness</th>\n",
              "      <th>Writer_Anticipation</th>\n",
              "      <th>Writer_Surprise</th>\n",
              "      <th>Writer_Anger</th>\n",
              "      <th>Writer_Fear</th>\n",
              "      <th>...</th>\n",
              "      <th>Reader3_Disgust</th>\n",
              "      <th>Reader3_Trust</th>\n",
              "      <th>Avg. Readers_Joy</th>\n",
              "      <th>Avg. Readers_Sadness</th>\n",
              "      <th>Avg. Readers_Anticipation</th>\n",
              "      <th>Avg. Readers_Surprise</th>\n",
              "      <th>Avg. Readers_Anger</th>\n",
              "      <th>Avg. Readers_Fear</th>\n",
              "      <th>Avg. Readers_Disgust</th>\n",
              "      <th>Avg. Readers_Trust</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ぼけっとしてたらこんな時間｡チャリあるから食べにでたいのに…</td>\n",
              "      <td>1</td>\n",
              "      <td>2012/07/31 23:48</td>\n",
              "      <td>train</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>今日の月も白くて明るい。昨日より雲が少なくてキレイな? と立ち止まる帰り道｡チャリなし生活も...</td>\n",
              "      <td>1</td>\n",
              "      <td>2012/08/02 23:09</td>\n",
              "      <td>train</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2 rows × 44 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a7d1612c-7bb6-491d-9df4-9b8ddc0f3c06')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-a7d1612c-7bb6-491d-9df4-9b8ddc0f3c06 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-a7d1612c-7bb6-491d-9df4-9b8ddc0f3c06');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-8d9c6c49-a609-46fa-8820-af49c872ff95\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-8d9c6c49-a609-46fa-8820-af49c872ff95')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-8d9c6c49-a609-46fa-8820-af49c872ff95 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "# pandas.DataFrameとして読み込む\n",
        "df_wrime = pd.read_table('wrime-ver1.tsv')\n",
        "df_wrime.head(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TsdByOjQUInk"
      },
      "outputs": [],
      "source": [
        "emotion_names = ['Joy', 'Sadness', 'Anticipation', 'Surprise', 'Anger', 'Fear', 'Disgust', 'Trust']\n",
        "emotion_names_jp = ['喜び', '悲しみ', '期待', '驚き', '怒り', '恐れ', '嫌悪', '信頼']\n",
        "num_labels = len(emotion_names)\n",
        "\n",
        "# objective emotion average (Avg. Readers_*) values are converted to list, defined as a new column\n",
        "df_wrime['readers_emotion_intensities'] = df_wrime.apply(lambda x: [x['Avg. Readers_' + name] for name in emotion_names], axis=1)\n",
        "\n",
        "# removing samples with less emotion intensities\n",
        "# (max.readers_emotion_intensities must be 2 or more)\n",
        "is_target = df_wrime['readers_emotion_intensities'].map(lambda x: max(x) >= 2)\n",
        "df_wrime_target = df_wrime[is_target]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dApwmsSfUInk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "97b82cc2-ca16-4d84-c453-99f0a23922ac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train : 17104\n",
            "test : 1133\n"
          ]
        }
      ],
      "source": [
        "# divide into train and test data\n",
        "df_groups = df_wrime_target.groupby('Train/Dev/Test')\n",
        "df_train = df_groups.get_group('train')\n",
        "df_test = pd.concat([df_groups.get_group('dev'), df_groups.get_group('test')])\n",
        "print('train :', len(df_train))\n",
        "print('test :', len(df_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 113,
          "referenced_widgets": [
            "2f1cf2602d364c589a5caaba4e7ceabc",
            "078ddc51740642c8ac3aa3fec6c6c28b",
            "ab313015283b418591334e7f77c32197",
            "e9243ca6650f4d329726cc8ef4642ac3",
            "14fa6c4abc2d4831a8c4e548df8abdf3",
            "29a2413c26aa4b3f8aba3e0e3d606ccf",
            "2cff2bdb5964410cb27c9b99df2ad2b6",
            "57989b5b3875477cb451022d2a15e86b",
            "869c7bb8ece8402c8a9aa3fd5665a126",
            "419b4f3c2af84ec08c318aa1d004f111",
            "a7e3f9f99ce5443c8b6fce8d29f15f50",
            "b7163fd1ec064514a41e73271e95f2c3",
            "d5cd1ad861a046a1a21d8f7c1e0d3b86",
            "8dc3b614f2464b2396a80cb85bb33d8d",
            "088a64c937ce438b90a62e88090fd076",
            "993b95e957494025b8c587465e36f6f5",
            "6d26a5b5a8e7478695938aac0bf402d9",
            "1700eb6fd1b244ab83c25784e396d379",
            "92fccf5f0f5f437fbcc4eaae75439522",
            "5a6db2452a234b029f7ecae081c82cb2",
            "6fdafa3be86f4e8b8ab6e58a8300f475",
            "4429df1353fd4683952b556e9c8d382b",
            "9323815bfa1a46148a912a36aab888b7",
            "9517af60ee1b44e1afaedc55afb2c595",
            "1a9f4ed51cd2428a8c3e1dbbfa609f30",
            "3155ca48b4124f5d90ae5ba267b12f6a",
            "b642a838d7d94eef880f39b04b8e41f2",
            "82299dbecd9f4827a70a543c83434c1a",
            "c1380b8849e94a0fb13da04ba3bcb7b9",
            "d27405f9034848e08c05b04bfc645bd8",
            "b51bbe79692a40d6b872d7775135a6cf",
            "6095a367327f44d589237002a69cfff6",
            "4f31f81de662467688183452fbf3edf0"
          ]
        },
        "id": "ZLTE0nvlWyTz",
        "outputId": "c9078018-3df5-482b-ad64-6ddbfa0941af"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/104 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2f1cf2602d364c589a5caaba4e7ceabc"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/479 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b7163fd1ec064514a41e73271e95f2c3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/258k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9323815bfa1a46148a912a36aab888b7"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "# 使用するモデルを指定して、Tokenizerを読み込む\n",
        "checkpoint = 'cl-tohoku/bert-base-japanese-whole-word-masking'\n",
        "tokenizer = AutoTokenizer.from_pretrained(checkpoint)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#  (1) 使用するモデルをより簡素なものに\n",
        "# checkpoint = 'distilbert-base-japanese'\n",
        "# tokenizer = AutoTokenizer.from_pretrained(checkpoint)"
      ],
      "metadata": {
        "id": "sAQbFmQyRNNX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# (2) モデルの一部の層を削減して軽量化\n",
        "from transformers import AutoModel, AutoConfig\n",
        "config = AutoConfig.from_pretrained(checkpoint, num_hidden_layers=6)  # 6層に変更\n",
        "model = AutoModel.from_pretrained(checkpoint, config=config)"
      ],
      "metadata": {
        "id": "9fV0ZxsqRbpa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "b0266dc4225d4c66ae443c4a11fbb84a",
            "de28f93a33514063ab2cb45df37db756",
            "fd478a042d49468b9baa3b6b02bb819f",
            "83d0cf064daa4d089bef73da304d9425",
            "710f48f6896843629cef73af8571a5b1",
            "1db03a67b12d47ae97a4fb0135666973",
            "4039757d01284537914c2420989843c3",
            "15c3974dee14439eab1e27ae8d71ab29",
            "5126ed76df9f4cdf9ffc2562b5892cc1",
            "d2f008731ea54770bd8597dad2506c21",
            "397ba97f88ce478ca526614c3de5d482"
          ]
        },
        "outputId": "8273b887-262b-453e-ea1a-58025149dd04"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "pytorch_model.bin:   0%|          | 0.00/445M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b0266dc4225d4c66ae443c4a11fbb84a"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# (3) モデルのEmbedding層の次元を削減\n",
        "# config = AutoConfig.from_pretrained(checkpoint, hidden_size=252)\n",
        "# model = AutoModel.from_pretrained(checkpoint, config=config, ignore_mismatched_sizes=True)\n"
      ],
      "metadata": {
        "id": "_4OG0RtkRfn_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f805eff0-3173-463f-d02d-d0b27e2c653c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertModel were not initialized from the model checkpoint at cl-tohoku/bert-base-japanese-whole-word-masking and are newly initialized because the shapes did not match:\n",
            "- bert.embeddings.word_embeddings.weight: found shape torch.Size([32000, 768]) in the checkpoint and torch.Size([32000, 252]) in the model instantiated\n",
            "- bert.embeddings.position_embeddings.weight: found shape torch.Size([512, 768]) in the checkpoint and torch.Size([512, 252]) in the model instantiated\n",
            "- bert.embeddings.token_type_embeddings.weight: found shape torch.Size([2, 768]) in the checkpoint and torch.Size([2, 252]) in the model instantiated\n",
            "- bert.embeddings.LayerNorm.weight: found shape torch.Size([768]) in the checkpoint and torch.Size([252]) in the model instantiated\n",
            "- bert.embeddings.LayerNorm.bias: found shape torch.Size([768]) in the checkpoint and torch.Size([252]) in the model instantiated\n",
            "- bert.encoder.layer.0.attention.self.query.weight: found shape torch.Size([768, 768]) in the checkpoint and torch.Size([252, 252]) in the model instantiated\n",
            "- bert.encoder.layer.0.attention.self.query.bias: found shape torch.Size([768]) in the checkpoint and torch.Size([252]) in the model instantiated\n",
            "- bert.encoder.layer.0.attention.self.key.weight: found shape torch.Size([768, 768]) in the checkpoint and torch.Size([252, 252]) in the model instantiated\n",
            "- bert.encoder.layer.0.attention.self.key.bias: found shape torch.Size([768]) in the checkpoint and torch.Size([252]) in the model instantiated\n",
            "- bert.encoder.layer.0.attention.self.value.weight: found shape torch.Size([768, 768]) in the checkpoint and torch.Size([252, 252]) in the model instantiated\n",
            "- bert.encoder.layer.0.attention.self.value.bias: found shape torch.Size([768]) in the checkpoint and torch.Size([252]) in the model instantiated\n",
            "- bert.encoder.layer.0.attention.output.dense.weight: found shape torch.Size([768, 768]) in the checkpoint and torch.Size([252, 252]) in the model instantiated\n",
            "- bert.encoder.layer.0.attention.output.dense.bias: found shape torch.Size([768]) in the checkpoint and torch.Size([252]) in the model instantiated\n",
            "- bert.encoder.layer.0.attention.output.LayerNorm.weight: found shape torch.Size([768]) in the checkpoint and torch.Size([252]) in the model instantiated\n",
            "- bert.encoder.layer.0.attention.output.LayerNorm.bias: found shape torch.Size([768]) in the checkpoint and torch.Size([252]) in the model instantiated\n",
            "- bert.encoder.layer.0.intermediate.dense.weight: found shape torch.Size([3072, 768]) in the checkpoint and torch.Size([3072, 252]) in the model instantiated\n",
            "- bert.encoder.layer.0.output.dense.weight: found shape torch.Size([768, 3072]) in the checkpoint and torch.Size([252, 3072]) in the model instantiated\n",
            "- bert.encoder.layer.0.output.dense.bias: found shape torch.Size([768]) in the checkpoint and torch.Size([252]) in the model instantiated\n",
            "- bert.encoder.layer.0.output.LayerNorm.weight: found shape torch.Size([768]) in the checkpoint and torch.Size([252]) in the model instantiated\n",
            "- bert.encoder.layer.0.output.LayerNorm.bias: found shape torch.Size([768]) in the checkpoint and torch.Size([252]) in the model instantiated\n",
            "- bert.encoder.layer.1.attention.self.query.weight: found shape torch.Size([768, 768]) in the checkpoint and torch.Size([252, 252]) in the model instantiated\n",
            "- bert.encoder.layer.1.attention.self.query.bias: found shape torch.Size([768]) in the checkpoint and torch.Size([252]) in the model instantiated\n",
            "- bert.encoder.layer.1.attention.self.key.weight: found shape torch.Size([768, 768]) in the checkpoint and torch.Size([252, 252]) in the model instantiated\n",
            "- bert.encoder.layer.1.attention.self.key.bias: found shape torch.Size([768]) in the checkpoint and torch.Size([252]) in the model instantiated\n",
            "- bert.encoder.layer.1.attention.self.value.weight: found shape torch.Size([768, 768]) in the checkpoint and torch.Size([252, 252]) in the model instantiated\n",
            "- bert.encoder.layer.1.attention.self.value.bias: found shape torch.Size([768]) in the checkpoint and torch.Size([252]) in the model instantiated\n",
            "- bert.encoder.layer.1.attention.output.dense.weight: found shape torch.Size([768, 768]) in the checkpoint and torch.Size([252, 252]) in the model instantiated\n",
            "- bert.encoder.layer.1.attention.output.dense.bias: found shape torch.Size([768]) in the checkpoint and torch.Size([252]) in the model instantiated\n",
            "- bert.encoder.layer.1.attention.output.LayerNorm.weight: found shape torch.Size([768]) in the checkpoint and torch.Size([252]) in the model instantiated\n",
            "- bert.encoder.layer.1.attention.output.LayerNorm.bias: found shape torch.Size([768]) in the checkpoint and torch.Size([252]) in the model instantiated\n",
            "- bert.encoder.layer.1.intermediate.dense.weight: found shape torch.Size([3072, 768]) in the checkpoint and torch.Size([3072, 252]) in the model instantiated\n",
            "- bert.encoder.layer.1.output.dense.weight: found shape torch.Size([768, 3072]) in the checkpoint and torch.Size([252, 3072]) in the model instantiated\n",
            "- bert.encoder.layer.1.output.dense.bias: found shape torch.Size([768]) in the checkpoint and torch.Size([252]) in the model instantiated\n",
            "- bert.encoder.layer.1.output.LayerNorm.weight: found shape torch.Size([768]) in the checkpoint and torch.Size([252]) in the model instantiated\n",
            "- bert.encoder.layer.1.output.LayerNorm.bias: found shape torch.Size([768]) in the checkpoint and torch.Size([252]) in the model instantiated\n",
            "- bert.encoder.layer.2.attention.self.query.weight: found shape torch.Size([768, 768]) in the checkpoint and torch.Size([252, 252]) in the model instantiated\n",
            "- bert.encoder.layer.2.attention.self.query.bias: found shape torch.Size([768]) in the checkpoint and torch.Size([252]) in the model instantiated\n",
            "- bert.encoder.layer.2.attention.self.key.weight: found shape torch.Size([768, 768]) in the checkpoint and torch.Size([252, 252]) in the model instantiated\n",
            "- bert.encoder.layer.2.attention.self.key.bias: found shape torch.Size([768]) in the checkpoint and torch.Size([252]) in the model instantiated\n",
            "- bert.encoder.layer.2.attention.self.value.weight: found shape torch.Size([768, 768]) in the checkpoint and torch.Size([252, 252]) in the model instantiated\n",
            "- bert.encoder.layer.2.attention.self.value.bias: found shape torch.Size([768]) in the checkpoint and torch.Size([252]) in the model instantiated\n",
            "- bert.encoder.layer.2.attention.output.dense.weight: found shape torch.Size([768, 768]) in the checkpoint and torch.Size([252, 252]) in the model instantiated\n",
            "- bert.encoder.layer.2.attention.output.dense.bias: found shape torch.Size([768]) in the checkpoint and torch.Size([252]) in the model instantiated\n",
            "- bert.encoder.layer.2.attention.output.LayerNorm.weight: found shape torch.Size([768]) in the checkpoint and torch.Size([252]) in the model instantiated\n",
            "- bert.encoder.layer.2.attention.output.LayerNorm.bias: found shape torch.Size([768]) in the checkpoint and torch.Size([252]) in the model instantiated\n",
            "- bert.encoder.layer.2.intermediate.dense.weight: found shape torch.Size([3072, 768]) in the checkpoint and torch.Size([3072, 252]) in the model instantiated\n",
            "- bert.encoder.layer.2.output.dense.weight: found shape torch.Size([768, 3072]) in the checkpoint and torch.Size([252, 3072]) in the model instantiated\n",
            "- bert.encoder.layer.2.output.dense.bias: found shape torch.Size([768]) in the checkpoint and torch.Size([252]) in the model instantiated\n",
            "- bert.encoder.layer.2.output.LayerNorm.weight: found shape torch.Size([768]) in the checkpoint and torch.Size([252]) in the model instantiated\n",
            "- bert.encoder.layer.2.output.LayerNorm.bias: found shape torch.Size([768]) in the checkpoint and torch.Size([252]) in the model instantiated\n",
            "- bert.encoder.layer.3.attention.self.query.weight: found shape torch.Size([768, 768]) in the checkpoint and torch.Size([252, 252]) in the model instantiated\n",
            "- bert.encoder.layer.3.attention.self.query.bias: found shape torch.Size([768]) in the checkpoint and torch.Size([252]) in the model instantiated\n",
            "- bert.encoder.layer.3.attention.self.key.weight: found shape torch.Size([768, 768]) in the checkpoint and torch.Size([252, 252]) in the model instantiated\n",
            "- bert.encoder.layer.3.attention.self.key.bias: found shape torch.Size([768]) in the checkpoint and torch.Size([252]) in the model instantiated\n",
            "- bert.encoder.layer.3.attention.self.value.weight: found shape torch.Size([768, 768]) in the checkpoint and torch.Size([252, 252]) in the model instantiated\n",
            "- bert.encoder.layer.3.attention.self.value.bias: found shape torch.Size([768]) in the checkpoint and torch.Size([252]) in the model instantiated\n",
            "- bert.encoder.layer.3.attention.output.dense.weight: found shape torch.Size([768, 768]) in the checkpoint and torch.Size([252, 252]) in the model instantiated\n",
            "- bert.encoder.layer.3.attention.output.dense.bias: found shape torch.Size([768]) in the checkpoint and torch.Size([252]) in the model instantiated\n",
            "- bert.encoder.layer.3.attention.output.LayerNorm.weight: found shape torch.Size([768]) in the checkpoint and torch.Size([252]) in the model instantiated\n",
            "- bert.encoder.layer.3.attention.output.LayerNorm.bias: found shape torch.Size([768]) in the checkpoint and torch.Size([252]) in the model instantiated\n",
            "- bert.encoder.layer.3.intermediate.dense.weight: found shape torch.Size([3072, 768]) in the checkpoint and torch.Size([3072, 252]) in the model instantiated\n",
            "- bert.encoder.layer.3.output.dense.weight: found shape torch.Size([768, 3072]) in the checkpoint and torch.Size([252, 3072]) in the model instantiated\n",
            "- bert.encoder.layer.3.output.dense.bias: found shape torch.Size([768]) in the checkpoint and torch.Size([252]) in the model instantiated\n",
            "- bert.encoder.layer.3.output.LayerNorm.weight: found shape torch.Size([768]) in the checkpoint and torch.Size([252]) in the model instantiated\n",
            "- bert.encoder.layer.3.output.LayerNorm.bias: found shape torch.Size([768]) in the checkpoint and torch.Size([252]) in the model instantiated\n",
            "- bert.encoder.layer.4.attention.self.query.weight: found shape torch.Size([768, 768]) in the checkpoint and torch.Size([252, 252]) in the model instantiated\n",
            "- bert.encoder.layer.4.attention.self.query.bias: found shape torch.Size([768]) in the checkpoint and torch.Size([252]) in the model instantiated\n",
            "- bert.encoder.layer.4.attention.self.key.weight: found shape torch.Size([768, 768]) in the checkpoint and torch.Size([252, 252]) in the model instantiated\n",
            "- bert.encoder.layer.4.attention.self.key.bias: found shape torch.Size([768]) in the checkpoint and torch.Size([252]) in the model instantiated\n",
            "- bert.encoder.layer.4.attention.self.value.weight: found shape torch.Size([768, 768]) in the checkpoint and torch.Size([252, 252]) in the model instantiated\n",
            "- bert.encoder.layer.4.attention.self.value.bias: found shape torch.Size([768]) in the checkpoint and torch.Size([252]) in the model instantiated\n",
            "- bert.encoder.layer.4.attention.output.dense.weight: found shape torch.Size([768, 768]) in the checkpoint and torch.Size([252, 252]) in the model instantiated\n",
            "- bert.encoder.layer.4.attention.output.dense.bias: found shape torch.Size([768]) in the checkpoint and torch.Size([252]) in the model instantiated\n",
            "- bert.encoder.layer.4.attention.output.LayerNorm.weight: found shape torch.Size([768]) in the checkpoint and torch.Size([252]) in the model instantiated\n",
            "- bert.encoder.layer.4.attention.output.LayerNorm.bias: found shape torch.Size([768]) in the checkpoint and torch.Size([252]) in the model instantiated\n",
            "- bert.encoder.layer.4.intermediate.dense.weight: found shape torch.Size([3072, 768]) in the checkpoint and torch.Size([3072, 252]) in the model instantiated\n",
            "- bert.encoder.layer.4.output.dense.weight: found shape torch.Size([768, 3072]) in the checkpoint and torch.Size([252, 3072]) in the model instantiated\n",
            "- bert.encoder.layer.4.output.dense.bias: found shape torch.Size([768]) in the checkpoint and torch.Size([252]) in the model instantiated\n",
            "- bert.encoder.layer.4.output.LayerNorm.weight: found shape torch.Size([768]) in the checkpoint and torch.Size([252]) in the model instantiated\n",
            "- bert.encoder.layer.4.output.LayerNorm.bias: found shape torch.Size([768]) in the checkpoint and torch.Size([252]) in the model instantiated\n",
            "- bert.encoder.layer.5.attention.self.query.weight: found shape torch.Size([768, 768]) in the checkpoint and torch.Size([252, 252]) in the model instantiated\n",
            "- bert.encoder.layer.5.attention.self.query.bias: found shape torch.Size([768]) in the checkpoint and torch.Size([252]) in the model instantiated\n",
            "- bert.encoder.layer.5.attention.self.key.weight: found shape torch.Size([768, 768]) in the checkpoint and torch.Size([252, 252]) in the model instantiated\n",
            "- bert.encoder.layer.5.attention.self.key.bias: found shape torch.Size([768]) in the checkpoint and torch.Size([252]) in the model instantiated\n",
            "- bert.encoder.layer.5.attention.self.value.weight: found shape torch.Size([768, 768]) in the checkpoint and torch.Size([252, 252]) in the model instantiated\n",
            "- bert.encoder.layer.5.attention.self.value.bias: found shape torch.Size([768]) in the checkpoint and torch.Size([252]) in the model instantiated\n",
            "- bert.encoder.layer.5.attention.output.dense.weight: found shape torch.Size([768, 768]) in the checkpoint and torch.Size([252, 252]) in the model instantiated\n",
            "- bert.encoder.layer.5.attention.output.dense.bias: found shape torch.Size([768]) in the checkpoint and torch.Size([252]) in the model instantiated\n",
            "- bert.encoder.layer.5.attention.output.LayerNorm.weight: found shape torch.Size([768]) in the checkpoint and torch.Size([252]) in the model instantiated\n",
            "- bert.encoder.layer.5.attention.output.LayerNorm.bias: found shape torch.Size([768]) in the checkpoint and torch.Size([252]) in the model instantiated\n",
            "- bert.encoder.layer.5.intermediate.dense.weight: found shape torch.Size([3072, 768]) in the checkpoint and torch.Size([3072, 252]) in the model instantiated\n",
            "- bert.encoder.layer.5.output.dense.weight: found shape torch.Size([768, 3072]) in the checkpoint and torch.Size([252, 3072]) in the model instantiated\n",
            "- bert.encoder.layer.5.output.dense.bias: found shape torch.Size([768]) in the checkpoint and torch.Size([252]) in the model instantiated\n",
            "- bert.encoder.layer.5.output.LayerNorm.weight: found shape torch.Size([768]) in the checkpoint and torch.Size([252]) in the model instantiated\n",
            "- bert.encoder.layer.5.output.LayerNorm.bias: found shape torch.Size([768]) in the checkpoint and torch.Size([252]) in the model instantiated\n",
            "- bert.encoder.layer.6.attention.self.query.weight: found shape torch.Size([768, 768]) in the checkpoint and torch.Size([252, 252]) in the model instantiated\n",
            "- bert.encoder.layer.6.attention.self.query.bias: found shape torch.Size([768]) in the checkpoint and torch.Size([252]) in the model instantiated\n",
            "- bert.encoder.layer.6.attention.self.key.weight: found shape torch.Size([768, 768]) in the checkpoint and torch.Size([252, 252]) in the model instantiated\n",
            "- bert.encoder.layer.6.attention.self.key.bias: found shape torch.Size([768]) in the checkpoint and torch.Size([252]) in the model instantiated\n",
            "- bert.encoder.layer.6.attention.self.value.weight: found shape torch.Size([768, 768]) in the checkpoint and torch.Size([252, 252]) in the model instantiated\n",
            "- bert.encoder.layer.6.attention.self.value.bias: found shape torch.Size([768]) in the checkpoint and torch.Size([252]) in the model instantiated\n",
            "- bert.encoder.layer.6.attention.output.dense.weight: found shape torch.Size([768, 768]) in the checkpoint and torch.Size([252, 252]) in the model instantiated\n",
            "- bert.encoder.layer.6.attention.output.dense.bias: found shape torch.Size([768]) in the checkpoint and torch.Size([252]) in the model instantiated\n",
            "- bert.encoder.layer.6.attention.output.LayerNorm.weight: found shape torch.Size([768]) in the checkpoint and torch.Size([252]) in the model instantiated\n",
            "- bert.encoder.layer.6.attention.output.LayerNorm.bias: found shape torch.Size([768]) in the checkpoint and torch.Size([252]) in the model instantiated\n",
            "- bert.encoder.layer.6.intermediate.dense.weight: found shape torch.Size([3072, 768]) in the checkpoint and torch.Size([3072, 252]) in the model instantiated\n",
            "- bert.encoder.layer.6.output.dense.weight: found shape torch.Size([768, 3072]) in the checkpoint and torch.Size([252, 3072]) in the model instantiated\n",
            "- bert.encoder.layer.6.output.dense.bias: found shape torch.Size([768]) in the checkpoint and torch.Size([252]) in the model instantiated\n",
            "- bert.encoder.layer.6.output.LayerNorm.weight: found shape torch.Size([768]) in the checkpoint and torch.Size([252]) in the model instantiated\n",
            "- bert.encoder.layer.6.output.LayerNorm.bias: found shape torch.Size([768]) in the checkpoint and torch.Size([252]) in the model instantiated\n",
            "- bert.encoder.layer.7.attention.self.query.weight: found shape torch.Size([768, 768]) in the checkpoint and torch.Size([252, 252]) in the model instantiated\n",
            "- bert.encoder.layer.7.attention.self.query.bias: found shape torch.Size([768]) in the checkpoint and torch.Size([252]) in the model instantiated\n",
            "- bert.encoder.layer.7.attention.self.key.weight: found shape torch.Size([768, 768]) in the checkpoint and torch.Size([252, 252]) in the model instantiated\n",
            "- bert.encoder.layer.7.attention.self.key.bias: found shape torch.Size([768]) in the checkpoint and torch.Size([252]) in the model instantiated\n",
            "- bert.encoder.layer.7.attention.self.value.weight: found shape torch.Size([768, 768]) in the checkpoint and torch.Size([252, 252]) in the model instantiated\n",
            "- bert.encoder.layer.7.attention.self.value.bias: found shape torch.Size([768]) in the checkpoint and torch.Size([252]) in the model instantiated\n",
            "- bert.encoder.layer.7.attention.output.dense.weight: found shape torch.Size([768, 768]) in the checkpoint and torch.Size([252, 252]) in the model instantiated\n",
            "- bert.encoder.layer.7.attention.output.dense.bias: found shape torch.Size([768]) in the checkpoint and torch.Size([252]) in the model instantiated\n",
            "- bert.encoder.layer.7.attention.output.LayerNorm.weight: found shape torch.Size([768]) in the checkpoint and torch.Size([252]) in the model instantiated\n",
            "- bert.encoder.layer.7.attention.output.LayerNorm.bias: found shape torch.Size([768]) in the checkpoint and torch.Size([252]) in the model instantiated\n",
            "- bert.encoder.layer.7.intermediate.dense.weight: found shape torch.Size([3072, 768]) in the checkpoint and torch.Size([3072, 252]) in the model instantiated\n",
            "- bert.encoder.layer.7.output.dense.weight: found shape torch.Size([768, 3072]) in the checkpoint and torch.Size([252, 3072]) in the model instantiated\n",
            "- bert.encoder.layer.7.output.dense.bias: found shape torch.Size([768]) in the checkpoint and torch.Size([252]) in the model instantiated\n",
            "- bert.encoder.layer.7.output.LayerNorm.weight: found shape torch.Size([768]) in the checkpoint and torch.Size([252]) in the model instantiated\n",
            "- bert.encoder.layer.7.output.LayerNorm.bias: found shape torch.Size([768]) in the checkpoint and torch.Size([252]) in the model instantiated\n",
            "- bert.encoder.layer.8.attention.self.query.weight: found shape torch.Size([768, 768]) in the checkpoint and torch.Size([252, 252]) in the model instantiated\n",
            "- bert.encoder.layer.8.attention.self.query.bias: found shape torch.Size([768]) in the checkpoint and torch.Size([252]) in the model instantiated\n",
            "- bert.encoder.layer.8.attention.self.key.weight: found shape torch.Size([768, 768]) in the checkpoint and torch.Size([252, 252]) in the model instantiated\n",
            "- bert.encoder.layer.8.attention.self.key.bias: found shape torch.Size([768]) in the checkpoint and torch.Size([252]) in the model instantiated\n",
            "- bert.encoder.layer.8.attention.self.value.weight: found shape torch.Size([768, 768]) in the checkpoint and torch.Size([252, 252]) in the model instantiated\n",
            "- bert.encoder.layer.8.attention.self.value.bias: found shape torch.Size([768]) in the checkpoint and torch.Size([252]) in the model instantiated\n",
            "- bert.encoder.layer.8.attention.output.dense.weight: found shape torch.Size([768, 768]) in the checkpoint and torch.Size([252, 252]) in the model instantiated\n",
            "- bert.encoder.layer.8.attention.output.dense.bias: found shape torch.Size([768]) in the checkpoint and torch.Size([252]) in the model instantiated\n",
            "- bert.encoder.layer.8.attention.output.LayerNorm.weight: found shape torch.Size([768]) in the checkpoint and torch.Size([252]) in the model instantiated\n",
            "- bert.encoder.layer.8.attention.output.LayerNorm.bias: found shape torch.Size([768]) in the checkpoint and torch.Size([252]) in the model instantiated\n",
            "- bert.encoder.layer.8.intermediate.dense.weight: found shape torch.Size([3072, 768]) in the checkpoint and torch.Size([3072, 252]) in the model instantiated\n",
            "- bert.encoder.layer.8.output.dense.weight: found shape torch.Size([768, 3072]) in the checkpoint and torch.Size([252, 3072]) in the model instantiated\n",
            "- bert.encoder.layer.8.output.dense.bias: found shape torch.Size([768]) in the checkpoint and torch.Size([252]) in the model instantiated\n",
            "- bert.encoder.layer.8.output.LayerNorm.weight: found shape torch.Size([768]) in the checkpoint and torch.Size([252]) in the model instantiated\n",
            "- bert.encoder.layer.8.output.LayerNorm.bias: found shape torch.Size([768]) in the checkpoint and torch.Size([252]) in the model instantiated\n",
            "- bert.encoder.layer.9.attention.self.query.weight: found shape torch.Size([768, 768]) in the checkpoint and torch.Size([252, 252]) in the model instantiated\n",
            "- bert.encoder.layer.9.attention.self.query.bias: found shape torch.Size([768]) in the checkpoint and torch.Size([252]) in the model instantiated\n",
            "- bert.encoder.layer.9.attention.self.key.weight: found shape torch.Size([768, 768]) in the checkpoint and torch.Size([252, 252]) in the model instantiated\n",
            "- bert.encoder.layer.9.attention.self.key.bias: found shape torch.Size([768]) in the checkpoint and torch.Size([252]) in the model instantiated\n",
            "- bert.encoder.layer.9.attention.self.value.weight: found shape torch.Size([768, 768]) in the checkpoint and torch.Size([252, 252]) in the model instantiated\n",
            "- bert.encoder.layer.9.attention.self.value.bias: found shape torch.Size([768]) in the checkpoint and torch.Size([252]) in the model instantiated\n",
            "- bert.encoder.layer.9.attention.output.dense.weight: found shape torch.Size([768, 768]) in the checkpoint and torch.Size([252, 252]) in the model instantiated\n",
            "- bert.encoder.layer.9.attention.output.dense.bias: found shape torch.Size([768]) in the checkpoint and torch.Size([252]) in the model instantiated\n",
            "- bert.encoder.layer.9.attention.output.LayerNorm.weight: found shape torch.Size([768]) in the checkpoint and torch.Size([252]) in the model instantiated\n",
            "- bert.encoder.layer.9.attention.output.LayerNorm.bias: found shape torch.Size([768]) in the checkpoint and torch.Size([252]) in the model instantiated\n",
            "- bert.encoder.layer.9.intermediate.dense.weight: found shape torch.Size([3072, 768]) in the checkpoint and torch.Size([3072, 252]) in the model instantiated\n",
            "- bert.encoder.layer.9.output.dense.weight: found shape torch.Size([768, 3072]) in the checkpoint and torch.Size([252, 3072]) in the model instantiated\n",
            "- bert.encoder.layer.9.output.dense.bias: found shape torch.Size([768]) in the checkpoint and torch.Size([252]) in the model instantiated\n",
            "- bert.encoder.layer.9.output.LayerNorm.weight: found shape torch.Size([768]) in the checkpoint and torch.Size([252]) in the model instantiated\n",
            "- bert.encoder.layer.9.output.LayerNorm.bias: found shape torch.Size([768]) in the checkpoint and torch.Size([252]) in the model instantiated\n",
            "- bert.encoder.layer.10.attention.self.query.weight: found shape torch.Size([768, 768]) in the checkpoint and torch.Size([252, 252]) in the model instantiated\n",
            "- bert.encoder.layer.10.attention.self.query.bias: found shape torch.Size([768]) in the checkpoint and torch.Size([252]) in the model instantiated\n",
            "- bert.encoder.layer.10.attention.self.key.weight: found shape torch.Size([768, 768]) in the checkpoint and torch.Size([252, 252]) in the model instantiated\n",
            "- bert.encoder.layer.10.attention.self.key.bias: found shape torch.Size([768]) in the checkpoint and torch.Size([252]) in the model instantiated\n",
            "- bert.encoder.layer.10.attention.self.value.weight: found shape torch.Size([768, 768]) in the checkpoint and torch.Size([252, 252]) in the model instantiated\n",
            "- bert.encoder.layer.10.attention.self.value.bias: found shape torch.Size([768]) in the checkpoint and torch.Size([252]) in the model instantiated\n",
            "- bert.encoder.layer.10.attention.output.dense.weight: found shape torch.Size([768, 768]) in the checkpoint and torch.Size([252, 252]) in the model instantiated\n",
            "- bert.encoder.layer.10.attention.output.dense.bias: found shape torch.Size([768]) in the checkpoint and torch.Size([252]) in the model instantiated\n",
            "- bert.encoder.layer.10.attention.output.LayerNorm.weight: found shape torch.Size([768]) in the checkpoint and torch.Size([252]) in the model instantiated\n",
            "- bert.encoder.layer.10.attention.output.LayerNorm.bias: found shape torch.Size([768]) in the checkpoint and torch.Size([252]) in the model instantiated\n",
            "- bert.encoder.layer.10.intermediate.dense.weight: found shape torch.Size([3072, 768]) in the checkpoint and torch.Size([3072, 252]) in the model instantiated\n",
            "- bert.encoder.layer.10.output.dense.weight: found shape torch.Size([768, 3072]) in the checkpoint and torch.Size([252, 3072]) in the model instantiated\n",
            "- bert.encoder.layer.10.output.dense.bias: found shape torch.Size([768]) in the checkpoint and torch.Size([252]) in the model instantiated\n",
            "- bert.encoder.layer.10.output.LayerNorm.weight: found shape torch.Size([768]) in the checkpoint and torch.Size([252]) in the model instantiated\n",
            "- bert.encoder.layer.10.output.LayerNorm.bias: found shape torch.Size([768]) in the checkpoint and torch.Size([252]) in the model instantiated\n",
            "- bert.encoder.layer.11.attention.self.query.weight: found shape torch.Size([768, 768]) in the checkpoint and torch.Size([252, 252]) in the model instantiated\n",
            "- bert.encoder.layer.11.attention.self.query.bias: found shape torch.Size([768]) in the checkpoint and torch.Size([252]) in the model instantiated\n",
            "- bert.encoder.layer.11.attention.self.key.weight: found shape torch.Size([768, 768]) in the checkpoint and torch.Size([252, 252]) in the model instantiated\n",
            "- bert.encoder.layer.11.attention.self.key.bias: found shape torch.Size([768]) in the checkpoint and torch.Size([252]) in the model instantiated\n",
            "- bert.encoder.layer.11.attention.self.value.weight: found shape torch.Size([768, 768]) in the checkpoint and torch.Size([252, 252]) in the model instantiated\n",
            "- bert.encoder.layer.11.attention.self.value.bias: found shape torch.Size([768]) in the checkpoint and torch.Size([252]) in the model instantiated\n",
            "- bert.encoder.layer.11.attention.output.dense.weight: found shape torch.Size([768, 768]) in the checkpoint and torch.Size([252, 252]) in the model instantiated\n",
            "- bert.encoder.layer.11.attention.output.dense.bias: found shape torch.Size([768]) in the checkpoint and torch.Size([252]) in the model instantiated\n",
            "- bert.encoder.layer.11.attention.output.LayerNorm.weight: found shape torch.Size([768]) in the checkpoint and torch.Size([252]) in the model instantiated\n",
            "- bert.encoder.layer.11.attention.output.LayerNorm.bias: found shape torch.Size([768]) in the checkpoint and torch.Size([252]) in the model instantiated\n",
            "- bert.encoder.layer.11.intermediate.dense.weight: found shape torch.Size([3072, 768]) in the checkpoint and torch.Size([3072, 252]) in the model instantiated\n",
            "- bert.encoder.layer.11.output.dense.weight: found shape torch.Size([768, 3072]) in the checkpoint and torch.Size([252, 3072]) in the model instantiated\n",
            "- bert.encoder.layer.11.output.dense.bias: found shape torch.Size([768]) in the checkpoint and torch.Size([252]) in the model instantiated\n",
            "- bert.encoder.layer.11.output.LayerNorm.weight: found shape torch.Size([768]) in the checkpoint and torch.Size([252]) in the model instantiated\n",
            "- bert.encoder.layer.11.output.LayerNorm.bias: found shape torch.Size([768]) in the checkpoint and torch.Size([252]) in the model instantiated\n",
            "- bert.pooler.dense.weight: found shape torch.Size([768, 768]) in the checkpoint and torch.Size([252, 252]) in the model instantiated\n",
            "- bert.pooler.dense.bias: found shape torch.Size([768]) in the checkpoint and torch.Size([252]) in the model instantiated\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "from transformers import AdamW, get_linear_schedule_with_warmup\n",
        "from datasets import load_metric"
      ],
      "metadata": {
        "id": "I9-WD0oC7q_W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81,
          "referenced_widgets": [
            "0b4c2a82c4af4bdc9abb1b1028b4580c",
            "48f149d06f6c41a6b71fdc17f542047e",
            "d63396ea5152425bb61f76bd410f1a33",
            "b902815d261942e7beba585a34587ba7",
            "bd9379892ef1453b816f1e92270750be",
            "a649d61ea6f6407db5010df76dde4dc6",
            "7a3ca3933ff34d5698d98cc80850a763",
            "132e236c94d54fb3bd43147e7d13ff9c",
            "f036c3a646d3459e8391c8782b5d8f33",
            "2686ac9ca90b485495cb7718efbdf00d",
            "b686a8eefcc1458689c655f243d6a0c0",
            "b88f4165ba47456d802ee411a947fa5f",
            "5727168cd7704503a1311588501160d2",
            "05376e07e7dd4033bc4e71186a421584",
            "018174037e50440d949c0c23306fcbc5",
            "e253f8d91ace43978ae647263762f4ef",
            "58e3f336b1254e379d85be2755a425ae",
            "5769c41dcfc34139b148563cc6af60c7",
            "8b4de1e5f1f2479e98e4ed96d5ce7851",
            "7fe3c10be27a47218d9412f9cdc63dbb",
            "a600ba765fc442d2a40d4d12d0519068",
            "de3ba313af3c4b9aaaba1032dccc0001"
          ]
        },
        "id": "rYUy4lfSW348",
        "outputId": "2cd3607a-2ca4-4b45-eaa3-3f4b94c9e2b2"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/17104 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0b4c2a82c4af4bdc9abb1b1028b4580c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/1133 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b88f4165ba47456d802ee411a947fa5f"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "# 前処理関数: tokenize_function\n",
        "# 感情強度の正規化（総和=1）も同時に実施する\n",
        "def tokenize_function(batch):\n",
        "    tokenized_batch = tokenizer(batch['Sentence'], truncation=True, padding='max_length', return_tensors=\"pt\")\n",
        "    tokenized_batch['labels'] = [x / np.sum(x) for x in batch['readers_emotion_intensities']]\n",
        "    return tokenized_batch\n",
        "\n",
        "# Transformers用のデータセット形式に変換\n",
        "# pandas.DataFrame -> datasets.Dataset\n",
        "target_columns = ['Sentence', 'readers_emotion_intensities']\n",
        "train_dataset = Dataset.from_pandas(df_train[target_columns])\n",
        "test_dataset = Dataset.from_pandas(df_test[target_columns])\n",
        "\n",
        "# 前処理（tokenize_function） を適用\n",
        "train_tokenized_dataset = train_dataset.map(tokenize_function, batched=True)\n",
        "test_tokenized_dataset = test_dataset.map(tokenize_function, batched=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pVvE_1GAXEFa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "25101ea7-4c67-4f0c-ba8f-effab130e927"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at cl-tohoku/bert-base-japanese and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "# 分類モデルのため AutoModelForSequenceClassification を使用する\n",
        "# checkpoint と num_labels（クラス数） を指定する. 今回は、いずれも上で定義済み\n",
        "# - checkpoint = 'cl-tohoku/bert-base-japanese-whole-word-masking'\n",
        "# - num_labels = 8\n",
        "# config = AutoConfig.from_pretrained(checkpoint, num_labels=8)\n",
        "model = AutoModelForSequenceClassification.from_pretrained(checkpoint)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3yjZJH7iUInl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "003b2115-63ab-4651-d647-2bf6e4bacea9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/datasets/load.py:752: FutureWarning: The repository for accuracy contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.16.1/metrics/accuracy/accuracy.py\n",
            "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
            "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "# 評価指標を定義\n",
        "# https://huggingface.co/docs/transformers/training\n",
        "metric = load_metric(\"accuracy\")\n",
        "def compute_metrics(eval_pred):\n",
        "    logits, labels = eval_pred\n",
        "    predictions = np.argmax(logits, axis=-1)\n",
        "    label_ids = np.argmax(labels, axis=-1)\n",
        "    return metric.compute(predictions=predictions, references=label_ids)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AdamW, get_linear_schedule_with_warmup\n",
        "\n",
        "# AdamWオプティマイザの定義\n",
        "optimizer = AdamW(model.parameters(), lr=2e-5)  # lrは学習率,これがデフォルト"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dhfjMBOLYpC0",
        "outputId": "c1715311-642a-4cda-8357-178e4747fe9f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:429: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize_batch(batch):\n",
        "    return tokenizer(batch['Sentence'], truncation=True, padding=True)"
      ],
      "metadata": {
        "id": "0XgW1vBSZCU0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# (1)\n",
        "#データセット内の各サンプルのSentenceを同じ長さに調整する\n",
        "# パディングを行うか、あるいはトリミングを行う\n",
        "max_length = 512  # 調整後の最大長さ\n",
        "\n",
        "# Sentenceを指定した長さにトリミングする関数\n",
        "def trim_sentence(sample, tokenizer, max_length):\n",
        "    # Sentenceをトークン化\n",
        "    tokens = tokenizer(\n",
        "        sample['Sentence'],\n",
        "        max_length=max_length,\n",
        "        truncation=True,\n",
        "        padding='max_length'  # パディングもmax_lengthに合わせる\n",
        "    )\n",
        "    # トリミング後のトークンを元のフィーチャに反映\n",
        "    sample['input_ids'] = tokens['input_ids'][:max_length]\n",
        "    sample['attention_mask'] = tokens['attention_mask'][:max_length]\n",
        "    sample['labels'] = sample['readers_emotion_intensities']  # labelsを追加\n",
        "    return sample\n",
        "\n",
        "# トリミングを適用\n",
        "trimmed_train_tokenized_dataset = [trim_sentence(sample, tokenizer, max_length) for sample in train_tokenized_dataset]\n",
        "trimmed_test_tokenized_dataset = [trim_sentence(sample, tokenizer, max_length) for sample in test_tokenized_dataset]\n"
      ],
      "metadata": {
        "id": "ycbPa64CiG6N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install accelerate==0.20.3\n",
        "!pip install transformers[torch] -U"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "5XE27uhcZoHI",
        "outputId": "21a92525-d5c0-48ab-aab9-aa7216b223d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting accelerate==0.20.3\n",
            "  Using cached accelerate-0.20.3-py3-none-any.whl (227 kB)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate==0.20.3) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate==0.20.3) (23.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate==0.20.3) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate==0.20.3) (6.0.1)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from accelerate==0.20.3) (2.1.0+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->accelerate==0.20.3) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->accelerate==0.20.3) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->accelerate==0.20.3) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->accelerate==0.20.3) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->accelerate==0.20.3) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->accelerate==0.20.3) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->accelerate==0.20.3) (2.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.6.0->accelerate==0.20.3) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.6.0->accelerate==0.20.3) (1.3.0)\n",
            "Installing collected packages: accelerate\n",
            "  Attempting uninstall: accelerate\n",
            "    Found existing installation: accelerate 0.26.1\n",
            "    Uninstalling accelerate-0.26.1:\n",
            "      Successfully uninstalled accelerate-0.26.1\n",
            "Successfully installed accelerate-0.20.3\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "accelerate"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers[torch] in /usr/local/lib/python3.10/dist-packages (4.36.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.20.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.15.0)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.4.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (4.66.1)\n",
            "Requirement already satisfied: torch!=1.12.0,>=1.10 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2.1.0+cu121)\n",
            "Collecting accelerate>=0.21.0 (from transformers[torch])\n",
            "  Using cached accelerate-0.26.1-py3-none-any.whl (270 kB)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.21.0->transformers[torch]) (5.9.5)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers[torch]) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers[torch]) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.10->transformers[torch]) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.10->transformers[torch]) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.10->transformers[torch]) (3.1.2)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.10->transformers[torch]) (2.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (2023.11.17)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch!=1.12.0,>=1.10->transformers[torch]) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch!=1.12.0,>=1.10->transformers[torch]) (1.3.0)\n",
            "Installing collected packages: accelerate\n",
            "  Attempting uninstall: accelerate\n",
            "    Found existing installation: accelerate 0.20.3\n",
            "    Uninstalling accelerate-0.20.3:\n",
            "      Successfully uninstalled accelerate-0.20.3\n",
            "Successfully installed accelerate-0.26.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "accelerate"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qv4kO7D11rXX",
        "outputId": "b6dc0f1c-1187-45e2-fa91-bd0aefd12409"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# 任意のディレクトリ名を指定\n",
        "directory_name = 'cta'\n",
        "\n",
        "# Google Drive内にディレクトリを作成\n",
        "directory_path = os.path.join('/content/drive/MyDrive', directory_name)\n",
        "os.makedirs(directory_path, exist_ok=True)\n"
      ],
      "metadata": {
        "id": "wkLOY89E1yro"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import get_linear_schedule_with_warmup\n",
        "\n",
        "# トレーニング時の設定\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"directory_path\",\n",
        "    per_device_train_batch_size=4,\n",
        "    per_device_eval_batch_size=4,\n",
        "    gradient_accumulation_steps=2,\n",
        "    num_train_epochs=0.8,\n",
        "    evaluation_strategy=\"steps\",\n",
        "    eval_steps=200,\n",
        "    lr_scheduler_type=\"linear\",  # スケジューラのタイプを指定\n",
        ")\n",
        "\n",
        "# 学習率のスケジューラの設定\n",
        "num_training_steps = len(train_tokenized_dataset) // training_args.per_device_train_batch_size * training_args.num_train_epochs\n",
        "warmup_steps = int(0.1 * num_training_steps)\n",
        "scheduler = get_linear_schedule_with_warmup(\n",
        "    optimizer,\n",
        "    num_warmup_steps=warmup_steps,\n",
        "    num_training_steps=num_training_steps\n",
        ")\n"
      ],
      "metadata": {
        "id": "z97HVe7PQeeP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import nn\n",
        "from transformers import Trainer\n",
        "\n",
        "class CustomTrainer(Trainer):\n",
        "    def compute_loss(self, model, inputs, return_outputs=False):\n",
        "        labels = inputs.get(\"labels\", None)\n",
        "        if labels is None:\n",
        "            raise ValueError(\"Labels are missing or None in the inputs during training.\")\n",
        "        # モデルのフォワードパス\n",
        "        outputs = model(**inputs)\n",
        "        # logitsから損失を計算\n",
        "        logits = outputs.logits\n",
        "        loss = nn.CrossEntropyLoss()(logits, labels.view(-1))  # ラベルの形状を変更\n",
        "        if return_outputs:\n",
        "            return (loss, outputs)\n",
        "        else:\n",
        "            return loss.item() if hasattr(loss, \"item\") else loss\n"
      ],
      "metadata": {
        "id": "_rtjupVPsF3G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 通常のTrainerと同様の引数を指定して、CustomTrainerを初期化する\n",
        "custom_trainer = CustomTrainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=trimmed_train_tokenized_dataset,\n",
        "    eval_dataset=trimmed_test_tokenized_dataset,\n",
        "    compute_metrics=compute_metrics,\n",
        "    optimizers=(optimizer, scheduler)\n",
        ")\n",
        "\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "# 訓練を実行\n",
        "custom_trainer.train()\n"
      ],
      "metadata": {
        "id": "pPFXdSaksJlw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377
        },
        "outputId": "0d0b69df-be92-4a59-f320-ef984731e991"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Expected input batch_size (4) to match target batch_size (32).",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-50-d48795d22c1b>\u001b[0m in \u001b[0;36m<cell line: 14>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# 訓練を実行\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mcustom_trainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1535\u001b[0m                 \u001b[0mhf_hub_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_progress_bars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1536\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1537\u001b[0;31m             return inner_training_loop(\n\u001b[0m\u001b[1;32m   1538\u001b[0m                 \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1539\u001b[0m                 \u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   1852\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1853\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccelerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccumulate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1854\u001b[0;31m                     \u001b[0mtr_loss_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1855\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1856\u001b[0m                 if (\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtraining_step\u001b[0;34m(self, model, inputs)\u001b[0m\n\u001b[1;32m   2733\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2734\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_loss_context_manager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2735\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2736\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2737\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_gpu\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-49-83544734d037>\u001b[0m in \u001b[0;36mcompute_loss\u001b[0;34m(self, model, inputs, return_outputs)\u001b[0m\n\u001b[1;32m      8\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Labels are missing or None in the inputs during training.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0;31m# モデルのフォワードパス\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0;31m# logitsから損失を計算\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1597\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproblem_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"single_label_classification\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1598\u001b[0m                 \u001b[0mloss_fct\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCrossEntropyLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1599\u001b[0;31m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1600\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproblem_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"multi_label_classification\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1601\u001b[0m                 \u001b[0mloss_fct\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBCEWithLogitsLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m   1177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1178\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1179\u001b[0;31m         return F.cross_entropy(input, target, weight=self.weight,\n\u001b[0m\u001b[1;32m   1180\u001b[0m                                \u001b[0mignore_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mignore_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1181\u001b[0m                                label_smoothing=self.label_smoothing)\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mcross_entropy\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[0m\n\u001b[1;32m   3051\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msize_average\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mreduce\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3052\u001b[0m         \u001b[0mreduction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_get_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize_average\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3053\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_entropy_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_smoothing\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3054\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3055\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Expected input batch_size (4) to match target batch_size (32)."
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "このエラーは、期待される入力とターゲットのバッチサイズが一致しないことを示しています。エラーメッセージによると、入力のバッチサイズは4であり、ターゲットのバッチサイズは32です。\n",
        "\n",
        "この問題を解決するために、次のいくつかの点を確認してみましょう。\n",
        "\n",
        "データの確認: トレーニングデータとラベルのサイズが正しいか確認してください。特に、データとラベルが正しく結びついていることを確認してください。\n",
        "\n",
        "データローダーのバッチサイズ: トレーニング中に使用されるデータローダーのバッチサイズが正しいか確認してください。データローダーのバッチサイズは、モデルへの入力とラベルのバッチサイズと一致する必要があります。\n",
        "\n",
        "損失関数の適用: カスタムの損失関数でnn.CrossEntropyLoss()を使用していますが、この関数は通常、ログオッズ（logits）とクラスラベルのバッチを取ります。ラベルは長さがバッチサイズ分の1次元テンソルである必要があります。エラーメッセージから見ても、ラベルの形状を変更しているようですが、それが正しく行われているか確認してください。"
      ],
      "metadata": {
        "id": "L5jI8Kk12ZhN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import nn\n",
        "from transformers import Trainer, TrainingArguments\n",
        "\n",
        "class CustomTrainer(Trainer):\n",
        "    def compute_loss(self, model, inputs, return_outputs=False):\n",
        "        labels = inputs.get(\"labels\", None)\n",
        "        if labels is None:\n",
        "            raise ValueError(\"Labels are missing or None in the inputs during training.\")\n",
        "        # モデルのフォワードパス\n",
        "        outputs = model(**inputs)\n",
        "        # logitsから損失を計算\n",
        "        logits = outputs.logits\n",
        "        # ラベルの形状を変更\n",
        "        labels = labels.view(-1)\n",
        "        # バッチサイズが4になるように変更\n",
        "        logits = logits.view(-1, 4)\n",
        "        loss = nn.CrossEntropyLoss()(logits, labels)\n",
        "        if return_outputs:\n",
        "            return (loss, outputs)\n",
        "        else:\n",
        "            return loss.item() if hasattr(loss, \"item\") else loss\n",
        "\n",
        "# 以下のように TrainingArguments を設定\n",
        "args = TrainingArguments(\n",
        "    output_dir=directory_path,\n",
        "    per_device_train_batch_size=4,  # 1つのGPUあたりのトレーニングバッチサイズ\n",
        "    per_device_eval_batch_size=4,   # 1つのGPUあたりの評価バッチサイズ\n",
        "    gradient_accumulation_steps=1,  # 勾配蓄積のステップ数\n",
        "    # 他の設定...\n",
        "    num_train_epochs=0.8,\n",
        "    evaluation_strategy=\"steps\",\n",
        "    eval_steps=200,\n",
        ")\n",
        "\n",
        "# 訓練データやモデルなどの準備...\n",
        "# train_dataset, eval_dataset, model, tokenizer の定義...\n",
        "\n",
        "# Trainerのインスタンスを作成\n",
        "custom_trainer = CustomTrainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    tokenizer=tokenizer,\n",
        "    train_dataset=trimmed_train_tokenized_dataset,\n",
        "    eval_dataset=trimmed_test_tokenized_dataset,\n",
        ")\n",
        "\n",
        "# 訓練を実行\n",
        "custom_trainer.train()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377
        },
        "id": "PLjTgP9I2yYd",
        "outputId": "98068d8b-e652-45b5-8c0e-c5c3a556a9d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Expected input batch_size (4) to match target batch_size (32).",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-36-f5fbbc77b517>\u001b[0m in \u001b[0;36m<cell line: 48>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;31m# 訓練を実行\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m \u001b[0mcustom_trainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1535\u001b[0m                 \u001b[0mhf_hub_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_progress_bars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1536\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1537\u001b[0;31m             return inner_training_loop(\n\u001b[0m\u001b[1;32m   1538\u001b[0m                 \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1539\u001b[0m                 \u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   1852\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1853\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccelerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccumulate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1854\u001b[0;31m                     \u001b[0mtr_loss_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1855\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1856\u001b[0m                 if (\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtraining_step\u001b[0;34m(self, model, inputs)\u001b[0m\n\u001b[1;32m   2733\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2734\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_loss_context_manager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2735\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2736\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2737\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_gpu\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-36-f5fbbc77b517>\u001b[0m in \u001b[0;36mcompute_loss\u001b[0;34m(self, model, inputs, return_outputs)\u001b[0m\n\u001b[1;32m      8\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Labels are missing or None in the inputs during training.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0;31m# モデルのフォワードパス\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0;31m# logitsから損失を計算\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1597\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproblem_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"single_label_classification\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1598\u001b[0m                 \u001b[0mloss_fct\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCrossEntropyLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1599\u001b[0;31m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1600\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproblem_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"multi_label_classification\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1601\u001b[0m                 \u001b[0mloss_fct\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBCEWithLogitsLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m   1177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1178\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1179\u001b[0;31m         return F.cross_entropy(input, target, weight=self.weight,\n\u001b[0m\u001b[1;32m   1180\u001b[0m                                \u001b[0mignore_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mignore_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1181\u001b[0m                                label_smoothing=self.label_smoothing)\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mcross_entropy\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[0m\n\u001b[1;32m   3051\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msize_average\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mreduce\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3052\u001b[0m         \u001b[0mreduction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_get_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize_average\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3053\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_entropy_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_smoothing\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3054\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3055\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Expected input batch_size (4) to match target batch_size (32)."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# trainer = Trainer(\n",
        "#     model=model,\n",
        "#     args=training_args,\n",
        "#     # data_collator=pad_collate,  # デフォルトのデータコレーターを使用\n",
        "#     train_dataset=train_tokenized_dataset,\n",
        "#     eval_dataset=test_tokenized_dataset,\n",
        "#     compute_metrics=compute_metrics,\n",
        "#     # optimizer=optimizer,\n",
        "#     # lr_scheduler=scheduler,  # 学習率スケジューラを指定\n",
        "# )\n",
        "\n",
        "# # 訓練を実行\n",
        "# trainer.train()"
      ],
      "metadata": {
        "id": "cRfMokBJ6qpT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-h0tclaxUInm"
      },
      "outputs": [],
      "source": [
        "# https://www.delftstack.com/ja/howto/numpy/numpy-softmax/\n",
        "def np_softmax(x):\n",
        "    f_x = np.exp(x) / np.sum(np.exp(x))\n",
        "    return f_x\n",
        "\n",
        "def analyze_emotion(text, show_fig=False, ret_prob=False):\n",
        "    # 推論モードを有効化\n",
        "    model.eval()\n",
        "\n",
        "    # 入力データ変換 + 推論\n",
        "    tokens = tokenizer(text, truncation=True, return_tensors=\"pt\")\n",
        "    tokens.to(model.device)\n",
        "    preds = model(**tokens)\n",
        "    prob = np_softmax(preds.logits.cpu().detach().numpy()[0])\n",
        "    out_dict = {n: p for n, p in zip(emotion_names_jp, prob)}\n",
        "\n",
        "    # 棒グラフを描画\n",
        "    if show_fig:\n",
        "        plt.figure(figsize=(8, 3))\n",
        "        df = pd.DataFrame(out_dict.items(), columns=['name', 'prob'])\n",
        "        sns.barplot(x='name', y='prob', data=df)\n",
        "        plt.title('入力文 : ' + text, fontsize=15)\n",
        "\n",
        "    if ret_prob:\n",
        "        return out_dict\n",
        "\n",
        "# 動作確認\n",
        "analyze_emotion('今日から長期休暇だぁーーー！！！', show_fig=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TmI5b0LdUInm"
      },
      "outputs": [],
      "source": [
        "analyze_emotion('この書類にはコーヒーかかってなくて良かった…。不幸中の幸いだ。', show_fig=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NN7HD39tXhrn"
      },
      "outputs": [],
      "source": [
        "analyze_emotion('なんで自分だけこんな目に遭うんだ……', show_fig=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sfhyeuHWXlZz"
      },
      "outputs": [],
      "source": [
        "analyze_emotion('君ならきっとやってくれると思っていたよ！', show_fig=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JieaUWipXnTP"
      },
      "outputs": [],
      "source": [
        "analyze_emotion('え、今日って休校だったの？', show_fig=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XKoAmqYlXpaj"
      },
      "outputs": [],
      "source": [
        "analyze_emotion('明日のプレゼンうまくできるかなぁ…', show_fig=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H824mByPXrJL"
      },
      "outputs": [],
      "source": [
        "analyze_emotion('あぁー、イライラするっ！！', show_fig=True)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.1"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "2f1cf2602d364c589a5caaba4e7ceabc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_078ddc51740642c8ac3aa3fec6c6c28b",
              "IPY_MODEL_ab313015283b418591334e7f77c32197",
              "IPY_MODEL_e9243ca6650f4d329726cc8ef4642ac3"
            ],
            "layout": "IPY_MODEL_14fa6c4abc2d4831a8c4e548df8abdf3"
          }
        },
        "078ddc51740642c8ac3aa3fec6c6c28b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_29a2413c26aa4b3f8aba3e0e3d606ccf",
            "placeholder": "​",
            "style": "IPY_MODEL_2cff2bdb5964410cb27c9b99df2ad2b6",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "ab313015283b418591334e7f77c32197": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_57989b5b3875477cb451022d2a15e86b",
            "max": 104,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_869c7bb8ece8402c8a9aa3fd5665a126",
            "value": 104
          }
        },
        "e9243ca6650f4d329726cc8ef4642ac3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_419b4f3c2af84ec08c318aa1d004f111",
            "placeholder": "​",
            "style": "IPY_MODEL_a7e3f9f99ce5443c8b6fce8d29f15f50",
            "value": " 104/104 [00:00&lt;00:00, 7.99kB/s]"
          }
        },
        "14fa6c4abc2d4831a8c4e548df8abdf3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "29a2413c26aa4b3f8aba3e0e3d606ccf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2cff2bdb5964410cb27c9b99df2ad2b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "57989b5b3875477cb451022d2a15e86b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "869c7bb8ece8402c8a9aa3fd5665a126": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "419b4f3c2af84ec08c318aa1d004f111": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a7e3f9f99ce5443c8b6fce8d29f15f50": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b7163fd1ec064514a41e73271e95f2c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d5cd1ad861a046a1a21d8f7c1e0d3b86",
              "IPY_MODEL_8dc3b614f2464b2396a80cb85bb33d8d",
              "IPY_MODEL_088a64c937ce438b90a62e88090fd076"
            ],
            "layout": "IPY_MODEL_993b95e957494025b8c587465e36f6f5"
          }
        },
        "d5cd1ad861a046a1a21d8f7c1e0d3b86": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6d26a5b5a8e7478695938aac0bf402d9",
            "placeholder": "​",
            "style": "IPY_MODEL_1700eb6fd1b244ab83c25784e396d379",
            "value": "config.json: 100%"
          }
        },
        "8dc3b614f2464b2396a80cb85bb33d8d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_92fccf5f0f5f437fbcc4eaae75439522",
            "max": 479,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5a6db2452a234b029f7ecae081c82cb2",
            "value": 479
          }
        },
        "088a64c937ce438b90a62e88090fd076": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6fdafa3be86f4e8b8ab6e58a8300f475",
            "placeholder": "​",
            "style": "IPY_MODEL_4429df1353fd4683952b556e9c8d382b",
            "value": " 479/479 [00:00&lt;00:00, 19.0kB/s]"
          }
        },
        "993b95e957494025b8c587465e36f6f5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6d26a5b5a8e7478695938aac0bf402d9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1700eb6fd1b244ab83c25784e396d379": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "92fccf5f0f5f437fbcc4eaae75439522": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5a6db2452a234b029f7ecae081c82cb2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6fdafa3be86f4e8b8ab6e58a8300f475": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4429df1353fd4683952b556e9c8d382b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9323815bfa1a46148a912a36aab888b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9517af60ee1b44e1afaedc55afb2c595",
              "IPY_MODEL_1a9f4ed51cd2428a8c3e1dbbfa609f30",
              "IPY_MODEL_3155ca48b4124f5d90ae5ba267b12f6a"
            ],
            "layout": "IPY_MODEL_b642a838d7d94eef880f39b04b8e41f2"
          }
        },
        "9517af60ee1b44e1afaedc55afb2c595": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_82299dbecd9f4827a70a543c83434c1a",
            "placeholder": "​",
            "style": "IPY_MODEL_c1380b8849e94a0fb13da04ba3bcb7b9",
            "value": "vocab.txt: 100%"
          }
        },
        "1a9f4ed51cd2428a8c3e1dbbfa609f30": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d27405f9034848e08c05b04bfc645bd8",
            "max": 257706,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b51bbe79692a40d6b872d7775135a6cf",
            "value": 257706
          }
        },
        "3155ca48b4124f5d90ae5ba267b12f6a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6095a367327f44d589237002a69cfff6",
            "placeholder": "​",
            "style": "IPY_MODEL_4f31f81de662467688183452fbf3edf0",
            "value": " 258k/258k [00:00&lt;00:00, 692kB/s]"
          }
        },
        "b642a838d7d94eef880f39b04b8e41f2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "82299dbecd9f4827a70a543c83434c1a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c1380b8849e94a0fb13da04ba3bcb7b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d27405f9034848e08c05b04bfc645bd8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b51bbe79692a40d6b872d7775135a6cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6095a367327f44d589237002a69cfff6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4f31f81de662467688183452fbf3edf0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b0266dc4225d4c66ae443c4a11fbb84a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_de28f93a33514063ab2cb45df37db756",
              "IPY_MODEL_fd478a042d49468b9baa3b6b02bb819f",
              "IPY_MODEL_83d0cf064daa4d089bef73da304d9425"
            ],
            "layout": "IPY_MODEL_710f48f6896843629cef73af8571a5b1"
          }
        },
        "de28f93a33514063ab2cb45df37db756": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1db03a67b12d47ae97a4fb0135666973",
            "placeholder": "​",
            "style": "IPY_MODEL_4039757d01284537914c2420989843c3",
            "value": "pytorch_model.bin: 100%"
          }
        },
        "fd478a042d49468b9baa3b6b02bb819f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_15c3974dee14439eab1e27ae8d71ab29",
            "max": 445021143,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5126ed76df9f4cdf9ffc2562b5892cc1",
            "value": 445021143
          }
        },
        "83d0cf064daa4d089bef73da304d9425": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d2f008731ea54770bd8597dad2506c21",
            "placeholder": "​",
            "style": "IPY_MODEL_397ba97f88ce478ca526614c3de5d482",
            "value": " 445M/445M [00:07&lt;00:00, 80.3MB/s]"
          }
        },
        "710f48f6896843629cef73af8571a5b1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1db03a67b12d47ae97a4fb0135666973": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4039757d01284537914c2420989843c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "15c3974dee14439eab1e27ae8d71ab29": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5126ed76df9f4cdf9ffc2562b5892cc1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d2f008731ea54770bd8597dad2506c21": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "397ba97f88ce478ca526614c3de5d482": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0b4c2a82c4af4bdc9abb1b1028b4580c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_48f149d06f6c41a6b71fdc17f542047e",
              "IPY_MODEL_d63396ea5152425bb61f76bd410f1a33",
              "IPY_MODEL_b902815d261942e7beba585a34587ba7"
            ],
            "layout": "IPY_MODEL_bd9379892ef1453b816f1e92270750be"
          }
        },
        "48f149d06f6c41a6b71fdc17f542047e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a649d61ea6f6407db5010df76dde4dc6",
            "placeholder": "​",
            "style": "IPY_MODEL_7a3ca3933ff34d5698d98cc80850a763",
            "value": "Map: 100%"
          }
        },
        "d63396ea5152425bb61f76bd410f1a33": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_132e236c94d54fb3bd43147e7d13ff9c",
            "max": 17104,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f036c3a646d3459e8391c8782b5d8f33",
            "value": 17104
          }
        },
        "b902815d261942e7beba585a34587ba7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2686ac9ca90b485495cb7718efbdf00d",
            "placeholder": "​",
            "style": "IPY_MODEL_b686a8eefcc1458689c655f243d6a0c0",
            "value": " 17104/17104 [00:10&lt;00:00, 1476.87 examples/s]"
          }
        },
        "bd9379892ef1453b816f1e92270750be": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a649d61ea6f6407db5010df76dde4dc6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7a3ca3933ff34d5698d98cc80850a763": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "132e236c94d54fb3bd43147e7d13ff9c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f036c3a646d3459e8391c8782b5d8f33": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2686ac9ca90b485495cb7718efbdf00d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b686a8eefcc1458689c655f243d6a0c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b88f4165ba47456d802ee411a947fa5f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5727168cd7704503a1311588501160d2",
              "IPY_MODEL_05376e07e7dd4033bc4e71186a421584",
              "IPY_MODEL_018174037e50440d949c0c23306fcbc5"
            ],
            "layout": "IPY_MODEL_e253f8d91ace43978ae647263762f4ef"
          }
        },
        "5727168cd7704503a1311588501160d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_58e3f336b1254e379d85be2755a425ae",
            "placeholder": "​",
            "style": "IPY_MODEL_5769c41dcfc34139b148563cc6af60c7",
            "value": "Map: 100%"
          }
        },
        "05376e07e7dd4033bc4e71186a421584": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8b4de1e5f1f2479e98e4ed96d5ce7851",
            "max": 1133,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7fe3c10be27a47218d9412f9cdc63dbb",
            "value": 1133
          }
        },
        "018174037e50440d949c0c23306fcbc5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a600ba765fc442d2a40d4d12d0519068",
            "placeholder": "​",
            "style": "IPY_MODEL_de3ba313af3c4b9aaaba1032dccc0001",
            "value": " 1133/1133 [00:00&lt;00:00, 1926.34 examples/s]"
          }
        },
        "e253f8d91ace43978ae647263762f4ef": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "58e3f336b1254e379d85be2755a425ae": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5769c41dcfc34139b148563cc6af60c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8b4de1e5f1f2479e98e4ed96d5ce7851": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7fe3c10be27a47218d9412f9cdc63dbb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a600ba765fc442d2a40d4d12d0519068": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "de3ba313af3c4b9aaaba1032dccc0001": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}