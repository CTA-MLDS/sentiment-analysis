{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nkZLAbNbUInd",
        "outputId": "0a667fb8-af59-420c-f755-db787ef86f6e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.36.2)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (2.16.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.0)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (10.0.1)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets) (0.6)\n",
            "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.7)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (1.5.3)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.4.1)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.15)\n",
            "Requirement already satisfied: fsspec[http]<=2023.10.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.9.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.2.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.4)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.11.17)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.3.post1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "! pip install transformers datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TFBeR-taUIng",
        "outputId": "55c338ca-04e5-4c49-ccfe-773722c6dcb0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: fugashi in /usr/local/lib/python3.10/dist-packages (1.3.0)\n",
            "Requirement already satisfied: ipadic in /usr/local/lib/python3.10/dist-packages (1.0.0)\n"
          ]
        }
      ],
      "source": [
        "! pip install fugashi ipadic"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6qA72unnUInh"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7KtLWdhuUInh"
      },
      "outputs": [],
      "source": [
        "# Hugging Face (Transformers) 関連のモジュール\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "from transformers import TrainingArguments, Trainer\n",
        "from datasets import Dataset, load_metric"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0A7oeix9UIni",
        "outputId": "71813e56-5495-4344-ee8e-e33f3e7ab9bf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "fonts-ipafont-gothic is already the newest version (00303-21ubuntu1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 24 not upgraded.\n",
            "rm: cannot remove '/root/.cache/matplotlib/fontlist-v310.json': No such file or directory\n"
          ]
        }
      ],
      "source": [
        "# [前準備] Matplotlib で日本語フォントを使用できるようにする\n",
        "# cf. https://blog.3qe.us/entry/2018/08/16/121457\n",
        "!apt-get -y install fonts-ipafont-gothic\n",
        "!rm /root/.cache/matplotlib/fontlist-v310.json\n",
        "# jupyter notebookで動くように書き換え↓\n",
        "# ! pip install matplotlib\n",
        "# ! pip install japanize-matplotlib\n",
        "\n",
        "# NOTE ここで、ランタイムを再起動"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z2SSxznCVFQ5",
        "outputId": "fc546bc0-33fa-469a-f4cb-22081b6c7dfd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "fonts-ipafont-gothic is already the newest version (00303-21ubuntu1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 24 not upgraded.\n",
            "/usr/share/fonts: caching, new cache contents: 0 fonts, 2 dirs\n",
            "/usr/share/fonts/opentype: caching, new cache contents: 0 fonts, 2 dirs\n",
            "/usr/share/fonts/opentype/ipafont-gothic: caching, new cache contents: 2 fonts, 0 dirs\n",
            "/usr/share/fonts/opentype/ipafont-mincho: caching, new cache contents: 2 fonts, 0 dirs\n",
            "/usr/share/fonts/truetype: caching, new cache contents: 2 fonts, 2 dirs\n",
            "/usr/share/fonts/truetype/humor-sans: caching, new cache contents: 1 fonts, 0 dirs\n",
            "/usr/share/fonts/truetype/liberation: caching, new cache contents: 16 fonts, 0 dirs\n",
            "/usr/local/share/fonts: caching, new cache contents: 0 fonts, 0 dirs\n",
            "/root/.local/share/fonts: skipping, no such directory\n",
            "/root/.fonts: skipping, no such directory\n",
            "/usr/share/fonts/opentype: skipping, looped directory detected\n",
            "/usr/share/fonts/truetype: skipping, looped directory detected\n",
            "/usr/share/fonts/opentype/ipafont-gothic: skipping, looped directory detected\n",
            "/usr/share/fonts/opentype/ipafont-mincho: skipping, looped directory detected\n",
            "/usr/share/fonts/truetype/humor-sans: skipping, looped directory detected\n",
            "/usr/share/fonts/truetype/liberation: skipping, looped directory detected\n",
            "/var/cache/fontconfig: cleaning cache directory\n",
            "/root/.cache/fontconfig: not cleaning non-existent cache directory\n",
            "/root/.fontconfig: not cleaning non-existent cache directory\n",
            "fc-cache: succeeded\n",
            "rm: cannot remove '/root/.cache/matplotlib/fontlist-v310.json': No such file or directory\n"
          ]
        }
      ],
      "source": [
        "!sudo apt-get install fonts-ipafont-gothic\n",
        "!sudo fc-cache -fv\n",
        "!rm /root/.cache/matplotlib/fontlist-v310.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Eze6XSk0VOqd",
        "outputId": "52d5c0b9-cb18-4cdf-f5d4-68ffbcd407e1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: japanize-matplotlib in /usr/local/lib/python3.10/dist-packages (1.1.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from japanize-matplotlib) (3.7.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->japanize-matplotlib) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->japanize-matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->japanize-matplotlib) (4.47.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->japanize-matplotlib) (1.4.5)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from matplotlib->japanize-matplotlib) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->japanize-matplotlib) (23.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->japanize-matplotlib) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->japanize-matplotlib) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->japanize-matplotlib) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->japanize-matplotlib) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "! pip install japanize-matplotlib\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wC4a9tDxUInj"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import japanize_matplotlib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "egwBaEh6UInj"
      },
      "outputs": [],
      "source": [
        "# if 'IPAGothic' not in plt.rcParams['font.family']:\n",
        "#     plt.rcParams['font.family'] = 'MS Gothic'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 158
        },
        "id": "nR0VWE4RUInj",
        "outputId": "7733cfeb-0111-4433-fbde-b83b226e718a"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 500x100 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# 動作確認\n",
        "plt.figure(figsize=(5, 1))\n",
        "plt.title('日本語表示、テスト')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JyEZkLerUInj",
        "outputId": "a6d6f856-f06a-465e-d1d9-3d7fd356ee17"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2024-01-09 08:56:21--  https://github.com/ids-cv/wrime/raw/master/wrime-ver1.tsv\n",
            "Resolving github.com (github.com)... 140.82.114.4\n",
            "Connecting to github.com (github.com)|140.82.114.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/ids-cv/wrime/master/wrime-ver1.tsv [following]\n",
            "--2024-01-09 08:56:22--  https://raw.githubusercontent.com/ids-cv/wrime/master/wrime-ver1.tsv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 9487235 (9.0M) [text/plain]\n",
            "Saving to: ‘wrime-ver1.tsv.2’\n",
            "\n",
            "wrime-ver1.tsv.2    100%[===================>]   9.05M  --.-KB/s    in 0.09s   \n",
            "\n",
            "2024-01-09 08:56:22 (99.3 MB/s) - ‘wrime-ver1.tsv.2’ saved [9487235/9487235]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# GitHubよりWRIMEデータをダウンロードする\n",
        "#\n",
        "# WRIME dataset : https://github.com/ids-cv/wrime\n",
        "# 今回使用するのは ver1 （感情極性が付与されていない版）\n",
        "\n",
        "! wget https://github.com/ids-cv/wrime/raw/master/wrime-ver1.tsv\n",
        "\n",
        "# question to ask\n",
        "# tried to run the command through this cell, didn't work.\n",
        "# installed wget, but couldn't execute the file\n",
        "# manually moved the file to the system32 file of windows and ran the program through cmd (and worked??)\n",
        "\n",
        "# fugashiがインストールできない\n",
        "# -> mecab.hが認識されない -> 通常はincludeサブディレクトリにあるはずだが、代わりにsrcに入っている（そしてincludeは存在していない）\n",
        "# -> mecabを再度インストール -> mecabのバージョンをチェックしたいmecab --versionが、エラー（'mecab' is not recognized as an internal or external command,\n",
        "# operable program or batch file.）-> 環境変数にpathを追加 -> INCLUDE変数も追加 -> やっぱりmecab.hが認識されない\n",
        "# mecabのビルド済みバイナリをインストール　pip install mecab-python-binary　pip install mecab-python3　pip install mecab-python3 --global-option=\"--with-cflags=-IC:\\Users\\minaa\\OneDrive\\TCA\\mecab\\mecab\\mecab\\src\"\n",
        "# fugashiを諦めます\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 491
        },
        "id": "zTVQyzpXUInk",
        "outputId": "3abd3fd3-0fff-4b92-b3f2-a0892da4d99e"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-2d46675a-54a5-47c5-ae23-ef6a0e6dab39\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sentence</th>\n",
              "      <th>UserID</th>\n",
              "      <th>Datetime</th>\n",
              "      <th>Train/Dev/Test</th>\n",
              "      <th>Writer_Joy</th>\n",
              "      <th>Writer_Sadness</th>\n",
              "      <th>Writer_Anticipation</th>\n",
              "      <th>Writer_Surprise</th>\n",
              "      <th>Writer_Anger</th>\n",
              "      <th>Writer_Fear</th>\n",
              "      <th>...</th>\n",
              "      <th>Reader3_Disgust</th>\n",
              "      <th>Reader3_Trust</th>\n",
              "      <th>Avg. Readers_Joy</th>\n",
              "      <th>Avg. Readers_Sadness</th>\n",
              "      <th>Avg. Readers_Anticipation</th>\n",
              "      <th>Avg. Readers_Surprise</th>\n",
              "      <th>Avg. Readers_Anger</th>\n",
              "      <th>Avg. Readers_Fear</th>\n",
              "      <th>Avg. Readers_Disgust</th>\n",
              "      <th>Avg. Readers_Trust</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ぼけっとしてたらこんな時間｡チャリあるから食べにでたいのに…</td>\n",
              "      <td>1</td>\n",
              "      <td>2012/07/31 23:48</td>\n",
              "      <td>train</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>今日の月も白くて明るい。昨日より雲が少なくてキレイな? と立ち止まる帰り道｡チャリなし生活も...</td>\n",
              "      <td>1</td>\n",
              "      <td>2012/08/02 23:09</td>\n",
              "      <td>train</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2 rows × 44 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2d46675a-54a5-47c5-ae23-ef6a0e6dab39')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-2d46675a-54a5-47c5-ae23-ef6a0e6dab39 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-2d46675a-54a5-47c5-ae23-ef6a0e6dab39');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-e3cbabef-9db5-401b-8696-76429c01aee6\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-e3cbabef-9db5-401b-8696-76429c01aee6')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-e3cbabef-9db5-401b-8696-76429c01aee6 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "                                            Sentence  UserID  \\\n",
              "0                     ぼけっとしてたらこんな時間｡チャリあるから食べにでたいのに…       1   \n",
              "1  今日の月も白くて明るい。昨日より雲が少なくてキレイな? と立ち止まる帰り道｡チャリなし生活も...       1   \n",
              "\n",
              "           Datetime Train/Dev/Test  Writer_Joy  Writer_Sadness  \\\n",
              "0  2012/07/31 23:48          train           0               1   \n",
              "1  2012/08/02 23:09          train           3               0   \n",
              "\n",
              "   Writer_Anticipation  Writer_Surprise  Writer_Anger  Writer_Fear  ...  \\\n",
              "0                    2                1             1            0  ...   \n",
              "1                    3                0             0            0  ...   \n",
              "\n",
              "   Reader3_Disgust  Reader3_Trust  Avg. Readers_Joy  Avg. Readers_Sadness  \\\n",
              "0                1              0                 0                     2   \n",
              "1                0              1                 1                     0   \n",
              "\n",
              "   Avg. Readers_Anticipation  Avg. Readers_Surprise  Avg. Readers_Anger  \\\n",
              "0                          0                      0                   0   \n",
              "1                          0                      2                   0   \n",
              "\n",
              "   Avg. Readers_Fear  Avg. Readers_Disgust  Avg. Readers_Trust  \n",
              "0                  0                     0                   0  \n",
              "1                  0                     0                   0  \n",
              "\n",
              "[2 rows x 44 columns]"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# pandas.DataFrameとして読み込む\n",
        "df_wrime = pd.read_table('wrime-ver1.tsv')\n",
        "df_wrime.head(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TsdByOjQUInk"
      },
      "outputs": [],
      "source": [
        "emotion_names = ['Joy', 'Sadness', 'Anticipation', 'Surprise', 'Anger', 'Fear', 'Disgust', 'Trust']\n",
        "num_labels = len(emotion_names)\n",
        "# objective emotion average (Avg. Readers_*) values are converted to list, defined as a new column\n",
        "df_wrime['readers_emotion_intensities'] = df_wrime.apply(lambda x: [x['Avg. Readers_' + name] for name in emotion_names], axis=1)\n",
        "\n",
        "# removing samples with less emotion intensities\n",
        "# (max.readers_emotion_intensities must be 2 or more)\n",
        "is_target = df_wrime['readers_emotion_intensities'].map(lambda x: max(x) >= 2)\n",
        "df_wrime_target = df_wrime[is_target]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dApwmsSfUInk"
      },
      "outputs": [],
      "source": [
        "# divide into train and test data\n",
        "df_groups = df_wrime_target.groupby('Train/Dev/Test')\n",
        "df_train = df_groups.get_group('train')\n",
        "df_test = pd.concat([df_groups.get_group('dev'), df_groups.get_group('test')])\n",
        "# print('train :', len(df_train))\n",
        "# print('test :', len(df_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZLTE0nvlWyTz",
        "outputId": "fd3a7027-3e24-4c63-9bb8-410a7185d969"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:72: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "# 使用するモデルを指定して、Tokenizerを読み込む\n",
        "checkpoint = 'cl-tohoku/bert-base-japanese-whole-word-masking'\n",
        "tokenizer = AutoTokenizer.from_pretrained(checkpoint)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sAQbFmQyRNNX"
      },
      "outputs": [],
      "source": [
        "#  (1) 使用するモデルをより簡素なものに\n",
        "# checkpoint = 'distilbert-base-japanese'\n",
        "# tokenizer = AutoTokenizer.from_pretrained(checkpoint)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9fV0ZxsqRbpa"
      },
      "outputs": [],
      "source": [
        "#  (2) モデルの一部の層を削減して軽量化\n",
        "from transformers import AutoModel, AutoConfig\n",
        "\n",
        "config = AutoConfig.from_pretrained(checkpoint, num_hidden_layers=6)  # 6層に変更\n",
        "model = AutoModel.from_pretrained(checkpoint, config=config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_4OG0RtkRfn_",
        "outputId": "a78c9a48-6a66-4927-cb4b-14033e9a680a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of BertModel were not initialized from the model checkpoint at cl-tohoku/bert-base-japanese-whole-word-masking and are newly initialized because the shapes did not match:\n",
            "- bert.embeddings.word_embeddings.weight: found shape torch.Size([32000, 768]) in the checkpoint and torch.Size([32000, 252]) in the model instantiated\n",
            "- bert.embeddings.position_embeddings.weight: found shape torch.Size([512, 768]) in the checkpoint and torch.Size([512, 252]) in the model instantiated\n",
            "- bert.embeddings.token_type_embeddings.weight: found shape torch.Size([2, 768]) in the checkpoint and torch.Size([2, 252]) in the model instantiated\n",
            "- bert.embeddings.LayerNorm.weight: found shape torch.Size([768]) in the checkpoint and torch.Size([252]) in the model instantiated\n",
            "- bert.embeddings.LayerNorm.bias: found shape torch.Size([768]) in the checkpoint and torch.Size([252]) in the model instantiated\n",
            "- bert.encoder.layer.0.attention.self.query.weight: found shape torch.Size([768, 768]) in the checkpoint and torch.Size([252, 252]) in the model instantiated\n",
            "- bert.encoder.layer.0.attention.self.query.bias: found shape torch.Size([768]) in the checkpoint and torch.Size([252]) in the model instantiated\n",
            "- bert.encoder.layer.0.attention.self.key.weight: found shape torch.Size([768, 768]) in the checkpoint and torch.Size([252, 252]) in the model instantiated\n",
            "- bert.encoder.layer.0.attention.self.key.bias: found shape torch.Size([768]) in the checkpoint and torch.Size([252]) in the model instantiated\n",
            "- bert.encoder.layer.0.attention.self.value.weight: found shape torch.Size([768, 768]) in the checkpoint and torch.Size([252, 252]) in the model instantiated\n",
            "- bert.encoder.layer.0.attention.self.value.bias: found shape torch.Size([768]) in the checkpoint and torch.Size([252]) in the model instantiated\n",
            "- bert.encoder.layer.0.attention.output.dense.weight: found shape torch.Size([768, 768]) in the checkpoint and torch.Size([252, 252]) in the model instantiated\n",
            "- bert.encoder.layer.0.attention.output.dense.bias: found shape torch.Size([768]) in the checkpoint and torch.Size([252]) in the model instantiated\n",
            "- bert.encoder.layer.0.attention.output.LayerNorm.weight: found shape torch.Size([768]) in the checkpoint and torch.Size([252]) in the model instantiated\n",
            "- bert.encoder.layer.0.attention.output.LayerNorm.bias: found shape torch.Size([768]) in the checkpoint and torch.Size([252]) in the model instantiated\n",
            "- bert.encoder.layer.0.intermediate.dense.weight: found shape torch.Size([3072, 768]) in the checkpoint and torch.Size([3072, 252]) in the model instantiated\n",
            "- bert.encoder.layer.0.output.dense.weight: found shape torch.Size([768, 3072]) in the checkpoint and torch.Size([252, 3072]) in the model instantiated\n",
            "- bert.encoder.layer.0.output.dense.bias: found shape torch.Size([768]) in the checkpoint and torch.Size([252]) in the model instantiated\n",
            "- bert.encoder.layer.0.output.LayerNorm.weight: found shape torch.Size([768]) in the checkpoint and torch.Size([252]) in the model instantiated\n",
            "- bert.encoder.layer.0.output.LayerNorm.bias: found shape torch.Size([768]) in the checkpoint and torch.Size([252]) in the model instantiated\n",
            "- bert.encoder.layer.1.attention.self.query.weight: found shape torch.Size([768, 768]) in the checkpoint and torch.Size([252, 252]) in the model instantiated\n",
            "- bert.encoder.layer.1.attention.self.query.bias: found shape torch.Size([768]) in the checkpoint and torch.Size([252]) in the model instantiated\n",
            "- bert.encoder.layer.1.attention.self.key.weight: found shape torch.Size([768, 768]) in the checkpoint and torch.Size([252, 252]) in the model instantiated\n",
            "- bert.encoder.layer.1.attention.self.key.bias: found shape torch.Size([768]) in the checkpoint and torch.Size([252]) in the model instantiated\n",
            "- bert.encoder.layer.1.attention.self.value.weight: found shape torch.Size([768, 768]) in the checkpoint and torch.Size([252, 252]) in the model instantiated\n",
            "- bert.encoder.layer.1.attention.self.value.bias: found shape torch.Size([768]) in the checkpoint and torch.Size([252]) in the model instantiated\n",
            "- bert.encoder.layer.1.attention.output.dense.weight: found shape torch.Size([768, 768]) in the checkpoint and torch.Size([252, 252]) in the model instantiated\n",
            "- bert.encoder.layer.1.attention.output.dense.bias: found shape torch.Size([768]) in the checkpoint and torch.Size([252]) in the model instantiated\n",
            "- bert.encoder.layer.1.attention.output.LayerNorm.weight: found shape torch.Size([768]) in the checkpoint and torch.Size([252]) in the model instantiated\n",
            "- bert.encoder.layer.1.attention.output.LayerNorm.bias: found shape torch.Size([768]) in the checkpoint and torch.Size([252]) in the model instantiated\n",
            "- bert.encoder.layer.1.intermediate.dense.weight: found shape torch.Size([3072, 768]) in the checkpoint and torch.Size([3072, 252]) in the model instantiated\n",
            "- bert.encoder.layer.1.output.dense.weight: found shape torch.Size([768, 3072]) in the checkpoint and torch.Size([252, 3072]) in the model instantiated\n",
            "- bert.encoder.layer.1.output.dense.bias: found shape torch.Size([768]) in the checkpoint and torch.Size([252]) in the model instantiated\n",
            "- bert.encoder.layer.1.output.LayerNorm.weight: found shape torch.Size([768]) in the checkpoint and torch.Size([252]) in the model instantiated\n",
            "- bert.encoder.layer.1.output.LayerNorm.bias: found shape torch.Size([768]) in the checkpoint and torch.Size([252]) in the model instantiated\n",
            "- bert.encoder.layer.2.attention.self.query.weight: found shape torch.Size([768, 768]) in the checkpoint and torch.Size([252, 252]) in the model instantiated\n",
            "- bert.encoder.layer.2.attention.self.query.bias: found shape torch.Size([768]) in the checkpoint and torch.Size([252]) in the model instantiated\n",
            "- bert.encoder.layer.2.attention.self.key.weight: found shape torch.Size([768, 768]) in the checkpoint and torch.Size([252, 252]) in the model instantiated\n",
            "- bert.encoder.layer.2.attention.self.key.bias: found shape torch.Size([768]) in the checkpoint and torch.Size([252]) in the model instantiated\n",
            "- bert.encoder.layer.2.attention.self.value.weight: found shape torch.Size([768, 768]) in the checkpoint and torch.Size([252, 252]) in the model instantiated\n",
            "- bert.encoder.layer.2.attention.self.value.bias: found shape torch.Size([768]) in the checkpoint and torch.Size([252]) in the model instantiated\n",
            "- bert.encoder.layer.2.attention.output.dense.weight: found shape torch.Size([768, 768]) in the checkpoint and torch.Size([252, 252]) in the model instantiated\n",
            "- bert.encoder.layer.2.attention.output.dense.bias: found shape torch.Size([768]) in the checkpoint and torch.Size([252]) in the model instantiated\n",
            "- bert.encoder.layer.2.attention.output.LayerNorm.weight: found shape torch.Size([768]) in the checkpoint and torch.Size([252]) in the model instantiated\n",
            "- bert.encoder.layer.2.attention.output.LayerNorm.bias: found shape torch.Size([768]) in the checkpoint and torch.Size([252]) in the model instantiated\n",
            "- bert.encoder.layer.2.intermediate.dense.weight: found shape torch.Size([3072, 768]) in the checkpoint and torch.Size([3072, 252]) in the model instantiated\n",
            "- bert.encoder.layer.2.output.dense.weight: found shape torch.Size([768, 3072]) in the checkpoint and torch.Size([252, 3072]) in the model instantiated\n",
            "- bert.encoder.layer.2.output.dense.bias: found shape torch.Size([768]) in the checkpoint and torch.Size([252]) in the model instantiated\n",
            "- bert.encoder.layer.2.output.LayerNorm.weight: found shape torch.Size([768]) in the checkpoint and torch.Size([252]) in the model instantiated\n",
            "- bert.encoder.layer.2.output.LayerNorm.bias: found shape torch.Size([768]) in the checkpoint and torch.Size([252]) in the model instantiated\n",
            "- bert.encoder.layer.3.attention.self.query.weight: found shape torch.Size([768, 768]) in the checkpoint and torch.Size([252, 252]) in the model instantiated\n",
            "- bert.encoder.layer.3.attention.self.query.bias: found shape torch.Size([768]) in the checkpoint and torch.Size([252]) in the model instantiated\n",
            "- bert.encoder.layer.3.attention.self.key.weight: found shape torch.Size([768, 768]) in the checkpoint and torch.Size([252, 252]) in the model instantiated\n",
            "- bert.encoder.layer.3.attention.self.key.bias: found shape torch.Size([768]) in the checkpoint and torch.Size([252]) in the model instantiated\n",
            "- bert.encoder.layer.3.attention.self.value.weight: found shape torch.Size([768, 768]) in the checkpoint and torch.Size([252, 252]) in the model instantiated\n",
            "- bert.encoder.layer.3.attention.self.value.bias: found shape torch.Size([768]) in the checkpoint and torch.Size([252]) in the model instantiated\n",
            "- bert.encoder.layer.3.attention.output.dense.weight: found shape torch.Size([768, 768]) in the checkpoint and torch.Size([252, 252]) in the model instantiated\n",
            "- bert.encoder.layer.3.attention.output.dense.bias: found shape torch.Size([768]) in the checkpoint and torch.Size([252]) in the model instantiated\n",
            "- bert.encoder.layer.3.attention.output.LayerNorm.weight: found shape torch.Size([768]) in the checkpoint and torch.Size([252]) in the model instantiated\n",
            "- bert.encoder.layer.3.attention.output.LayerNorm.bias: found shape torch.Size([768]) in the checkpoint and torch.Size([252]) in the model instantiated\n",
            "- bert.encoder.layer.3.intermediate.dense.weight: found shape torch.Size([3072, 768]) in the checkpoint and torch.Size([3072, 252]) in the model instantiated\n",
            "- bert.encoder.layer.3.output.dense.weight: found shape torch.Size([768, 3072]) in the checkpoint and torch.Size([252, 3072]) in the model instantiated\n",
            "- bert.encoder.layer.3.output.dense.bias: found shape torch.Size([768]) in the checkpoint and torch.Size([252]) in the model instantiated\n",
            "- bert.encoder.layer.3.output.LayerNorm.weight: found shape torch.Size([768]) in the checkpoint and torch.Size([252]) in the model instantiated\n",
            "- bert.encoder.layer.3.output.LayerNorm.bias: found shape torch.Size([768]) in the checkpoint and torch.Size([252]) in the model instantiated\n",
            "- bert.encoder.layer.4.attention.self.query.weight: found shape torch.Size([768, 768]) in the checkpoint and torch.Size([252, 252]) in the model instantiated\n",
            "- bert.encoder.layer.4.attention.self.query.bias: found shape torch.Size([768]) in the checkpoint and torch.Size([252]) in the model instantiated\n",
            "- bert.encoder.layer.4.attention.self.key.weight: found shape torch.Size([768, 768]) in the checkpoint and torch.Size([252, 252]) in the model instantiated\n",
            "- bert.encoder.layer.4.attention.self.key.bias: found shape torch.Size([768]) in the checkpoint and torch.Size([252]) in the model instantiated\n",
            "- bert.encoder.layer.4.attention.self.value.weight: found shape torch.Size([768, 768]) in the checkpoint and torch.Size([252, 252]) in the model instantiated\n",
            "- bert.encoder.layer.4.attention.self.value.bias: found shape torch.Size([768]) in the checkpoint and torch.Size([252]) in the model instantiated\n",
            "- bert.encoder.layer.4.attention.output.dense.weight: found shape torch.Size([768, 768]) in the checkpoint and torch.Size([252, 252]) in the model instantiated\n",
            "- bert.encoder.layer.4.attention.output.dense.bias: found shape torch.Size([768]) in the checkpoint and torch.Size([252]) in the model instantiated\n",
            "- bert.encoder.layer.4.attention.output.LayerNorm.weight: found shape torch.Size([768]) in the checkpoint and torch.Size([252]) in the model instantiated\n",
            "- bert.encoder.layer.4.attention.output.LayerNorm.bias: found shape torch.Size([768]) in the checkpoint and torch.Size([252]) in the model instantiated\n",
            "- bert.encoder.layer.4.intermediate.dense.weight: found shape torch.Size([3072, 768]) in the checkpoint and torch.Size([3072, 252]) in the model instantiated\n",
            "- bert.encoder.layer.4.output.dense.weight: found shape torch.Size([768, 3072]) in the checkpoint and torch.Size([252, 3072]) in the model instantiated\n",
            "- bert.encoder.layer.4.output.dense.bias: found shape torch.Size([768]) in the checkpoint and torch.Size([252]) in the model instantiated\n",
            "- bert.encoder.layer.4.output.LayerNorm.weight: found shape torch.Size([768]) in the checkpoint and torch.Size([252]) in the model instantiated\n",
            "- bert.encoder.layer.4.output.LayerNorm.bias: found shape torch.Size([768]) in the checkpoint and torch.Size([252]) in the model instantiated\n",
            "- bert.encoder.layer.5.attention.self.query.weight: found shape torch.Size([768, 768]) in the checkpoint and torch.Size([252, 252]) in the model instantiated\n",
            "- bert.encoder.layer.5.attention.self.query.bias: found shape torch.Size([768]) in the checkpoint and torch.Size([252]) in the model instantiated\n",
            "- bert.encoder.layer.5.attention.self.key.weight: found shape torch.Size([768, 768]) in the checkpoint and torch.Size([252, 252]) in the model instantiated\n",
            "- bert.encoder.layer.5.attention.self.key.bias: found shape torch.Size([768]) in the checkpoint and torch.Size([252]) in the model instantiated\n",
            "- bert.encoder.layer.5.attention.self.value.weight: found shape torch.Size([768, 768]) in the checkpoint and torch.Size([252, 252]) in the model instantiated\n",
            "- bert.encoder.layer.5.attention.self.value.bias: found shape torch.Size([768]) in the checkpoint and torch.Size([252]) in the model instantiated\n",
            "- bert.encoder.layer.5.attention.output.dense.weight: found shape torch.Size([768, 768]) in the checkpoint and torch.Size([252, 252]) in the model instantiated\n",
            "- bert.encoder.layer.5.attention.output.dense.bias: found shape torch.Size([768]) in the checkpoint and torch.Size([252]) in the model instantiated\n",
            "- bert.encoder.layer.5.attention.output.LayerNorm.weight: found shape torch.Size([768]) in the checkpoint and torch.Size([252]) in the model instantiated\n",
            "- bert.encoder.layer.5.attention.output.LayerNorm.bias: found shape torch.Size([768]) in the checkpoint and torch.Size([252]) in the model instantiated\n",
            "- bert.encoder.layer.5.intermediate.dense.weight: found shape torch.Size([3072, 768]) in the checkpoint and torch.Size([3072, 252]) in the model instantiated\n",
            "- bert.encoder.layer.5.output.dense.weight: found shape torch.Size([768, 3072]) in the checkpoint and torch.Size([252, 3072]) in the model instantiated\n",
            "- bert.encoder.layer.5.output.dense.bias: found shape torch.Size([768]) in the checkpoint and torch.Size([252]) in the model instantiated\n",
            "- bert.encoder.layer.5.output.LayerNorm.weight: found shape torch.Size([768]) in the checkpoint and torch.Size([252]) in the model instantiated\n",
            "- bert.encoder.layer.5.output.LayerNorm.bias: found shape torch.Size([768]) in the checkpoint and torch.Size([252]) in the model instantiated\n",
            "- bert.encoder.layer.6.attention.self.query.weight: found shape torch.Size([768, 768]) in the checkpoint and torch.Size([252, 252]) in the model instantiated\n",
            "- bert.encoder.layer.6.attention.self.query.bias: found shape torch.Size([768]) in the checkpoint and torch.Size([252]) in the model instantiated\n",
            "- bert.encoder.layer.6.attention.self.key.weight: found shape torch.Size([768, 768]) in the checkpoint and torch.Size([252, 252]) in the model instantiated\n",
            "- bert.encoder.layer.6.attention.self.key.bias: found shape torch.Size([768]) in the checkpoint and torch.Size([252]) in the model instantiated\n",
            "- bert.encoder.layer.6.attention.self.value.weight: found shape torch.Size([768, 768]) in the checkpoint and torch.Size([252, 252]) in the model instantiated\n",
            "- bert.encoder.layer.6.attention.self.value.bias: found shape torch.Size([768]) in the checkpoint and torch.Size([252]) in the model instantiated\n",
            "- bert.encoder.layer.6.attention.output.dense.weight: found shape torch.Size([768, 768]) in the checkpoint and torch.Size([252, 252]) in the model instantiated\n",
            "- bert.encoder.layer.6.attention.output.dense.bias: found shape torch.Size([768]) in the checkpoint and torch.Size([252]) in the model instantiated\n",
            "- bert.encoder.layer.6.attention.output.LayerNorm.weight: found shape torch.Size([768]) in the checkpoint and torch.Size([252]) in the model instantiated\n",
            "- bert.encoder.layer.6.attention.output.LayerNorm.bias: found shape torch.Size([768]) in the checkpoint and torch.Size([252]) in the model instantiated\n",
            "- bert.encoder.layer.6.intermediate.dense.weight: found shape torch.Size([3072, 768]) in the checkpoint and torch.Size([3072, 252]) in the model instantiated\n",
            "- bert.encoder.layer.6.output.dense.weight: found shape torch.Size([768, 3072]) in the checkpoint and torch.Size([252, 3072]) in the model instantiated\n",
            "- bert.encoder.layer.6.output.dense.bias: found shape torch.Size([768]) in the checkpoint and torch.Size([252]) in the model instantiated\n",
            "- bert.encoder.layer.6.output.LayerNorm.weight: found shape torch.Size([768]) in the checkpoint and torch.Size([252]) in the model instantiated\n",
            "- bert.encoder.layer.6.output.LayerNorm.bias: found shape torch.Size([768]) in the checkpoint and torch.Size([252]) in the model instantiated\n",
            "- bert.encoder.layer.7.attention.self.query.weight: found shape torch.Size([768, 768]) in the checkpoint and torch.Size([252, 252]) in the model instantiated\n",
            "- bert.encoder.layer.7.attention.self.query.bias: found shape torch.Size([768]) in the checkpoint and torch.Size([252]) in the model instantiated\n",
            "- bert.encoder.layer.7.attention.self.key.weight: found shape torch.Size([768, 768]) in the checkpoint and torch.Size([252, 252]) in the model instantiated\n",
            "- bert.encoder.layer.7.attention.self.key.bias: found shape torch.Size([768]) in the checkpoint and torch.Size([252]) in the model instantiated\n",
            "- bert.encoder.layer.7.attention.self.value.weight: found shape torch.Size([768, 768]) in the checkpoint and torch.Size([252, 252]) in the model instantiated\n",
            "- bert.encoder.layer.7.attention.self.value.bias: found shape torch.Size([768]) in the checkpoint and torch.Size([252]) in the model instantiated\n",
            "- bert.encoder.layer.7.attention.output.dense.weight: found shape torch.Size([768, 768]) in the checkpoint and torch.Size([252, 252]) in the model instantiated\n",
            "- bert.encoder.layer.7.attention.output.dense.bias: found shape torch.Size([768]) in the checkpoint and torch.Size([252]) in the model instantiated\n",
            "- bert.encoder.layer.7.attention.output.LayerNorm.weight: found shape torch.Size([768]) in the checkpoint and torch.Size([252]) in the model instantiated\n",
            "- bert.encoder.layer.7.attention.output.LayerNorm.bias: found shape torch.Size([768]) in the checkpoint and torch.Size([252]) in the model instantiated\n",
            "- bert.encoder.layer.7.intermediate.dense.weight: found shape torch.Size([3072, 768]) in the checkpoint and torch.Size([3072, 252]) in the model instantiated\n",
            "- bert.encoder.layer.7.output.dense.weight: found shape torch.Size([768, 3072]) in the checkpoint and torch.Size([252, 3072]) in the model instantiated\n",
            "- bert.encoder.layer.7.output.dense.bias: found shape torch.Size([768]) in the checkpoint and torch.Size([252]) in the model instantiated\n",
            "- bert.encoder.layer.7.output.LayerNorm.weight: found shape torch.Size([768]) in the checkpoint and torch.Size([252]) in the model instantiated\n",
            "- bert.encoder.layer.7.output.LayerNorm.bias: found shape torch.Size([768]) in the checkpoint and torch.Size([252]) in the model instantiated\n",
            "- bert.encoder.layer.8.attention.self.query.weight: found shape torch.Size([768, 768]) in the checkpoint and torch.Size([252, 252]) in the model instantiated\n",
            "- bert.encoder.layer.8.attention.self.query.bias: found shape torch.Size([768]) in the checkpoint and torch.Size([252]) in the model instantiated\n",
            "- bert.encoder.layer.8.attention.self.key.weight: found shape torch.Size([768, 768]) in the checkpoint and torch.Size([252, 252]) in the model instantiated\n",
            "- bert.encoder.layer.8.attention.self.key.bias: found shape torch.Size([768]) in the checkpoint and torch.Size([252]) in the model instantiated\n",
            "- bert.encoder.layer.8.attention.self.value.weight: found shape torch.Size([768, 768]) in the checkpoint and torch.Size([252, 252]) in the model instantiated\n",
            "- bert.encoder.layer.8.attention.self.value.bias: found shape torch.Size([768]) in the checkpoint and torch.Size([252]) in the model instantiated\n",
            "- bert.encoder.layer.8.attention.output.dense.weight: found shape torch.Size([768, 768]) in the checkpoint and torch.Size([252, 252]) in the model instantiated\n",
            "- bert.encoder.layer.8.attention.output.dense.bias: found shape torch.Size([768]) in the checkpoint and torch.Size([252]) in the model instantiated\n",
            "- bert.encoder.layer.8.attention.output.LayerNorm.weight: found shape torch.Size([768]) in the checkpoint and torch.Size([252]) in the model instantiated\n",
            "- bert.encoder.layer.8.attention.output.LayerNorm.bias: found shape torch.Size([768]) in the checkpoint and torch.Size([252]) in the model instantiated\n",
            "- bert.encoder.layer.8.intermediate.dense.weight: found shape torch.Size([3072, 768]) in the checkpoint and torch.Size([3072, 252]) in the model instantiated\n",
            "- bert.encoder.layer.8.output.dense.weight: found shape torch.Size([768, 3072]) in the checkpoint and torch.Size([252, 3072]) in the model instantiated\n",
            "- bert.encoder.layer.8.output.dense.bias: found shape torch.Size([768]) in the checkpoint and torch.Size([252]) in the model instantiated\n",
            "- bert.encoder.layer.8.output.LayerNorm.weight: found shape torch.Size([768]) in the checkpoint and torch.Size([252]) in the model instantiated\n",
            "- bert.encoder.layer.8.output.LayerNorm.bias: found shape torch.Size([768]) in the checkpoint and torch.Size([252]) in the model instantiated\n",
            "- bert.encoder.layer.9.attention.self.query.weight: found shape torch.Size([768, 768]) in the checkpoint and torch.Size([252, 252]) in the model instantiated\n",
            "- bert.encoder.layer.9.attention.self.query.bias: found shape torch.Size([768]) in the checkpoint and torch.Size([252]) in the model instantiated\n",
            "- bert.encoder.layer.9.attention.self.key.weight: found shape torch.Size([768, 768]) in the checkpoint and torch.Size([252, 252]) in the model instantiated\n",
            "- bert.encoder.layer.9.attention.self.key.bias: found shape torch.Size([768]) in the checkpoint and torch.Size([252]) in the model instantiated\n",
            "- bert.encoder.layer.9.attention.self.value.weight: found shape torch.Size([768, 768]) in the checkpoint and torch.Size([252, 252]) in the model instantiated\n",
            "- bert.encoder.layer.9.attention.self.value.bias: found shape torch.Size([768]) in the checkpoint and torch.Size([252]) in the model instantiated\n",
            "- bert.encoder.layer.9.attention.output.dense.weight: found shape torch.Size([768, 768]) in the checkpoint and torch.Size([252, 252]) in the model instantiated\n",
            "- bert.encoder.layer.9.attention.output.dense.bias: found shape torch.Size([768]) in the checkpoint and torch.Size([252]) in the model instantiated\n",
            "- bert.encoder.layer.9.attention.output.LayerNorm.weight: found shape torch.Size([768]) in the checkpoint and torch.Size([252]) in the model instantiated\n",
            "- bert.encoder.layer.9.attention.output.LayerNorm.bias: found shape torch.Size([768]) in the checkpoint and torch.Size([252]) in the model instantiated\n",
            "- bert.encoder.layer.9.intermediate.dense.weight: found shape torch.Size([3072, 768]) in the checkpoint and torch.Size([3072, 252]) in the model instantiated\n",
            "- bert.encoder.layer.9.output.dense.weight: found shape torch.Size([768, 3072]) in the checkpoint and torch.Size([252, 3072]) in the model instantiated\n",
            "- bert.encoder.layer.9.output.dense.bias: found shape torch.Size([768]) in the checkpoint and torch.Size([252]) in the model instantiated\n",
            "- bert.encoder.layer.9.output.LayerNorm.weight: found shape torch.Size([768]) in the checkpoint and torch.Size([252]) in the model instantiated\n",
            "- bert.encoder.layer.9.output.LayerNorm.bias: found shape torch.Size([768]) in the checkpoint and torch.Size([252]) in the model instantiated\n",
            "- bert.encoder.layer.10.attention.self.query.weight: found shape torch.Size([768, 768]) in the checkpoint and torch.Size([252, 252]) in the model instantiated\n",
            "- bert.encoder.layer.10.attention.self.query.bias: found shape torch.Size([768]) in the checkpoint and torch.Size([252]) in the model instantiated\n",
            "- bert.encoder.layer.10.attention.self.key.weight: found shape torch.Size([768, 768]) in the checkpoint and torch.Size([252, 252]) in the model instantiated\n",
            "- bert.encoder.layer.10.attention.self.key.bias: found shape torch.Size([768]) in the checkpoint and torch.Size([252]) in the model instantiated\n",
            "- bert.encoder.layer.10.attention.self.value.weight: found shape torch.Size([768, 768]) in the checkpoint and torch.Size([252, 252]) in the model instantiated\n",
            "- bert.encoder.layer.10.attention.self.value.bias: found shape torch.Size([768]) in the checkpoint and torch.Size([252]) in the model instantiated\n",
            "- bert.encoder.layer.10.attention.output.dense.weight: found shape torch.Size([768, 768]) in the checkpoint and torch.Size([252, 252]) in the model instantiated\n",
            "- bert.encoder.layer.10.attention.output.dense.bias: found shape torch.Size([768]) in the checkpoint and torch.Size([252]) in the model instantiated\n",
            "- bert.encoder.layer.10.attention.output.LayerNorm.weight: found shape torch.Size([768]) in the checkpoint and torch.Size([252]) in the model instantiated\n",
            "- bert.encoder.layer.10.attention.output.LayerNorm.bias: found shape torch.Size([768]) in the checkpoint and torch.Size([252]) in the model instantiated\n",
            "- bert.encoder.layer.10.intermediate.dense.weight: found shape torch.Size([3072, 768]) in the checkpoint and torch.Size([3072, 252]) in the model instantiated\n",
            "- bert.encoder.layer.10.output.dense.weight: found shape torch.Size([768, 3072]) in the checkpoint and torch.Size([252, 3072]) in the model instantiated\n",
            "- bert.encoder.layer.10.output.dense.bias: found shape torch.Size([768]) in the checkpoint and torch.Size([252]) in the model instantiated\n",
            "- bert.encoder.layer.10.output.LayerNorm.weight: found shape torch.Size([768]) in the checkpoint and torch.Size([252]) in the model instantiated\n",
            "- bert.encoder.layer.10.output.LayerNorm.bias: found shape torch.Size([768]) in the checkpoint and torch.Size([252]) in the model instantiated\n",
            "- bert.encoder.layer.11.attention.self.query.weight: found shape torch.Size([768, 768]) in the checkpoint and torch.Size([252, 252]) in the model instantiated\n",
            "- bert.encoder.layer.11.attention.self.query.bias: found shape torch.Size([768]) in the checkpoint and torch.Size([252]) in the model instantiated\n",
            "- bert.encoder.layer.11.attention.self.key.weight: found shape torch.Size([768, 768]) in the checkpoint and torch.Size([252, 252]) in the model instantiated\n",
            "- bert.encoder.layer.11.attention.self.key.bias: found shape torch.Size([768]) in the checkpoint and torch.Size([252]) in the model instantiated\n",
            "- bert.encoder.layer.11.attention.self.value.weight: found shape torch.Size([768, 768]) in the checkpoint and torch.Size([252, 252]) in the model instantiated\n",
            "- bert.encoder.layer.11.attention.self.value.bias: found shape torch.Size([768]) in the checkpoint and torch.Size([252]) in the model instantiated\n",
            "- bert.encoder.layer.11.attention.output.dense.weight: found shape torch.Size([768, 768]) in the checkpoint and torch.Size([252, 252]) in the model instantiated\n",
            "- bert.encoder.layer.11.attention.output.dense.bias: found shape torch.Size([768]) in the checkpoint and torch.Size([252]) in the model instantiated\n",
            "- bert.encoder.layer.11.attention.output.LayerNorm.weight: found shape torch.Size([768]) in the checkpoint and torch.Size([252]) in the model instantiated\n",
            "- bert.encoder.layer.11.attention.output.LayerNorm.bias: found shape torch.Size([768]) in the checkpoint and torch.Size([252]) in the model instantiated\n",
            "- bert.encoder.layer.11.intermediate.dense.weight: found shape torch.Size([3072, 768]) in the checkpoint and torch.Size([3072, 252]) in the model instantiated\n",
            "- bert.encoder.layer.11.output.dense.weight: found shape torch.Size([768, 3072]) in the checkpoint and torch.Size([252, 3072]) in the model instantiated\n",
            "- bert.encoder.layer.11.output.dense.bias: found shape torch.Size([768]) in the checkpoint and torch.Size([252]) in the model instantiated\n",
            "- bert.encoder.layer.11.output.LayerNorm.weight: found shape torch.Size([768]) in the checkpoint and torch.Size([252]) in the model instantiated\n",
            "- bert.encoder.layer.11.output.LayerNorm.bias: found shape torch.Size([768]) in the checkpoint and torch.Size([252]) in the model instantiated\n",
            "- bert.pooler.dense.weight: found shape torch.Size([768, 768]) in the checkpoint and torch.Size([252, 252]) in the model instantiated\n",
            "- bert.pooler.dense.bias: found shape torch.Size([768]) in the checkpoint and torch.Size([252]) in the model instantiated\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "#  (3)モデルのEmbedding層の次元を削減することで、パラメータ数を減らし、モデルを軽量化\n",
        "from transformers import AutoModel, AutoConfig\n",
        "\n",
        "config = AutoConfig.from_pretrained(checkpoint, hidden_size=252)  # 例えば256次元に変更->multiples of 12, 252 -> 事前学習済みモデルの重みとモデル構造のサイズが一致しない\n",
        "model = AutoModel.from_pretrained(checkpoint, config=config, ignore_mismatched_sizes=True) #ignore_mismatched_sizes=Trueを追加->次元の不一致を無視してモデルを読み込む"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81,
          "referenced_widgets": [
            "7d015d06d74e4598a73d22f84b0185c8",
            "9eb48618edbe42748b184ca96cca60db",
            "86e5bdcf84a341d9bdd32d72660ed387",
            "082681b0dd7040048427ed5c861fa3ac",
            "ee35170d37fa4a0ba721800912fdbc25",
            "172f88d91a444833867e9dbb31d52274",
            "a3d3fec0163141ecb7826cd4099b6fe9",
            "729eb716e1214709b43fe66c920330e7",
            "316df9767ddd4d48b39e0052946e2547",
            "4ea653a948c74689ad053b9817afa566",
            "ba8f3b8f5f7c46c18cffc82c399b1dbd",
            "60260c685bb142829572d5c646a3145b",
            "6b373d574a094cf990373c98d0fa8ede",
            "f45167c9ff7f420b9f5d0238ad4f45b1",
            "272423ff61754e159807936eb016c70f",
            "0ae278f1821b4899b9434287bd0c1f69",
            "f4ddb37ac0a24eb2b50cb4713a72d70b",
            "dea786df607a4d3a895f1f1a9f01f20b",
            "4f5d262094f8444eb7856127075e7396",
            "1a5da83170a74acaa3c07e107ada9b1c",
            "da865d232f52416e92932c9882c25470",
            "cd1285e136124c299b0377fb90c2bbcd"
          ]
        },
        "id": "rYUy4lfSW348",
        "outputId": "01815ceb-a8f9-4a03-ecc8-ed087ab423d7"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7d015d06d74e4598a73d22f84b0185c8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/17104 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "60260c685bb142829572d5c646a3145b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/1133 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# 前処理関数: tokenize_function\n",
        "# 感情強度の正規化（総和=1）も同時に実施する\n",
        "def tokenize_function(batch):\n",
        "    tokenized_batch = tokenizer(batch['Sentence'], truncation=True, padding='max_length', return_tensors=\"pt\")\n",
        "    tokenized_batch['labels'] = [x / np.sum(x) for x in batch['readers_emotion_intensities']]  # 総和=1に正規化\n",
        "    return tokenized_batch\n",
        "\n",
        "# Transformers用のデータセット形式に変換\n",
        "# pandas.DataFrame -> datasets.Dataset\n",
        "target_columns = ['Sentence', 'readers_emotion_intensities']\n",
        "train_dataset = Dataset.from_pandas(df_train[target_columns])\n",
        "test_dataset = Dataset.from_pandas(df_test[target_columns])\n",
        "\n",
        "# 前処理（tokenize_function） を適用\n",
        "train_tokenized_dataset = train_dataset.map(tokenize_function, batched=True)\n",
        "test_tokenized_dataset = test_dataset.map(tokenize_function, batched=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pVvE_1GAXEFa",
        "outputId": "a843a9ca-c844-448b-f6f1-23ee7daa92cd"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:72: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at cl-tohoku/bert-base-japanese-whole-word-masking and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "# 分類モデルのため AutoModelForSequenceClassification を使用する\n",
        "# checkpoint と num_labels（クラス数） を指定する. 今回は、いずれも上で定義済み\n",
        "# - checkpoint = 'cl-tohoku/bert-base-japanese-whole-word-masking'\n",
        "# - num_labels = 8\n",
        "model = AutoModelForSequenceClassification.from_pretrained(checkpoint, num_labels=num_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3yjZJH7iUInl",
        "outputId": "92713b63-313e-4074-90c4-82a8eb8e60e7"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-21-175910f6c859>:3: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library 🤗 Evaluate: https://huggingface.co/docs/evaluate\n",
            "  metric = load_metric(\"accuracy\")\n",
            "/usr/local/lib/python3.10/dist-packages/datasets/load.py:752: FutureWarning: The repository for accuracy contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.16.1/metrics/accuracy/accuracy.py\n",
            "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
            "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "# 評価指標を定義\n",
        "# https://huggingface.co/docs/transformers/training\n",
        "metric = load_metric(\"accuracy\")\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    logits, labels = eval_pred\n",
        "    predictions = np.argmax(logits, axis=-1)\n",
        "    label_ids = np.argmax(labels, axis=-1)\n",
        "    return metric.compute(predictions=predictions, references=label_ids)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_yrBIv5SYXPN",
        "outputId": "33e1a5ba-4c9b-43dd-8661-cb2c3a7a6bac"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers[torch] in /usr/local/lib/python3.10/dist-packages (4.36.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.20.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.15.0)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.4.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (4.66.1)\n",
            "Requirement already satisfied: torch!=1.12.0,>=1.10 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2.1.0+cu121)\n",
            "Requirement already satisfied: accelerate>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.25.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.21.0->transformers[torch]) (5.9.5)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers[torch]) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers[torch]) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.10->transformers[torch]) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.10->transformers[torch]) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.10->transformers[torch]) (3.1.2)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.10->transformers[torch]) (2.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (2023.11.17)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch!=1.12.0,>=1.10->transformers[torch]) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch!=1.12.0,>=1.10->transformers[torch]) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "! pip install transformers[torch]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JlcA10eAUInl"
      },
      "outputs": [],
      "source": [
        "# # Transformers の Trainer を用いる\n",
        "# # https://huggingface.co/docs/transformers/v4.21.1/en/main_classes/trainer#transformers.TrainingArguments\n",
        "\n",
        "# # 訓練時の設定\n",
        "# training_args = TrainingArguments(\n",
        "#     output_dir=\"test_trainer\",\n",
        "#     per_device_train_batch_size=8\n",
        "#     num_train_epochs=1.0,\n",
        "#     evaluation_strategy=\"steps\", eval_steps=200)  # 200ステップ毎にテストデータで評価する\n",
        "\n",
        "# # Trainerを生成\n",
        "# trainer = Trainer(\n",
        "#     model=model,\n",
        "#     args=training_args,\n",
        "#     train_dataset=train_tokenized_dataset,\n",
        "#     eval_dataset=test_tokenized_dataset,\n",
        "#     compute_metrics=compute_metrics,\n",
        "# )\n",
        "\n",
        "# # 訓練を実行\n",
        "# trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lWyzO7GrUdv6",
        "outputId": "db8c072a-4cc0-44f2-ee55-fd0376e63737"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name: accelerate\n",
            "Version: 0.25.0\n",
            "Summary: Accelerate\n",
            "Home-page: https://github.com/huggingface/accelerate\n",
            "Author: The HuggingFace team\n",
            "Author-email: sylvain@huggingface.co\n",
            "License: Apache\n",
            "Location: /usr/local/lib/python3.10/dist-packages\n",
            "Requires: huggingface-hub, numpy, packaging, psutil, pyyaml, safetensors, torch\n",
            "Required-by: \n"
          ]
        }
      ],
      "source": [
        "# \"Using the `Trainer` with `PyTorch` requires `accelerate>=0.20.1`: Please run `pip install transformers[torch]` or `pip install accelerate -U`\"\n",
        "# (1) バージョン確認->ある\n",
        "! pip show accelerate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nxQoO-n7UkXD",
        "outputId": "51aa82b9-849d-4f90-8c6e-bb611a17f227"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers[torch] in /usr/local/lib/python3.10/dist-packages (4.36.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.20.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.15.0)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.4.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (4.66.1)\n",
            "Requirement already satisfied: torch!=1.12.0,>=1.10 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2.1.0+cu121)\n",
            "Requirement already satisfied: accelerate>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.25.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.21.0->transformers[torch]) (5.9.5)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers[torch]) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers[torch]) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.10->transformers[torch]) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.10->transformers[torch]) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.10->transformers[torch]) (3.1.2)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.10->transformers[torch]) (2.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (2023.11.17)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch!=1.12.0,>=1.10->transformers[torch]) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch!=1.12.0,>=1.10->transformers[torch]) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "# \"Using the `Trainer` with `PyTorch` requires `accelerate>=0.20.1`: Please run `pip install transformers[torch]` or `pip install accelerate -U`\"\n",
        "# (2) キャッシュをクリアしてから再度実行->同じエラー\n",
        "! pip install --no-cache-dir transformers[torch]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dhfjMBOLYpC0",
        "outputId": "572b2a29-81c5-40a3-9a60-cb4fa77ac600"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:429: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "from transformers import AdamW, get_linear_schedule_with_warmup\n",
        "\n",
        "# AdamWオプティマイザの定義\n",
        "optimizer = AdamW(model.parameters(), lr=2e-5)  # lrは学習率,これがデフォルト"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0XgW1vBSZCU0"
      },
      "outputs": [],
      "source": [
        "def tokenize_batch(batch):\n",
        "    return tokenizer(batch['Sentence'], truncation=True, padding=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "14dycdV2bUS2",
        "outputId": "5501712f-6280-48d9-efe6-ef856f304c2b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.36.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.0)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.11.17)\n"
          ]
        }
      ],
      "source": [
        "#Trainer.__init__() got an unexpected keyword argument 'lr_scheduler' -> transformersが最新バージョンかチェック\n",
        "! pip install transformers --upgrade"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "URRD-mLqhNpl"
      },
      "source": [
        "\n",
        "     36 # 訓練を実行\n",
        "---> 37 trainer.train()\n",
        "\n",
        "7 frames\n",
        "/usr/local/lib/python3.10/dist-packages/transformers/data/data_collator.py in torch_default_data_collator(features)\n",
        "    134                 batch[k] = torch.tensor(np.stack([f[k] for f in features]))\n",
        "    135             else:\n",
        "--> 136                 batch[k] = torch.tensor([f[k] for f in features])\n",
        "    137\n",
        "    138     return batch\n",
        "\n",
        "ValueError: expected sequence of length 112 at dim 1 (got 97)\n",
        "\n",
        "\n",
        "このエラーは、torch_default_data_collator内のデータコレーションの過程で、シーケンスの次元が予想よりも短いものが含まれていることを示しています。特定のフィーチャが予想よりも短い場合、PyTorchのtorch.tensor()が期待する次元に達していない可能性があります。\n",
        "\n",
        "エラーの原因を特定するために、以下の点を確認してみてください：\n",
        "\n",
        "(1) train_tokenized_datasetおよびtest_tokenized_datasetの中の各サンプルのフィーチャの長さが一様であるかどうかを確認してください。データセット内で異なる次元のデータが混在している可能性があります。->トリミングを行う->同じエラー\n",
        "\n",
        "(2) トークン化されたデータセットが正しく行われており、予期せぬデータが混入していないかを確認してください。異なるサンプルのフィーチャが予期せぬ次元である場合、データの前処理に問題があるかもしれません。->トークン数をそろえる->同じエラー\n",
        "\n",
        "(3) トークン化されたデータセットがPyTorchテンソルに変換される際に、不適切なサイズのテンソルが生成されていないか確認してください。->トークン化されたデータセットをPyTorchテンソルに変換し、そのサイズを確認->問題なし"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ycbPa64CiG6N"
      },
      "outputs": [],
      "source": [
        "# (1)\n",
        "#データセット内の各サンプルのSentenceを同じ長さに調整する\n",
        "# パディングを行うか、あるいはトリミングを行う\n",
        "max_length = 50  # 調整後の最大長さ\n",
        "\n",
        "# Sentenceを指定した長さにトリミングする関数\n",
        "def trim_sentence(sample, tokenizer, max_length):\n",
        "    # Sentenceをトークン化\n",
        "    tokens = tokenizer(\n",
        "        sample['Sentence'],\n",
        "        max_length=max_length,\n",
        "        truncation=True,\n",
        "        padding='max_length'  # パディングもmax_lengthに合わせる\n",
        "    )\n",
        "\n",
        "    # トリミング後のトークンを元のフィーチャに反映\n",
        "    sample['input_ids'] = tokens['input_ids'][:max_length]\n",
        "    sample['attention_mask'] = tokens['attention_mask'][:max_length]\n",
        "\n",
        "    return sample\n",
        "\n",
        "# トリミングを適用\n",
        "trimmed_train_tokenized_dataset = [trim_sentence(sample, tokenizer, max_length) for sample in train_tokenized_dataset]\n",
        "trimmed_test_tokenized_dataset = [trim_sentence(sample, tokenizer, max_length) for sample in test_tokenized_dataset]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ATI5wZfDhWNM",
        "outputId": "5310a33f-61da-4556-b868-bd72f042b024"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "50\n",
            "50\n",
            "50\n",
            "50\n",
            "50\n",
            "50\n",
            "50\n",
            "50\n",
            "50\n",
            "50\n"
          ]
        }
      ],
      "source": [
        "# トリミング後のトークン数を表示\n",
        "for sample in trimmed_train_tokenized_dataset[:5]:\n",
        "    print(len(sample['input_ids']))\n",
        "\n",
        "for sample in trimmed_test_tokenized_dataset[:5]:\n",
        "    print(len(sample['input_ids']))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jGRUlK4fjGdA",
        "outputId": "1708f1be-2960-4f77-8680-a22cc13c3d1d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Sentence': '吐瀉物が落ちている、TOKYO', 'readers_emotion_intensities': [0, 1, 0, 0, 0, 0, 2, 0], '__index_level_0__': 1440, 'input_ids': [2, 1, 410, 14, 3024, 16, 33, 6, 10713, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}\n",
            "{'Sentence': '夫、GWの事何も言わなくなったから断念したのかな。(性格上言えばムキになると思うので、私からは土曜からその話題を振ってない)', 'readers_emotion_intensities': [1, 0, 2, 0, 0, 0, 0, 0], '__index_level_0__': 5363, 'input_ids': [2, 1532, 6, 383, 28865, 5, 146, 1037, 28, 1653, 332, 58, 10, 40, 8307, 15, 10, 5, 29, 18, 8, 23, 3961, 109, 5498, 312, 1335, 28580, 28446, 2641, 13, 7105, 947, 6, 1325, 40, 9, 6637, 40, 59, 4459, 11, 22608, 16, 80, 24, 3, 0, 0, 0], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]}\n",
            "{'Sentence': 'あんな至近距離でチアのダンス見せられたら、見よる方が恥ずかしなったがな。( ??ω?? )', 'readers_emotion_intensities': [1, 0, 0, 2, 0, 0, 0, 0], '__index_level_0__': 12795, 'input_ids': [2, 9039, 28462, 20353, 2377, 12, 25763, 5, 4460, 2685, 84, 3318, 6, 212, 1517, 283, 14, 12650, 2922, 28454, 58, 10, 14, 18, 8, 23, 2935, 29805, 1, 2935, 29805, 24, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}\n",
            "{'Sentence': 'ゆずと潘さん(^O^)いやー、買うしかないよね!!発売かもん!!', 'readers_emotion_intensities': [1, 0, 2, 0, 0, 0, 0, 0], '__index_level_0__': 13841, 'input_ids': [2, 26879, 13, 1, 2375, 23, 31737, 681, 1, 17989, 28451, 6, 16941, 278, 80, 54, 1852, 3421, 580, 4830, 1058, 3421, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}\n",
            "{'Sentence': '旅行関連の記事は全滅だが、家で楽しむ系の記事が生き残ってくれたー！', 'readers_emotion_intensities': [2, 0, 0, 0, 0, 0, 0, 0], '__index_level_0__': 40475, 'input_ids': [2, 3807, 1634, 5, 2622, 9, 16635, 75, 14, 6, 167, 12, 11453, 384, 5, 2622, 14, 14310, 16, 4831, 10, 3871, 679, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}\n"
          ]
        }
      ],
      "source": [
        "# (2)\n",
        "import random\n",
        "\n",
        "# ランダムなサンプルを表示\n",
        "for sample in random.sample(list(trimmed_train_tokenized_dataset), 5):\n",
        "    print(sample)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rHklqkGPjb_Y",
        "outputId": "a2979724-7cb6-4df3-aea7-acba579291c0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "50\n",
            "50\n",
            "50\n",
            "50\n",
            "50\n"
          ]
        }
      ],
      "source": [
        "# トークンの数を表示\n",
        "for sample in random.sample(list(trimmed_train_tokenized_dataset), 5):\n",
        "    print(len(sample['input_ids']))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tCDwLdvwoUJr",
        "outputId": "f3dab4f9-a82f-40f5-e0d3-80fea4f8079a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "input_ids size: torch.Size([17104, 50])\n",
            "attention_mask size: torch.Size([17104, 50])\n"
          ]
        }
      ],
      "source": [
        "# (3)\n",
        "\n",
        "import torch\n",
        "\n",
        "# トークン化されたデータセット（例としてtrimmed_datasetを使用）\n",
        "# （trimmed_datasetは辞書のリストであると仮定）\n",
        "tokenized_tensors = {\n",
        "    'input_ids': torch.tensor([sample['input_ids'] for sample in trimmed_train_tokenized_dataset]),\n",
        "    'attention_mask': torch.tensor([sample['attention_mask'] for sample in trimmed_train_tokenized_dataset]),\n",
        "    # 他のトークン化された特徴も追加する\n",
        "}\n",
        "\n",
        "# 各テンソルのサイズを確認\n",
        "for key, tensor in tokenized_tensors.items():\n",
        "    print(f\"{key} size: {tensor.size()}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sxw5vhmboy60"
      },
      "source": [
        "各サンプルが同じ次元数の特徴を持っているか"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9spZrfaDpdV3"
      },
      "source": [
        "データコレーターの処理で何かしらの不備が生じている->データコレーターに手動で調整を加えるか、または他のデータコレーターを検討する\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z97HVe7PQeeP"
      },
      "outputs": [],
      "source": [
        "from transformers import get_linear_schedule_with_warmup\n",
        "\n",
        "# トレーニング時の設定\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"test_trainer\",\n",
        "    per_device_train_batch_size=7,\n",
        "    num_train_epochs=0.9,\n",
        "    evaluation_strategy=\"steps\",\n",
        "    eval_steps=200,\n",
        "    lr_scheduler_type=\"linear\",  # スケジューラのタイプを指定\n",
        ")\n",
        "\n",
        "# Trainerを生成（schedulerの設定はTrainerの前に行う）\n",
        "# train_tokenized_dataset = train_dataset.map(tokenize_batch, batched=True)\n",
        "# test_tokenized_dataset = test_dataset.map(tokenize_batch, batched=True)\n",
        "\n",
        "# 学習率のスケジューラの設定\n",
        "num_training_steps = len(train_tokenized_dataset) // training_args.per_device_train_batch_size * training_args.num_train_epochs\n",
        "warmup_steps = int(0.1 * num_training_steps)\n",
        "scheduler = get_linear_schedule_with_warmup(\n",
        "    optimizer,\n",
        "    num_warmup_steps=warmup_steps,\n",
        "    num_training_steps=num_training_steps\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_rtjupVPsF3G"
      },
      "outputs": [],
      "source": [
        "from torch import nn\n",
        "from transformers import Trainer\n",
        "\n",
        "class CustomTrainer(Trainer):\n",
        "    def compute_loss(self, model, inputs, return_outputs=False):\n",
        "        labels = inputs.get(\"labels\", None)\n",
        "\n",
        "        if labels is None:\n",
        "            if \"labels\" not in inputs or inputs[\"labels\"] is None:\n",
        "                raise ValueError(\"Labels are missing or None in the inputs during training.\")\n",
        "            else:\n",
        "                labels = inputs[\"labels\"]\n",
        "\n",
        "        # モデルのフォワードパス\n",
        "        outputs = model(**inputs)\n",
        "\n",
        "        # logitsから損失を計算\n",
        "        loss = nn.CrossEntropyLoss()(outputs.logits, labels)\n",
        "\n",
        "        if return_outputs:\n",
        "            return (loss, outputs)\n",
        "        else:\n",
        "            return loss.item() if hasattr(loss, \"item\") else loss\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WniOb5Nyy3jq"
      },
      "source": [
        "labelsがトレーニング中に欠落しているというエラーは、トレーニングデータセットにlabelsが正しく含まれていない可能性があります。以下の点を確認してください。\n",
        "\n",
        "1 トレーニングデータセットにlabelsが正しく含まれているか確認してください。各サンプルに対してlabelsが与えられている必要があります。\n",
        "\n",
        "2 トークナイザーを適切に適用しているか確認してください。トークン化されたデータセットにlabelsが適切に含まれていることが必要です。\n",
        "\n",
        "3 CustomTrainerを初期化する際に、train_dataset引数にトレーニングデータセットを指定していますか？\n",
        "\n",
        "例えば、トレーニングデータセットの各サンプルが辞書としてinput_idsとlabelsをキーとして持っている場合、以下のようなトレーニングデータセットを作成してCustomTrainerに渡すことが考えられます。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ugsMTBfTy-qF",
        "outputId": "375833a7-2bf1-49be-d325-a3d0f3ea9325"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sample 1:\n",
            "{'Sentence': 'ぼけっとしてたらこんな時間｡チャリあるから食べにでたいのに…', 'readers_emotion_intensities': [0, 2, 0, 0, 0, 0, 0, 0], '__index_level_0__': 0, 'input_ids': [2, 3937, 28517, 26099, 15, 16, 3318, 12272, 640, 8, 1131, 28479, 31, 40, 2949, 7, 12, 1549, 5602, 3215, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}\n",
            "\n",
            "Sample 2:\n",
            "{'Sentence': '今日の月も白くて明るい。昨日より雲が少なくてキレイな? と立ち止まる帰り道｡チャリなし生活も悪くない｡', 'readers_emotion_intensities': [1, 0, 0, 2, 0, 0, 0, 0], '__index_level_0__': 1, 'input_ids': [2, 3246, 5, 37, 28, 21845, 16, 10820, 8, 10271, 28486, 221, 3436, 14, 2451, 16, 185, 721, 18, 2935, 13, 2021, 28957, 1649, 10766, 28622, 8, 1131, 28479, 3350, 1326, 28, 8734, 80, 8, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}\n",
            "\n",
            "Sample 3:\n",
            "{'Sentence': 'やばい｡おもろいな?思ってみてみた「シャレードがいっぱい」｡よすぎるやん。', 'readers_emotion_intensities': [2, 0, 0, 0, 0, 0, 0, 0], '__index_level_0__': 6, 'input_ids': [2, 49, 26635, 8, 5925, 28828, 28457, 18, 2935, 4479, 16, 546, 16, 546, 10, 36, 1479, 8299, 14, 15890, 38, 8, 54, 8896, 49, 28575, 8, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}\n",
            "\n",
            "Sample 4:\n",
            "{'Sentence': 'おなかすいた…夜ご飯仲間募集｡', 'readers_emotion_intensities': [0, 0, 2, 0, 0, 0, 0, 0], '__index_level_0__': 7, 'input_ids': [2, 73, 7914, 14617, 10, 3215, 1563, 27073, 3587, 6353, 8, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}\n",
            "\n",
            "Sample 5:\n",
            "{'Sentence': '最近アップにしていたので気づかなかったけど、ちゃんとブローしたらモテキ小宮山夏樹(後期)に似てきてる｡この感じ定着したらパーマしよ。', 'readers_emotion_intensities': [1, 0, 2, 0, 0, 0, 0, 0], '__index_level_0__': 9, 'input_ids': [2, 5233, 3091, 7, 15, 16, 21, 10, 947, 22387, 316, 10, 11218, 6, 26591, 12086, 15, 3318, 249, 28522, 28580, 160, 28999, 28646, 1428, 29545, 23, 3143, 24, 7, 2407, 16, 322, 7134, 8, 70, 3415, 5231, 15, 3318, 24843, 15, 54, 8, 3, 0, 0, 0, 0, 0], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]}\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#1\n",
        "# トレーニングデータセットの最初の数サンプルを確認\n",
        "for i in range(min(5, len(trimmed_train_tokenized_dataset))):\n",
        "    sample = trimmed_train_tokenized_dataset[i]\n",
        "    print(f\"Sample {i + 1}:\\n{sample}\\n\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 360
        },
        "id": "pPFXdSaksJlw",
        "outputId": "51d0bbdf-bfac-4d89-93c3-95fe02cfe304"
      },
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "Labels are missing or None in the inputs during training.",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-124-9e063b7f59f6>\u001b[0m in \u001b[0;36m<cell line: 13>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# 訓練を実行\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mcustom_trainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1535\u001b[0m                 \u001b[0mhf_hub_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_progress_bars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1536\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1537\u001b[0;31m             return inner_training_loop(\n\u001b[0m\u001b[1;32m   1538\u001b[0m                 \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1539\u001b[0m                 \u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   1852\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1853\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccelerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccumulate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1854\u001b[0;31m                     \u001b[0mtr_loss_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1855\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1856\u001b[0m                 if (\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtraining_step\u001b[0;34m(self, model, inputs)\u001b[0m\n\u001b[1;32m   2733\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2734\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_loss_context_manager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2735\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2736\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2737\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_gpu\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-122-8d5ca70d35b2>\u001b[0m in \u001b[0;36mcompute_loss\u001b[0;34m(self, model, inputs, return_outputs)\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;34m\"labels\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"labels\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Labels are missing or None in the inputs during training.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m                 \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"labels\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Labels are missing or None in the inputs during training."
          ]
        }
      ],
      "source": [
        "# 通常のTrainerと同様の引数を指定して、CustomTrainerを初期化する\n",
        "custom_trainer = CustomTrainer(\n",
        "    model=model,                        # トレーニングするモデル\n",
        "    args=training_args,                  # トレーニングの設定\n",
        "    train_dataset=trimmed_train_tokenized_dataset,  # トレーニングデータセット\n",
        "    eval_dataset=trimmed_test_tokenized_dataset,    # 評価データセット\n",
        "    compute_metrics=compute_metrics,     # メトリクスの計算関数\n",
        "    data_collator=pad_collate,  # パディングを行うデータコレーターを指定\n",
        "    optimizers=(optimizer, scheduler)    # カスタムTrainerにはoptimizerとschedulerをタプルで渡す\n",
        ")\n",
        "\n",
        "# 訓練を実行\n",
        "custom_trainer.train()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-h0tclaxUInm"
      },
      "outputs": [],
      "source": [
        "# https://www.delftstack.com/ja/howto/numpy/numpy-softmax/\n",
        "def np_softmax(x):\n",
        "    f_x = np.exp(x) / np.sum(np.exp(x))\n",
        "    return f_x\n",
        "\n",
        "def analyze_emotion(text, show_fig=False, ret_prob=False):\n",
        "    # 推論モードを有効化\n",
        "    model.eval()\n",
        "\n",
        "    # 入力データ変換 + 推論\n",
        "    tokens = tokenizer(text, truncation=True, return_tensors=\"pt\")\n",
        "    tokens.to(model.device)\n",
        "    preds = model(**tokens)\n",
        "    prob = np_softmax(preds.logits.cpu().detach().numpy()[0])\n",
        "    out_dict = {n: p for n, p in zip(emotion_names_jp, prob)}\n",
        "\n",
        "    # 棒グラフを描画\n",
        "    if show_fig:\n",
        "        plt.figure(figsize=(8, 3))\n",
        "        df = pd.DataFrame(out_dict.items(), columns=['name', 'prob'])\n",
        "        sns.barplot(x='name', y='prob', data=df)\n",
        "        plt.title('入力文 : ' + text, fontsize=15)\n",
        "\n",
        "    if ret_prob:\n",
        "        return out_dict\n",
        "\n",
        "# 動作確認\n",
        "analyze_emotion('今日から長期休暇だぁーーー！！！', show_fig=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TmI5b0LdUInm"
      },
      "outputs": [],
      "source": [
        "analyze_emotion('この書類にはコーヒーかかってなくて良かった…。不幸中の幸いだ。', show_fig=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NN7HD39tXhrn"
      },
      "outputs": [],
      "source": [
        "analyze_emotion('なんで自分だけこんな目に遭うんだ……', show_fig=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sfhyeuHWXlZz"
      },
      "outputs": [],
      "source": [
        "analyze_emotion('君ならきっとやってくれると思っていたよ！', show_fig=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JieaUWipXnTP"
      },
      "outputs": [],
      "source": [
        "analyze_emotion('え、今日って休校だったの？', show_fig=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XKoAmqYlXpaj"
      },
      "outputs": [],
      "source": [
        "analyze_emotion('明日のプレゼンうまくできるかなぁ…', show_fig=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H824mByPXrJL"
      },
      "outputs": [],
      "source": [
        "analyze_emotion('あぁー、イライラするっ！！', show_fig=True)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.1"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "082681b0dd7040048427ed5c861fa3ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4ea653a948c74689ad053b9817afa566",
            "placeholder": "​",
            "style": "IPY_MODEL_ba8f3b8f5f7c46c18cffc82c399b1dbd",
            "value": " 17104/17104 [00:22&lt;00:00, 761.33 examples/s]"
          }
        },
        "0ae278f1821b4899b9434287bd0c1f69": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "172f88d91a444833867e9dbb31d52274": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1a5da83170a74acaa3c07e107ada9b1c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "272423ff61754e159807936eb016c70f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_da865d232f52416e92932c9882c25470",
            "placeholder": "​",
            "style": "IPY_MODEL_cd1285e136124c299b0377fb90c2bbcd",
            "value": " 1133/1133 [00:00&lt;00:00, 1510.73 examples/s]"
          }
        },
        "316df9767ddd4d48b39e0052946e2547": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4ea653a948c74689ad053b9817afa566": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4f5d262094f8444eb7856127075e7396": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "60260c685bb142829572d5c646a3145b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6b373d574a094cf990373c98d0fa8ede",
              "IPY_MODEL_f45167c9ff7f420b9f5d0238ad4f45b1",
              "IPY_MODEL_272423ff61754e159807936eb016c70f"
            ],
            "layout": "IPY_MODEL_0ae278f1821b4899b9434287bd0c1f69"
          }
        },
        "6b373d574a094cf990373c98d0fa8ede": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f4ddb37ac0a24eb2b50cb4713a72d70b",
            "placeholder": "​",
            "style": "IPY_MODEL_dea786df607a4d3a895f1f1a9f01f20b",
            "value": "Map: 100%"
          }
        },
        "729eb716e1214709b43fe66c920330e7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7d015d06d74e4598a73d22f84b0185c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9eb48618edbe42748b184ca96cca60db",
              "IPY_MODEL_86e5bdcf84a341d9bdd32d72660ed387",
              "IPY_MODEL_082681b0dd7040048427ed5c861fa3ac"
            ],
            "layout": "IPY_MODEL_ee35170d37fa4a0ba721800912fdbc25"
          }
        },
        "86e5bdcf84a341d9bdd32d72660ed387": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_729eb716e1214709b43fe66c920330e7",
            "max": 17104,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_316df9767ddd4d48b39e0052946e2547",
            "value": 17104
          }
        },
        "9eb48618edbe42748b184ca96cca60db": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_172f88d91a444833867e9dbb31d52274",
            "placeholder": "​",
            "style": "IPY_MODEL_a3d3fec0163141ecb7826cd4099b6fe9",
            "value": "Map: 100%"
          }
        },
        "a3d3fec0163141ecb7826cd4099b6fe9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ba8f3b8f5f7c46c18cffc82c399b1dbd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cd1285e136124c299b0377fb90c2bbcd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "da865d232f52416e92932c9882c25470": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dea786df607a4d3a895f1f1a9f01f20b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ee35170d37fa4a0ba721800912fdbc25": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f45167c9ff7f420b9f5d0238ad4f45b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4f5d262094f8444eb7856127075e7396",
            "max": 1133,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1a5da83170a74acaa3c07e107ada9b1c",
            "value": 1133
          }
        },
        "f4ddb37ac0a24eb2b50cb4713a72d70b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
