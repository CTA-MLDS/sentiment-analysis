{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CTA-MLDS/sentiment-analysis/blob/main/data_set_processing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nkZLAbNbUInd"
      },
      "outputs": [],
      "source": [
        "! pip install transformers datasets"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install transformers --upgrade"
      ],
      "metadata": {
        "id": "wEuDWZh38G6K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TFBeR-taUIng"
      },
      "outputs": [],
      "source": [
        "! pip install fugashi ipadic"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6qA72unnUInh"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7KtLWdhuUInh"
      },
      "outputs": [],
      "source": [
        "# Hugging Face (Transformers) 関連のモジュール\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "from transformers import TrainingArguments, Trainer\n",
        "from datasets import Dataset, load_metric"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0A7oeix9UIni"
      },
      "outputs": [],
      "source": [
        "# [前準備] Matplotlib で日本語フォントを使用できるようにする\n",
        "# cf. https://blog.3qe.us/entry/2018/08/16/121457\n",
        "!apt-get -y install fonts-ipafont-gothic\n",
        "!rm /root/.cache/matplotlib/fontlist-v310.json\n",
        "# jupyter notebookで動くように書き換え↓\n",
        "# ! pip install matplotlib\n",
        "# ! pip install japanize-matplotlib\n",
        "\n",
        "# NOTE ここで、ランタイムを再起動"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z2SSxznCVFQ5"
      },
      "outputs": [],
      "source": [
        "!sudo apt-get install fonts-ipafont-gothic\n",
        "!sudo fc-cache -fv\n",
        "!rm /root/.cache/matplotlib/fontlist-v310.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Eze6XSk0VOqd"
      },
      "outputs": [],
      "source": [
        "! pip install japanize-matplotlib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wC4a9tDxUInj"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import japanize_matplotlib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "egwBaEh6UInj"
      },
      "outputs": [],
      "source": [
        "# if 'IPAGothic' not in plt.rcParams['font.family']:\n",
        "#     plt.rcParams['font.family'] = 'MS Gothic'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 158
        },
        "id": "nR0VWE4RUInj",
        "outputId": "3da33e23-11fe-45e3-eff9-47347a618dca"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 500x100 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# 動作確認\n",
        "plt.figure(figsize=(5, 1))\n",
        "plt.title('日本語表示、テスト')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JyEZkLerUInj"
      },
      "outputs": [],
      "source": [
        "# GitHubよりWRIMEデータをダウンロードする\n",
        "#\n",
        "# WRIME dataset : https://github.com/ids-cv/wrime\n",
        "# 今回使用するのは ver1 （感情極性が付与されていない版）\n",
        "\n",
        "! wget https://github.com/ids-cv/wrime/raw/master/wrime-ver1.tsv\n",
        "\n",
        "# question to ask\n",
        "# tried to run the command through this cell, didn't work.\n",
        "# installed wget, but couldn't execute the file\n",
        "# manually moved the file to the system32 file of windows and ran the program through cmd (and worked??)\n",
        "\n",
        "# fugashiがインストールできない\n",
        "# -> mecab.hが認識されない -> 通常はincludeサブディレクトリにあるはずだが、代わりにsrcに入っている（そしてincludeは存在していない）\n",
        "# -> mecabを再度インストール -> mecabのバージョンをチェックしたいmecab --versionが、エラー（'mecab' is not recognized as an internal or external command,\n",
        "# operable program or batch file.）-> 環境変数にpathを追加 -> INCLUDE変数も追加 -> やっぱりmecab.hが認識されない\n",
        "# mecabのビルド済みバイナリをインストール　pip install mecab-python-binary　pip install mecab-python3　pip install mecab-python3 --global-option=\"--with-cflags=-IC:\\Users\\minaa\\OneDrive\\TCA\\mecab\\mecab\\mecab\\src\"\n",
        "# fugashiを諦めます\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zTVQyzpXUInk"
      },
      "outputs": [],
      "source": [
        "# pandas.DataFrameとして読み込む\n",
        "df_wrime = pd.read_table('wrime-ver1.tsv')\n",
        "df_wrime.head(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TsdByOjQUInk"
      },
      "outputs": [],
      "source": [
        "emotion_names = ['Joy', 'Sadness', 'Anticipation', 'Surprise', 'Anger', 'Fear', 'Disgust', 'Trust']\n",
        "num_labels = len(emotion_names)\n",
        "# objective emotion average (Avg. Readers_*) values are converted to list, defined as a new column\n",
        "df_wrime['readers_emotion_intensities'] = df_wrime.apply(lambda x: [x['Avg. Readers_' + name] for name in emotion_names], axis=1)\n",
        "\n",
        "# removing samples with less emotion intensities\n",
        "# (max.readers_emotion_intensities must be 2 or more)\n",
        "is_target = df_wrime['readers_emotion_intensities'].map(lambda x: max(x) >= 2)\n",
        "df_wrime_target = df_wrime[is_target]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dApwmsSfUInk"
      },
      "outputs": [],
      "source": [
        "# divide into train and test data\n",
        "df_groups = df_wrime_target.groupby('Train/Dev/Test')\n",
        "df_train = df_groups.get_group('train')\n",
        "df_test = pd.concat([df_groups.get_group('dev'), df_groups.get_group('test')])\n",
        "# print('train :', len(df_train))\n",
        "# print('test :', len(df_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZLTE0nvlWyTz",
        "outputId": "f53df924-f9fb-4a1e-d9d1-7d5f51995035"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:72: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "# 使用するモデルを指定して、Tokenizerを読み込む\n",
        "checkpoint = 'cl-tohoku/bert-base-japanese-whole-word-masking'\n",
        "tokenizer = AutoTokenizer.from_pretrained(checkpoint)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#  (1) 使用するモデルをより簡素なものに\n",
        "# checkpoint = 'distilbert-base-japanese'\n",
        "# tokenizer = AutoTokenizer.from_pretrained(checkpoint)"
      ],
      "metadata": {
        "id": "sAQbFmQyRNNX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# (2) モデルの一部の層を削減して軽量化\n",
        "from transformers import AutoModel, AutoConfig\n",
        "config = AutoConfig.from_pretrained(checkpoint, num_hidden_layers=6)  # 6層に変更\n",
        "model = AutoModel.from_pretrained(checkpoint, config=config)"
      ],
      "metadata": {
        "id": "9fV0ZxsqRbpa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# (3) モデルのEmbedding層の次元を削減\n",
        "config = AutoConfig.from_pretrained(checkpoint, hidden_size=252)\n",
        "model = AutoModel.from_pretrained(checkpoint, config=config, ignore_mismatched_sizes=True)\n"
      ],
      "metadata": {
        "id": "_4OG0RtkRfn_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
        "from transformers import AdamW, get_linear_schedule_with_warmup\n",
        "from datasets import load_metric"
      ],
      "metadata": {
        "id": "I9-WD0oC7q_W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170,
          "referenced_widgets": [
            "4865d29cc23742fba06ee0d4b33ca110",
            "c450e78130b445778392ce5dda42a8be",
            "256352a743374f37b42f68dfdff1048a",
            "b1ed0980406f4f558577e78a08e246a9",
            "f3ac7c37d26a498993363c00cb6f19f4",
            "c590677ca1c04cccb0a382451ef5f61d",
            "4ac7e2327f6c459dbd5ceba4bb696592",
            "06864032e2ad43a3a2975ea39b500d47",
            "8b497efce6ac4ceda52044b5cbde2699",
            "a13965e6a1e64c6ab95f5b18220ee43c",
            "e3e664fc08614659a7e7f8d8b19a6c91",
            "ea859a0d8bc047be9e2d8d13421c3b12",
            "c6b01b65b6f149cfa9a687ab8e6e7fd6",
            "b236d2deb30f4253be20e750aad15e27",
            "aca51aeeac474323abd96a83268b17f4",
            "e926a34caf68404da2eaf625feda82be",
            "9c8a4c95cb7a4e60a523c9d52d99d189",
            "0422e15ad92749cd8d92beb658045cdc",
            "0aacf537e45f41b5a348b3b76cabc058",
            "80206e3f4e7b4d7e89a1bf0495b0db3d",
            "d79f63a487ef437f9c6281b224f989df",
            "305430c960bc400f9f23bdb8a8770ee0"
          ]
        },
        "id": "rYUy4lfSW348",
        "outputId": "03ace149-2b9b-45d8-fe50-df1b663b2579"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Parameter 'function'=<function tokenize_function at 0x781de8300ca0> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.\n",
            "WARNING:datasets.fingerprint:Parameter 'function'=<function tokenize_function at 0x781de8300ca0> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/17104 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4865d29cc23742fba06ee0d4b33ca110"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-22-016af921c8ea>:5: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:261.)\n",
            "  tokenized_batch['labels'] = torch.tensor([x / np.sum(x) for x in batch['readers_emotion_intensities']], dtype=torch.float32)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/1133 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ea859a0d8bc047be9e2d8d13421c3b12"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "# 前処理関数: tokenize_function\n",
        "# 感情強度の正規化（総和=1）も同時に実施する\n",
        "def tokenize_function(batch):\n",
        "    tokenized_batch = tokenizer(batch['Sentence'], truncation=True, padding='max_length', return_tensors=\"pt\")\n",
        "    tokenized_batch['labels'] = torch.tensor([x / np.sum(x) for x in batch['readers_emotion_intensities']], dtype=torch.float32)\n",
        "    return tokenized_batch\n",
        "\n",
        "# Transformers用のデータセット形式に変換\n",
        "# pandas.DataFrame -> datasets.Dataset\n",
        "target_columns = ['Sentence', 'readers_emotion_intensities']\n",
        "train_dataset = Dataset.from_pandas(df_train[target_columns])\n",
        "test_dataset = Dataset.from_pandas(df_test[target_columns])\n",
        "\n",
        "# 前処理（tokenize_function） を適用\n",
        "train_tokenized_dataset = train_dataset.map(tokenize_function, batched=True)\n",
        "test_tokenized_dataset = test_dataset.map(tokenize_function, batched=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pVvE_1GAXEFa"
      },
      "outputs": [],
      "source": [
        "# 分類モデルのため AutoModelForSequenceClassification を使用する\n",
        "# checkpoint と num_labels（クラス数） を指定する. 今回は、いずれも上で定義済み\n",
        "# - checkpoint = 'cl-tohoku/bert-base-japanese-whole-word-masking'\n",
        "# - num_labels = 8\n",
        "config = AutoConfig.from_pretrained(checkpoint, num_labels=8)\n",
        "model = AutoModelForSequenceClassification.from_pretrained(checkpoint)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3yjZJH7iUInl"
      },
      "outputs": [],
      "source": [
        "# 評価指標を定義\n",
        "# https://huggingface.co/docs/transformers/training\n",
        "metric = load_metric(\"accuracy\")\n",
        "def compute_metrics(eval_pred):\n",
        "    logits, labels = eval_pred\n",
        "    predictions = np.argmax(logits, axis=-1)\n",
        "    label_ids = np.argmax(labels, axis=-1)\n",
        "    return metric.compute(predictions=predictions, references=label_ids)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_yrBIv5SYXPN"
      },
      "outputs": [],
      "source": [
        "! pip install transformers[torch]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AdamW, get_linear_schedule_with_warmup\n",
        "\n",
        "# AdamWオプティマイザの定義\n",
        "optimizer = AdamW(model.parameters(), lr=2e-5)  # lrは学習率,これがデフォルト"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dhfjMBOLYpC0",
        "outputId": "f8284c08-9de3-4809-8e2e-648d7d0f9b75"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:429: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize_batch(batch):\n",
        "    return tokenizer(batch['Sentence'], truncation=True, padding=True)"
      ],
      "metadata": {
        "id": "0XgW1vBSZCU0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Trainer.__init__() got an unexpected keyword argument 'lr_scheduler' -> transformersが最新バージョンかチェック\n",
        "! pip install transformers --upgrade"
      ],
      "metadata": {
        "id": "14dycdV2bUS2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# (1)\n",
        "#データセット内の各サンプルのSentenceを同じ長さに調整する\n",
        "# パディングを行うか、あるいはトリミングを行う\n",
        "max_length = 512  # 調整後の最大長さ\n",
        "\n",
        "# Sentenceを指定した長さにトリミングする関数\n",
        "def trim_sentence(sample, tokenizer, max_length):\n",
        "    # Sentenceをトークン化\n",
        "    tokens = tokenizer(\n",
        "        sample['Sentence'],\n",
        "        max_length=max_length,\n",
        "        truncation=True,\n",
        "        padding='max_length'  # パディングもmax_lengthに合わせる\n",
        "    )\n",
        "\n",
        "    # トリミング後のトークンを元のフィーチャに反映\n",
        "    sample['input_ids'] = tokens['input_ids'][:max_length]\n",
        "    sample['attention_mask'] = tokens['attention_mask'][:max_length]\n",
        "\n",
        "    return sample\n",
        "\n",
        "# トリミングを適用\n",
        "trimmed_train_tokenized_dataset = [trim_sentence(sample, tokenizer, max_length) for sample in train_tokenized_dataset]\n",
        "trimmed_test_tokenized_dataset = [trim_sentence(sample, tokenizer, max_length) for sample in test_tokenized_dataset]\n"
      ],
      "metadata": {
        "id": "ycbPa64CiG6N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "データコレーターの処理で何かしらの不備が生じている->データコレーターに手動で調整を加えるか、または他のデータコレーターを検討する\n"
      ],
      "metadata": {
        "id": "9spZrfaDpdV3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import get_linear_schedule_with_warmup\n",
        "\n",
        "# トレーニング時の設定\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"test_trainer\",\n",
        "    per_device_train_batch_size=7,\n",
        "    num_train_epochs=0.9,\n",
        "    evaluation_strategy=\"steps\",\n",
        "    eval_steps=200,\n",
        "    lr_scheduler_type=\"linear\",  # スケジューラのタイプを指定\n",
        ")\n",
        "\n",
        "# 学習率のスケジューラの設定\n",
        "num_training_steps = len(train_tokenized_dataset) // training_args.per_device_train_batch_size * training_args.num_train_epochs\n",
        "warmup_steps = int(0.1 * num_training_steps)\n",
        "scheduler = get_linear_schedule_with_warmup(\n",
        "    optimizer,\n",
        "    num_warmup_steps=warmup_steps,\n",
        "    num_training_steps=num_training_steps\n",
        ")\n"
      ],
      "metadata": {
        "id": "z97HVe7PQeeP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import nn\n",
        "from transformers import Trainer\n",
        "\n",
        "class CustomTrainer(Trainer):\n",
        "    def compute_loss(self, model, inputs, return_outputs=False):\n",
        "        labels = inputs.get(\"labels\", None)\n",
        "\n",
        "        if labels is None:\n",
        "            if \"labels\" not in inputs or inputs[\"labels\"] is None:\n",
        "                raise ValueError(\"Labels are missing or None in the inputs during training.\")\n",
        "            else:\n",
        "                labels = inputs[\"labels\"]\n",
        "\n",
        "        # モデルのフォワードパス\n",
        "        outputs = model(**inputs)\n",
        "\n",
        "        # logitsから損失を計算\n",
        "        loss = nn.CrossEntropyLoss()(outputs.logits, labels)\n",
        "\n",
        "        if return_outputs:\n",
        "            return (loss, outputs)\n",
        "        else:\n",
        "            return loss.item() if hasattr(loss, \"item\") else loss\n"
      ],
      "metadata": {
        "id": "_rtjupVPsF3G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 通常のTrainerと同様の引数を指定して、CustomTrainerを初期化する\n",
        "custom_trainer = CustomTrainer(\n",
        "    model=model,                        # トレーニングするモデル\n",
        "    args=training_args,                  # トレーニングの設定\n",
        "    train_dataset=trimmed_train_tokenized_dataset,  # トレーニングデータセット\n",
        "    eval_dataset=trimmed_test_tokenized_dataset,    # 評価データセット\n",
        "    compute_metrics=compute_metrics,     # メトリクスの計算関数\n",
        "    # data_collator=pad_collate,  # パディングを行うデータコレーターを指定\n",
        "    optimizers=(optimizer, scheduler)    # カスタムTrainerにはoptimizerとschedulerをタプルで渡す\n",
        ")\n",
        "\n",
        "# 訓練を実行\n",
        "custom_trainer.train()\n"
      ],
      "metadata": {
        "id": "pPFXdSaksJlw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# trainer = Trainer(\n",
        "#     model=model,\n",
        "#     args=training_args,\n",
        "#     # data_collator=pad_collate,  # デフォルトのデータコレーターを使用\n",
        "#     train_dataset=train_tokenized_dataset,\n",
        "#     eval_dataset=test_tokenized_dataset,\n",
        "#     compute_metrics=compute_metrics,\n",
        "#     # optimizer=optimizer,\n",
        "#     # lr_scheduler=scheduler,  # 学習率スケジューラを指定\n",
        "# )\n",
        "\n",
        "# # 訓練を実行\n",
        "# trainer.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 360
        },
        "id": "cRfMokBJ6qpT",
        "outputId": "38169cf3-a41e-4715-f748-207b9447ae0b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-37-7fec38dcf302>\u001b[0m in \u001b[0;36m<cell line: 13>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# 訓練を実行\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1535\u001b[0m                 \u001b[0mhf_hub_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_progress_bars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1536\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1537\u001b[0;31m             return inner_training_loop(\n\u001b[0m\u001b[1;32m   1538\u001b[0m                 \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1539\u001b[0m                 \u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   1852\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1853\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccelerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccumulate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1854\u001b[0;31m                     \u001b[0mtr_loss_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1855\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1856\u001b[0m                 if (\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtraining_step\u001b[0;34m(self, model, inputs)\u001b[0m\n\u001b[1;32m   2733\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2734\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_loss_context_manager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2735\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2736\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2737\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_gpu\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mcompute_loss\u001b[0;34m(self, model, inputs, return_outputs)\u001b[0m\n\u001b[1;32m   2756\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2757\u001b[0m             \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2758\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2759\u001b[0m         \u001b[0;31m# Save past state if it exists\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2760\u001b[0m         \u001b[0;31m# TODO: this needs to be fixed and made cleaner later.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1562\u001b[0m         \u001b[0mreturn_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_return_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1563\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1564\u001b[0;31m         outputs = self.bert(\n\u001b[0m\u001b[1;32m   1565\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1566\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1011\u001b[0m             \u001b[0mpast_key_values_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpast_key_values_length\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1012\u001b[0m         )\n\u001b[0;32m-> 1013\u001b[0;31m         encoder_outputs = self.encoder(\n\u001b[0m\u001b[1;32m   1014\u001b[0m             \u001b[0membedding_output\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1015\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mextended_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    605\u001b[0m                 )\n\u001b[1;32m    606\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 607\u001b[0;31m                 layer_outputs = layer_module(\n\u001b[0m\u001b[1;32m    608\u001b[0m                     \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    609\u001b[0m                     \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    537\u001b[0m             \u001b[0mpresent_key_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpresent_key_value\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mcross_attn_present_key_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    538\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 539\u001b[0;31m         layer_output = apply_chunking_to_forward(\n\u001b[0m\u001b[1;32m    540\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeed_forward_chunk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchunk_size_feed_forward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseq_len_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    541\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/pytorch_utils.py\u001b[0m in \u001b[0;36mapply_chunking_to_forward\u001b[0;34m(forward_fn, chunk_size, chunk_dim, *input_tensors)\u001b[0m\n\u001b[1;32m    240\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_chunks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mchunk_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 242\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mforward_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput_tensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    243\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mfeed_forward_chunk\u001b[0;34m(self, attention_output)\u001b[0m\n\u001b[1;32m    549\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    550\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfeed_forward_chunk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 551\u001b[0;31m         \u001b[0mintermediate_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintermediate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattention_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    552\u001b[0m         \u001b[0mlayer_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mintermediate_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    553\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlayer_output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states)\u001b[0m\n\u001b[1;32m    449\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 451\u001b[0;31m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    452\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintermediate_act_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-h0tclaxUInm"
      },
      "outputs": [],
      "source": [
        "# https://www.delftstack.com/ja/howto/numpy/numpy-softmax/\n",
        "def np_softmax(x):\n",
        "    f_x = np.exp(x) / np.sum(np.exp(x))\n",
        "    return f_x\n",
        "\n",
        "def analyze_emotion(text, show_fig=False, ret_prob=False):\n",
        "    # 推論モードを有効化\n",
        "    model.eval()\n",
        "\n",
        "    # 入力データ変換 + 推論\n",
        "    tokens = tokenizer(text, truncation=True, return_tensors=\"pt\")\n",
        "    tokens.to(model.device)\n",
        "    preds = model(**tokens)\n",
        "    prob = np_softmax(preds.logits.cpu().detach().numpy()[0])\n",
        "    out_dict = {n: p for n, p in zip(emotion_names_jp, prob)}\n",
        "\n",
        "    # 棒グラフを描画\n",
        "    if show_fig:\n",
        "        plt.figure(figsize=(8, 3))\n",
        "        df = pd.DataFrame(out_dict.items(), columns=['name', 'prob'])\n",
        "        sns.barplot(x='name', y='prob', data=df)\n",
        "        plt.title('入力文 : ' + text, fontsize=15)\n",
        "\n",
        "    if ret_prob:\n",
        "        return out_dict\n",
        "\n",
        "# 動作確認\n",
        "analyze_emotion('今日から長期休暇だぁーーー！！！', show_fig=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TmI5b0LdUInm"
      },
      "outputs": [],
      "source": [
        "analyze_emotion('この書類にはコーヒーかかってなくて良かった…。不幸中の幸いだ。', show_fig=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NN7HD39tXhrn"
      },
      "outputs": [],
      "source": [
        "analyze_emotion('なんで自分だけこんな目に遭うんだ……', show_fig=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sfhyeuHWXlZz"
      },
      "outputs": [],
      "source": [
        "analyze_emotion('君ならきっとやってくれると思っていたよ！', show_fig=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JieaUWipXnTP"
      },
      "outputs": [],
      "source": [
        "analyze_emotion('え、今日って休校だったの？', show_fig=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XKoAmqYlXpaj"
      },
      "outputs": [],
      "source": [
        "analyze_emotion('明日のプレゼンうまくできるかなぁ…', show_fig=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H824mByPXrJL"
      },
      "outputs": [],
      "source": [
        "analyze_emotion('あぁー、イライラするっ！！', show_fig=True)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.1"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "4865d29cc23742fba06ee0d4b33ca110": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c450e78130b445778392ce5dda42a8be",
              "IPY_MODEL_256352a743374f37b42f68dfdff1048a",
              "IPY_MODEL_b1ed0980406f4f558577e78a08e246a9"
            ],
            "layout": "IPY_MODEL_f3ac7c37d26a498993363c00cb6f19f4"
          }
        },
        "c450e78130b445778392ce5dda42a8be": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c590677ca1c04cccb0a382451ef5f61d",
            "placeholder": "​",
            "style": "IPY_MODEL_4ac7e2327f6c459dbd5ceba4bb696592",
            "value": "Map: 100%"
          }
        },
        "256352a743374f37b42f68dfdff1048a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_06864032e2ad43a3a2975ea39b500d47",
            "max": 17104,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8b497efce6ac4ceda52044b5cbde2699",
            "value": 17104
          }
        },
        "b1ed0980406f4f558577e78a08e246a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a13965e6a1e64c6ab95f5b18220ee43c",
            "placeholder": "​",
            "style": "IPY_MODEL_e3e664fc08614659a7e7f8d8b19a6c91",
            "value": " 17104/17104 [00:22&lt;00:00, 650.68 examples/s]"
          }
        },
        "f3ac7c37d26a498993363c00cb6f19f4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c590677ca1c04cccb0a382451ef5f61d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4ac7e2327f6c459dbd5ceba4bb696592": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "06864032e2ad43a3a2975ea39b500d47": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8b497efce6ac4ceda52044b5cbde2699": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a13965e6a1e64c6ab95f5b18220ee43c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e3e664fc08614659a7e7f8d8b19a6c91": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ea859a0d8bc047be9e2d8d13421c3b12": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c6b01b65b6f149cfa9a687ab8e6e7fd6",
              "IPY_MODEL_b236d2deb30f4253be20e750aad15e27",
              "IPY_MODEL_aca51aeeac474323abd96a83268b17f4"
            ],
            "layout": "IPY_MODEL_e926a34caf68404da2eaf625feda82be"
          }
        },
        "c6b01b65b6f149cfa9a687ab8e6e7fd6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9c8a4c95cb7a4e60a523c9d52d99d189",
            "placeholder": "​",
            "style": "IPY_MODEL_0422e15ad92749cd8d92beb658045cdc",
            "value": "Map: 100%"
          }
        },
        "b236d2deb30f4253be20e750aad15e27": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0aacf537e45f41b5a348b3b76cabc058",
            "max": 1133,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_80206e3f4e7b4d7e89a1bf0495b0db3d",
            "value": 1133
          }
        },
        "aca51aeeac474323abd96a83268b17f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d79f63a487ef437f9c6281b224f989df",
            "placeholder": "​",
            "style": "IPY_MODEL_305430c960bc400f9f23bdb8a8770ee0",
            "value": " 1133/1133 [00:01&lt;00:00, 773.04 examples/s]"
          }
        },
        "e926a34caf68404da2eaf625feda82be": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9c8a4c95cb7a4e60a523c9d52d99d189": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0422e15ad92749cd8d92beb658045cdc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0aacf537e45f41b5a348b3b76cabc058": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "80206e3f4e7b4d7e89a1bf0495b0db3d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d79f63a487ef437f9c6281b224f989df": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "305430c960bc400f9f23bdb8a8770ee0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}