{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ã‚«ãƒ¼ãƒãƒ«ãƒªã‚¹ã‚¿ãƒ¼ãƒˆã®æ™‚ã¯ã“ã®ã‚»ãƒ«ã‚’å®Ÿè¡Œã—ãªãã¦ã‚‚OK\n",
    "# !wget https://bootstrap.pypa.io/get-pip.py\n",
    "# !python get-pip.py\n",
    "# %pip install tokenizers fugashi ipadic accelerate==0.20.3 seaborn\n",
    "# %pip install transformers datasets scikit-learn\n",
    "# !wget https://github.com/ids-cv/wrime/raw/master/wrime-ver1.tsv\n",
    "# %pip install -U imbalanced-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch\n",
    "\n",
    "from torch import nn\n",
    "from datasets import Dataset, load_metric\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer, AutoConfig, AdamW, get_linear_schedule_with_warmup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wrime = pd.read_table('wrime-ver1.tsv')\n",
    "emotion_names = ['Joy', 'Sadness', 'Anticipation', 'Surprise', 'Anger', 'Fear', 'Disgust', 'Trust']\n",
    "emotion_names_jp = ['å–œã³', 'æ‚²ã—ã¿', 'æœŸå¾…', 'é©šã', 'æ€’ã‚Š', 'æã‚Œ', 'å«Œæ‚ª', 'ä¿¡é ¼']\n",
    "num_labels = len(emotion_names)\n",
    "\n",
    "df_wrime['readers_emotion_intensities'] = df_wrime.apply(lambda x: [x['Avg. Readers_' + name] for name in emotion_names], axis=1)\n",
    "\n",
    "# removing samples with less emotion intensities\n",
    "# (max.readers_emotion_intensities must be 2 or more)\n",
    "is_target = df_wrime['readers_emotion_intensities'].map(lambda x: max(x) >= 2)\n",
    "df_wrime_target = df_wrime[is_target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_columns = ['Sentence', 'readers_emotion_intensities']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_dataframe(df):\n",
    "    if 'readers_emotion_intensities' not in df.columns:\n",
    "        raise ValueError(\"DataFrame does not contain 'readers_emotion_intensities' column.\")\n",
    "    \n",
    "    # DataFrameã‚’ã‚³ãƒ”ãƒ¼ã—ã¦æ–°ã—ã„DataFrameã‚’ä½œæˆ\n",
    "    updated_df = df.copy()\n",
    "    \n",
    "    # 'readers_emotion_intensities'åˆ—ã®å„è¦ç´ ã‚’æ›´æ–°\n",
    "    for index, row in updated_df.iterrows():\n",
    "        max_value = max(row['readers_emotion_intensities'])\n",
    "        updated_df.at[index, 'readers_emotion_intensities'] = [int(value == max_value) for value in row['readers_emotion_intensities']]\n",
    "    \n",
    "    return updated_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wrime_target_updated = update_dataframe(df_wrime_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# readers_emotion_intensities åˆ—ã«1ãŒ2å›ä»¥ä¸Šç™»å ´ã™ã‚‹è¡Œã‚’å‰Šé™¤ã™ã‚‹\n",
    "df_wrime_target_updated_filtered = df_wrime_target_updated[df_wrime_target_updated['readers_emotion_intensities'].apply(lambda x: x.count(1) < 2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1435/2427799980.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_wrime_target_updated_filtered['emotion'] = emotion_labels\n"
     ]
    }
   ],
   "source": [
    "# æ„Ÿæƒ…ãƒ©ãƒ™ãƒ«ã‚’ä¿å­˜ã™ã‚‹ãŸã‚ã®ç©ºã®ãƒªã‚¹ãƒˆã‚’ä½œæˆ\n",
    "emotion_labels = []\n",
    "\n",
    "# å„è¡Œã«å¯¾ã—ã¦å‡¦ç†ã‚’è¡Œã†\n",
    "for index, row in df_wrime_target_updated_filtered.iterrows():\n",
    "    # 1ãŒæ ¼ç´ã•ã‚Œã¦ã„ã‚‹ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’å–å¾—ã—ã€å¯¾å¿œã™ã‚‹æ„Ÿæƒ…ãƒ©ãƒ™ãƒ«ã‚’å–å¾—ã™ã‚‹\n",
    "    emotions = [emotion_names_jp[i] for i, val in enumerate(row['readers_emotion_intensities']) if val == 1]\n",
    "    # æ„Ÿæƒ…ãƒ©ãƒ™ãƒ«ãŒãªã„å ´åˆã¯ç©ºæ–‡å­—åˆ—ã‚’è¿½åŠ ã™ã‚‹\n",
    "    if len(emotions) == 0:\n",
    "        emotion_labels.append('')\n",
    "    else:\n",
    "        # è¤‡æ•°ã®æ„Ÿæƒ…ãŒã‚ã‚‹å ´åˆã¯ã‚«ãƒ³ãƒåŒºåˆ‡ã‚Šã®æ–‡å­—åˆ—ã«å¤‰æ›ã—ã¦è¿½åŠ ã™ã‚‹\n",
    "        emotion_labels.append(', '.join(emotions))\n",
    "\n",
    "# æ–°ã—ã„æ„Ÿæƒ…ã‚«ãƒ©ãƒ ã‚’ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã«è¿½åŠ ã™ã‚‹\n",
    "df_wrime_target_updated_filtered['emotion'] = emotion_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "emotion\n",
      "å–œã³     4441\n",
      "æœŸå¾…     4053\n",
      "æ‚²ã—ã¿    2900\n",
      "é©šã     1955\n",
      "æã‚Œ     1591\n",
      "å«Œæ‚ª     1024\n",
      "æ€’ã‚Š      197\n",
      "ä¿¡é ¼       45\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df_wrime_target_updated_filtered['emotion'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "emotion\n",
      "æ‚²ã—ã¿    4441\n",
      "é©šã     4441\n",
      "å–œã³     4441\n",
      "æœŸå¾…     4441\n",
      "æã‚Œ     4441\n",
      "ä¿¡é ¼     4441\n",
      "æ€’ã‚Š     4441\n",
      "å«Œæ‚ª     4441\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# å„æ„Ÿæƒ…ãƒ©ãƒ™ãƒ«ã”ã¨ã®ã‚µãƒ³ãƒ—ãƒ«æ•°ã‚’ã‚«ã‚¦ãƒ³ãƒˆ\n",
    "emotion_counts = df_wrime_target_updated_filtered['emotion'].value_counts()\n",
    "\n",
    "# ã‚ªãƒ¼ãƒãƒ¼ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã®ãŸã‚ã®ã‚µãƒ³ãƒ—ãƒ«æ•°ã®è¨ˆç®—\n",
    "max_samples = emotion_counts.max()  # æœ€å¤§ã®ã‚µãƒ³ãƒ—ãƒ«æ•°ã‚’åŸºæº–ã«ã™ã‚‹\n",
    "min_samples = emotion_counts.min()\n",
    "\n",
    "# ã‚ªãƒ¼ãƒãƒ¼ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°\n",
    "ros = RandomOverSampler(sampling_strategy={label: max_samples for label in emotion_counts.index})\n",
    "oversampled_X, oversampled_y = ros.fit_resample(df_wrime_target_updated_filtered['Sentence'].values.reshape(-1, 1), df_wrime_target_updated_filtered['emotion'])\n",
    "\n",
    "# ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã«å¤‰æ›\n",
    "df_wrime_target_updated_filtered_oversampled = pd.DataFrame({'Sentence': oversampled_X.flatten(), 'emotion': oversampled_y})\n",
    "\n",
    "\n",
    "# çµæœã®è¡¨ç¤º\n",
    "print(df_wrime_target_updated_filtered_oversampled['emotion'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_emotion_to_binary(emotion_label):\n",
    "    # ãƒ©ãƒ™ãƒ«ãŒå­˜åœ¨ã™ã‚‹å ´åˆã¯å¯¾å¿œã™ã‚‹ãƒã‚¤ãƒŠãƒªãƒ‡ãƒ¼ã‚¿ã‚’ä½œæˆ\n",
    "    if emotion_label in emotion_names_jp:\n",
    "        # ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’å–å¾—\n",
    "        idx = emotion_names_jp.index(emotion_label)\n",
    "        # ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã«å¯¾å¿œã™ã‚‹ä½ç½®ã‚’1ã€ãã‚Œä»¥å¤–ã‚’0ã¨ã™ã‚‹ãƒªã‚¹ãƒˆã‚’ä½œæˆ\n",
    "        binary_data = [1 if i == idx else 0 for i in range(len(emotion_names_jp))]\n",
    "        return binary_data\n",
    "    else:\n",
    "        # ãƒ©ãƒ™ãƒ«ãŒå­˜åœ¨ã—ãªã„å ´åˆã¯ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’å‡ºåŠ›ã—ã¦Noneã‚’è¿”ã™\n",
    "        print(\"Invalid emotion label!\")\n",
    "        return [0] * len(emotion_names_jp)\n",
    "\n",
    "# NaNã‚’åŸ‹ã‚ã‚‹\n",
    "df_wrime_target_updated_filtered_oversampled['readers_emotion_intensities'] = df_wrime_target_updated_filtered_oversampled['emotion'].apply(convert_emotion_to_binary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ä½¿ç”¨ã™ã‚‹ãƒ¢ãƒ‡ãƒ«ã‚’æŒ‡å®šã—ã¦ã€Tokenizerã‚’èª­ã¿è¾¼ã‚€\n",
    "checkpoint = 'cl-tohoku/bert-base-japanese-whole-word-masking'\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divide into train, validation, and test sets\n",
    "train_data, test_valid_data = train_test_split(df_wrime_target_updated_filtered_oversampled, test_size=0.4, random_state=42)\n",
    "valid_data, test_data = train_test_split(test_valid_data, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_function(batch):\n",
    "    tokenized_batch = tokenizer(batch['Sentence'], truncation=True, padding='max_length', return_tensors=\"pt\")\n",
    "    tokenized_batch['labels'] = [x / np.sum(x) for x in batch['readers_emotion_intensities']]\n",
    "    return tokenized_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parameter 'function'=<function tokenize_function at 0x7efb0066ef80> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca8dd529cb1b4500962bd174bb75977d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/21316 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24c8e18f4eb24587a3f0976b418f54f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/7106 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4aae951ca604995a9e30292dbdba7a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/7106 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Transformersç”¨ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆå½¢å¼ã«å¤‰æ›\n",
    "# pandas.DataFrame -> datasets.Dataset\n",
    "target_columns = ['Sentence', 'readers_emotion_intensities']\n",
    "train_dataset = Dataset.from_pandas(train_data[target_columns])\n",
    "valid_dataset = Dataset.from_pandas(valid_data[target_columns])\n",
    "test_dataset = Dataset.from_pandas(test_data[target_columns])\n",
    "\n",
    "# å‰å‡¦ç†ï¼ˆtokenize_functionï¼‰ ã‚’é©ç”¨\n",
    "train_tokenized_dataset = train_dataset.map(tokenize_function, batched=True)\n",
    "valid_tokenized_dataset = valid_dataset.map(tokenize_function, batched=True)\n",
    "test_tokenized_dataset = test_dataset.map(tokenize_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1435/2983350284.py:2: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library ğŸ¤— Evaluate: https://huggingface.co/docs/evaluate\n",
      "  metric = load_metric(\"accuracy\")\n",
      "/usr/local/lib/python3.10/dist-packages/datasets/load.py:753: FutureWarning: The repository for accuracy contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.17.0/metrics/accuracy/accuracy.py\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# https://huggingface.co/docs/transformers/training\n",
    "metric = load_metric(\"accuracy\")\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    label_ids = np.argmax(labels, axis=-1)\n",
    "    return metric.compute(predictions=predictions, references=label_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at cl-tohoku/bert-base-japanese-whole-word-masking and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(checkpoint, num_labels=num_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install accelerate transformers[torch] -U\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "è¨“ç·´æ™‚ã«error â†’ ä¸Šã®ã‚³ãƒ¼ãƒ‰ã‚»ãƒ«ã‚’ã‚³ãƒ¡ãƒ³ãƒˆã‚¢ã‚¦ãƒˆ â†’ å®Ÿè¡Œ â†’ (ä»®æƒ³ç’°å¢ƒã‚’deactivate + restart vscode)ã‚‚ã—ãã¯(ã‚«ãƒ¼ãƒãƒ«ãƒªã‚¹ã‚¿ãƒ¼ãƒˆ) â†’ ä¸Šã®ã‚³ãƒ¼ãƒ‰ã‚»ãƒ«ã‚’ã‚³ãƒ¡ãƒ³ãƒˆã‚¢ã‚¦ãƒˆ â†’ run all the cells againã§è§£æ±º\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3999' max='3999' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3999/3999 17:22, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.244400</td>\n",
       "      <td>0.163124</td>\n",
       "      <td>0.746834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.149000</td>\n",
       "      <td>0.125771</td>\n",
       "      <td>0.808331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.103500</td>\n",
       "      <td>0.109874</td>\n",
       "      <td>0.842387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.066600</td>\n",
       "      <td>0.102253</td>\n",
       "      <td>0.853786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.060700</td>\n",
       "      <td>0.090913</td>\n",
       "      <td>0.876724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.038600</td>\n",
       "      <td>0.097098</td>\n",
       "      <td>0.878694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>0.026900</td>\n",
       "      <td>0.095092</td>\n",
       "      <td>0.885167</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checkpoint destination directory test_trainer/checkpoint-500 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory test_trainer/checkpoint-1000 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory test_trainer/checkpoint-1500 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory test_trainer/checkpoint-2000 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory test_trainer/checkpoint-2500 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory test_trainer/checkpoint-3000 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory test_trainer/checkpoint-3500 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=3999, training_loss=0.08923298539325994, metrics={'train_runtime': 1042.4949, 'train_samples_per_second': 61.341, 'train_steps_per_second': 3.836, 'total_flos': 1.6826332180414464e+16, 'train_loss': 0.08923298539325994, 'epoch': 3.0})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Transformers ã® Trainer ã‚’ç”¨ã„ã‚‹\n",
    "# https://huggingface.co/docs/transformers/v4.21.1/en/main_classes/trainer#transformers.TrainingArguments\n",
    "\n",
    "# è¨“ç·´æ™‚ã®è¨­å®šã‚’ä¿®æ­£\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"test_trainer\",\n",
    "    per_device_train_batch_size=16, # originally 8\n",
    "    num_train_epochs=3.0, # originally 1\n",
    "    evaluation_strategy=\"steps\", eval_steps=500)  # 500ã‚¹ãƒ†ãƒƒãƒ—æ¯ã«æ¤œè¨¼ãƒ‡ãƒ¼ã‚¿ã§è©•ä¾¡ã™ã‚‹\n",
    "\n",
    "# Trainerã‚’ç”Ÿæˆ\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_tokenized_dataset,\n",
    "    eval_dataset=valid_tokenized_dataset,  # æ¤œè¨¼ãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ç”¨ã™ã‚‹\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "# è¨“ç·´ã‚’å®Ÿè¡Œ\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.delftstack.com/ja/howto/numpy/numpy-softmax/\n",
    "def np_softmax(x):\n",
    "    f_x = np.exp(x) / np.sum(np.exp(x))\n",
    "    return f_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ãƒ†ã‚­ã‚¹ãƒˆã‚’æ„Ÿæƒ…è§£æã™ã‚‹é–¢æ•°\n",
    "def analyze_emotion(text):\n",
    "    # æ¨è«–ãƒ¢ãƒ¼ãƒ‰\n",
    "    model.eval()\n",
    "\n",
    "    # å…¥åŠ›ãƒ‡ãƒ¼ã‚¿å¤‰æ› + æ¨è«–\n",
    "    tokens = tokenizer(text, truncation=True, return_tensors=\"pt\")\n",
    "    tokens.to(model.device)\n",
    "    preds = model(**tokens)\n",
    "    prob = np_softmax(preds.logits.cpu().detach().numpy()[0])\n",
    "    out_dict = {n: p for n, p in zip(emotion_names_jp, prob)}\n",
    "    out_list = list(out_dict.values())\n",
    "    return out_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# çµæœã‚’ä¿å­˜ã™ã‚‹ç©ºã®ãƒªã‚¹ãƒˆã‚’ä½œæˆ\n",
    "predicted_labels = []\n",
    "\n",
    "# test_tokenized_datasetã‹ã‚‰Sentenceã‚«ãƒ©ãƒ ã®ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—\n",
    "sentences = test_tokenized_dataset['Sentence']\n",
    "\n",
    "# å„ãƒ†ã‚­ã‚¹ãƒˆã«analyze_emotioné–¢æ•°ã‚’é©ç”¨ã—ã€çµæœã‚’ãƒªã‚¹ãƒˆã«ä¿å­˜\n",
    "for text in sentences:\n",
    "    result = analyze_emotion(text)\n",
    "    predicted_labels.append(result)\n",
    "\n",
    "true_labels = test_tokenized_dataset['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# äºˆæ¸¬çµæœã¨çœŸã®ãƒ©ãƒ™ãƒ«ã‚’DataFrameã«å¤‰æ›\n",
    "predicted_df = pd.DataFrame(predicted_labels, columns=emotion_names_jp)\n",
    "true_df = pd.DataFrame(true_labels, columns=emotion_names_jp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataFrameã®å„è¡Œã‚’æ›´æ–°ã—ã¦ã€æœ€å¤§å€¤ã«1ã€ãã‚Œä»¥å¤–ã«0ã‚’æŒã¤ã‚ˆã†ã«ã™ã‚‹\n",
    "def update_dataframe(df):\n",
    "    for index, row in df.iterrows():\n",
    "        max_value = row.max()\n",
    "        df.loc[index] = (row == max_value).astype(int)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_process_values = update_dataframe(predicted_df)\n",
    "true_process_values = update_dataframe(true_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å„DataFrameã‹ã‚‰æœ€å¤§ã®æ„Ÿæƒ…ã‚’æŠ½å‡º\n",
    "def get_max_emotions(df):\n",
    "    max_emotions = []\n",
    "    for index, row in df.iterrows():\n",
    "        max_emotions.append(row.index[row == 1].tolist())\n",
    "    return pd.DataFrame({'Emotions': max_emotions})\n",
    "\n",
    "predicted_emotions = get_max_emotions(predicted_df)\n",
    "true_emotions = get_max_emotions(true_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# true_emotionsã®ãƒªã‚¹ãƒˆã‚µã‚¤ã‚ºãŒ2ä»¥ä¸Šã®å ´åˆã€ä»¥ä¸‹ã®2ã¤ã‚’å®Ÿè¡Œ\n",
    "# 1:predãƒªã‚¹ãƒˆã®æ„Ÿæƒ…ãŒtrueãƒªã‚¹ãƒˆã«ã‚ã‚‹å ´åˆã¯ã€predãƒªã‚¹ãƒˆã¨ä¸€è‡´ã™ã‚‹æ„Ÿæƒ…ã‚’é™¤ã„ã¦trueãƒªã‚¹ãƒˆå†…ã®æ„Ÿæƒ…ã‚’å‰Šé™¤ \n",
    "# 2:predãƒªã‚¹ãƒˆã®æ„Ÿæƒ…ãŒtrueãƒªã‚¹ãƒˆã«ãªã„å ´åˆã¯ã€ä¸¡ãƒªã‚¹ãƒˆã®æ„Ÿæƒ…ã‚’ã™ã¹ã¦å‰Šé™¤ã—ã¦ç©ºãƒªã‚¹ãƒˆã«ã™ã‚‹â†’æ··åŒè¡Œåˆ—ãƒ»F1ã‚¹ã‚³ã‚¢è¨ˆç®—ã«ã¯å«ã¾ãªã„ã‚¨ãƒ³ãƒˆãƒªã¨ã—ã¦æ‰±ã†\n",
    "def remove_extra_emotions(predicted_emotions, true_emotions):\n",
    "    for idx, (pred, true) in zip(predicted_emotions.index, zip(predicted_emotions['Emotions'], true_emotions['Emotions'])):\n",
    "        if len(true) >= 2:\n",
    "            true_emotions.at[idx, 'Emotions'] = [emotion for emotion in true if emotion in pred] if any(emotion in pred for emotion in true) else []\n",
    "\n",
    "remove_extra_emotions(predicted_emotions, true_emotions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# æ„Ÿæƒ…ãƒ©ãƒ™ãƒ«ã‚’æ•°å€¤ã«å¤‰æ›ã™ã‚‹é–¢æ•°ã‚’å®šç¾©\n",
    "def label_to_index(label):\n",
    "    return emotion_names_jp.index(label)\n",
    "\n",
    "# äºˆæ¸¬å€¤ã¨æ­£è§£å€¤ã®æ„Ÿæƒ…ãƒ©ãƒ™ãƒ«ã‚’æ•°å€¤ã«å¤‰æ›\n",
    "predicted_indices = [label_to_index(label) for labels in predicted_emotions['Emotions'] for label in labels]\n",
    "true_indices = [label_to_index(label) for labels in true_emotions['Emotions'] for label in labels]\n",
    "\n",
    "# æ··åŒè¡Œåˆ—ã‚’ä½œæˆ\n",
    "confusion_matrix_data = confusion_matrix(true_indices, predicted_indices)\n",
    "\n",
    "# æ··åŒè¡Œåˆ—ã‚’DataFrameã«å¤‰æ›\n",
    "confusion_matrix_df = pd.DataFrame(confusion_matrix_data, index=[f'çœŸ: {label}' for label in emotion_names_jp], columns=[f'äºˆ: {label}' for label in emotion_names_jp])\n",
    "\n",
    "# å„è¡Œã¨å„åˆ—ã®åˆè¨ˆã‚’è¿½åŠ \n",
    "confusion_matrix_df['åˆè¨ˆ'] = confusion_matrix_df.sum(axis=1)\n",
    "confusion_matrix_df.loc['åˆè¨ˆ'] = confusion_matrix_df.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>äºˆ: å–œã³</th>\n",
       "      <th>äºˆ: æ‚²ã—ã¿</th>\n",
       "      <th>äºˆ: æœŸå¾…</th>\n",
       "      <th>äºˆ: é©šã</th>\n",
       "      <th>äºˆ: æ€’ã‚Š</th>\n",
       "      <th>äºˆ: æã‚Œ</th>\n",
       "      <th>äºˆ: å«Œæ‚ª</th>\n",
       "      <th>äºˆ: ä¿¡é ¼</th>\n",
       "      <th>åˆè¨ˆ</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>çœŸ: å–œã³</th>\n",
       "      <td>719</td>\n",
       "      <td>31</td>\n",
       "      <td>82</td>\n",
       "      <td>43</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>çœŸ: æ‚²ã—ã¿</th>\n",
       "      <td>12</td>\n",
       "      <td>734</td>\n",
       "      <td>36</td>\n",
       "      <td>36</td>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>çœŸ: æœŸå¾…</th>\n",
       "      <td>75</td>\n",
       "      <td>28</td>\n",
       "      <td>718</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>çœŸ: é©šã</th>\n",
       "      <td>47</td>\n",
       "      <td>14</td>\n",
       "      <td>16</td>\n",
       "      <td>766</td>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>çœŸ: æ€’ã‚Š</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>886</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>çœŸ: æã‚Œ</th>\n",
       "      <td>7</td>\n",
       "      <td>32</td>\n",
       "      <td>22</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>776</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>çœŸ: å«Œæ‚ª</th>\n",
       "      <td>6</td>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>828</td>\n",
       "      <td>0</td>\n",
       "      <td>873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>çœŸ: ä¿¡é ¼</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>912</td>\n",
       "      <td>912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>åˆè¨ˆ</th>\n",
       "      <td>866</td>\n",
       "      <td>854</td>\n",
       "      <td>876</td>\n",
       "      <td>895</td>\n",
       "      <td>891</td>\n",
       "      <td>916</td>\n",
       "      <td>895</td>\n",
       "      <td>913</td>\n",
       "      <td>7106</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        äºˆ: å–œã³  äºˆ: æ‚²ã—ã¿  äºˆ: æœŸå¾…  äºˆ: é©šã  äºˆ: æ€’ã‚Š  äºˆ: æã‚Œ  äºˆ: å«Œæ‚ª  äºˆ: ä¿¡é ¼    åˆè¨ˆ\n",
       "çœŸ: å–œã³     719      31     82     43      1     13      7      1   897\n",
       "çœŸ: æ‚²ã—ã¿     12     734     36     36      1     60     23      0   902\n",
       "çœŸ: æœŸå¾…      75      28    718     22      0     25      6      0   874\n",
       "çœŸ: é©šã      47      14     16    766      0     31     14      0   888\n",
       "çœŸ: æ€’ã‚Š       0       0      0      0    886      0      0      0   886\n",
       "çœŸ: æã‚Œ       7      32     22     20      0    776     17      0   874\n",
       "çœŸ: å«Œæ‚ª       6      15      2      8      3     11    828      0   873\n",
       "çœŸ: ä¿¡é ¼       0       0      0      0      0      0      0    912   912\n",
       "åˆè¨ˆ        866     854    876    895    891    916    895    913  7106"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å„æ„Ÿæƒ…ãƒ©ãƒ™ãƒ«ã®Precisionã€Recallã€F1ã‚¹ã‚³ã‚¢ã‚’è¨ˆç®—ã™ã‚‹é–¢æ•°ã‚’å®šç¾©\n",
    "def calculate_metrics(confusion_matrix):\n",
    "    metrics = {}\n",
    "    for i in range(len(emotion_names_jp)):\n",
    "        true_positive = confusion_matrix[i, i]\n",
    "        false_positive = confusion_matrix[:, i].sum() - true_positive\n",
    "        false_negative = confusion_matrix[i, :].sum() - true_positive\n",
    "        precision = true_positive / (true_positive + false_positive) if true_positive + false_positive > 0 else 0\n",
    "        recall = true_positive / (true_positive + false_negative) if true_positive + false_negative > 0 else 0\n",
    "        f1_score = 2 * precision * recall / (precision + recall) if precision + recall > 0 else 0\n",
    "        metrics[emotion_names_jp[i]] = {'Precision': precision, 'Recall': recall, 'F1 Score': f1_score}\n",
    "    return metrics\n",
    "\n",
    "# æ··åŒè¡Œåˆ—ã‹ã‚‰Precisionã€Recallã€F1ã‚¹ã‚³ã‚¢ã‚’è¨ˆç®—\n",
    "metrics = calculate_metrics(confusion_matrix_data)\n",
    "\n",
    "metrics_df = pd.DataFrame(metrics).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>å–œã³</th>\n",
       "      <td>0.830254</td>\n",
       "      <td>0.801561</td>\n",
       "      <td>0.815655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>æ‚²ã—ã¿</th>\n",
       "      <td>0.859485</td>\n",
       "      <td>0.813747</td>\n",
       "      <td>0.835991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>æœŸå¾…</th>\n",
       "      <td>0.819635</td>\n",
       "      <td>0.821510</td>\n",
       "      <td>0.820571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>é©šã</th>\n",
       "      <td>0.855866</td>\n",
       "      <td>0.862613</td>\n",
       "      <td>0.859226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>æ€’ã‚Š</th>\n",
       "      <td>0.994388</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.997186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>æã‚Œ</th>\n",
       "      <td>0.847162</td>\n",
       "      <td>0.887872</td>\n",
       "      <td>0.867039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>å«Œæ‚ª</th>\n",
       "      <td>0.925140</td>\n",
       "      <td>0.948454</td>\n",
       "      <td>0.936652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ä¿¡é ¼</th>\n",
       "      <td>0.998905</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999452</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Precision    Recall  F1 Score\n",
       "å–œã³    0.830254  0.801561  0.815655\n",
       "æ‚²ã—ã¿   0.859485  0.813747  0.835991\n",
       "æœŸå¾…    0.819635  0.821510  0.820571\n",
       "é©šã    0.855866  0.862613  0.859226\n",
       "æ€’ã‚Š    0.994388  1.000000  0.997186\n",
       "æã‚Œ    0.847162  0.887872  0.867039\n",
       "å«Œæ‚ª    0.925140  0.948454  0.936652\n",
       "ä¿¡é ¼    0.998905  1.000000  0.999452"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained(\"/workspace/0212_omg_its_working_finally.bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspace/0212_omg_its_working_finally\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
