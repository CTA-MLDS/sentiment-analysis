{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # カーネルリスタートの時はこのセルを実行しなくてもOK\n",
    "# !wget https://bootstrap.pypa.io/get-pip.py\n",
    "# !python get-pip.py\n",
    "# %pip install tokenizers fugashi ipadic accelerate==0.20.3 seaborn\n",
    "# %pip install transformers datasets scikit-learn\n",
    "# !wget https://github.com/ids-cv/wrime/raw/master/wrime-ver1.tsv\n",
    "\n",
    "# %pip install -U imbalanced-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch\n",
    "from torch import nn\n",
    "from datasets import Dataset, load_metric\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer, AutoConfig, AdamW, get_linear_schedule_with_warmup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wrime = pd.read_table('wrime-ver1.tsv')\n",
    "emotion_names = ['Joy', 'Sadness', 'Anticipation', 'Surprise', 'Anger', 'Fear', 'Disgust', 'Trust']\n",
    "emotion_names_jp = ['喜び', '悲しみ', '期待', '驚き', '怒り', '恐れ', '嫌悪', '信頼']\n",
    "num_labels = len(emotion_names)\n",
    "\n",
    "df_wrime['readers_emotion_intensities'] = df_wrime.apply(lambda x: [x['Avg. Readers_' + name] for name in emotion_names], axis=1)\n",
    "\n",
    "# removing samples with less emotion intensities\n",
    "# (max.readers_emotion_intensities must be 2 or more)\n",
    "is_target = df_wrime['readers_emotion_intensities'].map(lambda x: max(x) >= 2)\n",
    "df_wrime_target = df_wrime[is_target]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_dataframe(df):\n",
    "    if 'readers_emotion_intensities' not in df.columns:\n",
    "        raise ValueError(\"DataFrame does not contain 'readers_emotion_intensities' column.\")\n",
    "    \n",
    "    # DataFrameをコピーして新しいDataFrameを作成\n",
    "    updated_df = df.copy()\n",
    "    \n",
    "    # 'readers_emotion_intensities'列の各要素を更新\n",
    "    for index, row in updated_df.iterrows():\n",
    "        max_value = max(row['readers_emotion_intensities'])\n",
    "        updated_df.at[index, 'readers_emotion_intensities'] = [int(value == max_value) for value in row['readers_emotion_intensities']]\n",
    "    \n",
    "    return updated_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wrime_target_updated = update_dataframe(df_wrime_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# readers_emotion_intensities 列に1が2回以上登場する行を削除する\n",
    "df_wrime_target_updated_filtered = df_wrime_target_updated[df_wrime_target_updated['readers_emotion_intensities'].apply(lambda x: x.count(1) < 2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2222/2427799980.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_wrime_target_updated_filtered['emotion'] = emotion_labels\n"
     ]
    }
   ],
   "source": [
    "# 感情ラベルを保存するための空のリストを作成\n",
    "emotion_labels = []\n",
    "\n",
    "# 各行に対して処理を行う\n",
    "for index, row in df_wrime_target_updated_filtered.iterrows():\n",
    "    # 1が格納されているインデックスを取得し、対応する感情ラベルを取得する\n",
    "    emotions = [emotion_names_jp[i] for i, val in enumerate(row['readers_emotion_intensities']) if val == 1]\n",
    "    # 感情ラベルがない場合は空文字列を追加する\n",
    "    if len(emotions) == 0:\n",
    "        emotion_labels.append('')\n",
    "    else:\n",
    "        # 複数の感情がある場合はカンマ区切りの文字列に変換して追加する\n",
    "        emotion_labels.append(', '.join(emotions))\n",
    "\n",
    "# 新しい感情カラムをデータフレームに追加する\n",
    "df_wrime_target_updated_filtered['emotion'] = emotion_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "emotion\n",
      "恐れ     45\n",
      "信頼     45\n",
      "期待     45\n",
      "喜び     45\n",
      "悲しみ    45\n",
      "嫌悪     45\n",
      "驚き     45\n",
      "怒り     45\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# sm = SMOTE()\n",
    "# x_resampled, y_resampled = sm.fit_sample(x_train, y_train)\n",
    "\n",
    "# 各感情ラベルごとのサンプル数をカウント\n",
    "emotion_counts = df_wrime_target_updated_filtered['emotion'].value_counts()\n",
    "\n",
    "# アンダーサンプリングとオーバーサンプリングのためのサンプル数の計算\n",
    "max_samples = emotion_counts.min()  # 最小のサンプル数を基準にする\n",
    "min_samples = emotion_counts.min()\n",
    "\n",
    "# アンダーサンプリング\n",
    "rus = RandomUnderSampler(sampling_strategy={label: min_samples for label in emotion_counts.index})\n",
    "undersampled_X, undersampled_y = rus.fit_resample(df_wrime_target_updated_filtered['Sentence'].values.reshape(-1, 1), df_wrime_target_updated_filtered['emotion'])\n",
    "\n",
    "# オーバーサンプリング\n",
    "ros = RandomOverSampler(sampling_strategy={label: min_samples for label in emotion_counts.index})\n",
    "oversampled_X, oversampled_y = ros.fit_resample(undersampled_X, undersampled_y)\n",
    "\n",
    "# データフレームに変換\n",
    "df_wrime_target_updated_filtered_oversampled = pd.DataFrame({'Sentence': oversampled_X.flatten(), 'emotion': oversampled_y})\n",
    "\n",
    "# シャッフル\n",
    "df_wrime_target_updated_filtered_oversampled = df_wrime_target_updated_filtered_oversampled.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# 結果の表示\n",
    "print(df_wrime_target_updated_filtered_oversampled['emotion'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_wrime_target_updated_filtered_oversampled の Sentence カラムに存在する Sentence データの集合を作成\n",
    "existing_sentences = set(df_wrime_target_updated_filtered_oversampled['Sentence'])\n",
    "\n",
    "# df_wrime_target の Sentence カラムに含まれるエントリが df_wrime_target_updated_filtered_oversampled の Sentence カラムに存在しない行を削除\n",
    "df_wrime_target_updated_filtered_processed = df_wrime_target_updated_filtered[df_wrime_target_updated_filtered['Sentence'].isin(existing_sentences)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2222/464221191.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_wrime_target_updated_filtered_processed.drop(columns=['emotion'], inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# emotion 列を削除する\n",
    "df_wrime_target_updated_filtered_processed.drop(columns=['emotion'], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用するモデルを指定して、Tokenizerを読み込む\n",
    "checkpoint = 'cl-tohoku/bert-base-japanese-whole-word-masking'\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divide into train, validation, and test sets\n",
    "train_data, test_valid_data = train_test_split(df_wrime_target_updated_filtered_processed, test_size=0.4, random_state=42)\n",
    "valid_data, test_data = train_test_split(test_valid_data, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_function(batch):\n",
    "    tokenized_batch = tokenizer(batch['Sentence'], truncation=True, padding='max_length', return_tensors=\"pt\")\n",
    "    tokenized_batch['labels'] = [x / np.sum(x) for x in batch['readers_emotion_intensities']]\n",
    "    return tokenized_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba41533ec6d540a5b9020c97672c8aa2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/224 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58c7a5d8b1e546d7b1d4a333afa0d1f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/75 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d11b09cc94054a92b1e2fedaa8d81e3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/75 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Transformers用のデータセット形式に変換\n",
    "# pandas.DataFrame -> datasets.Dataset\n",
    "target_columns = ['Sentence', 'readers_emotion_intensities']\n",
    "train_dataset = Dataset.from_pandas(train_data[target_columns])\n",
    "valid_dataset = Dataset.from_pandas(valid_data[target_columns])\n",
    "test_dataset = Dataset.from_pandas(test_data[target_columns])\n",
    "\n",
    "# 前処理（tokenize_function） を適用\n",
    "train_tokenized_dataset = train_dataset.map(tokenize_function, batched=True)\n",
    "valid_tokenized_dataset = valid_dataset.map(tokenize_function, batched=True)\n",
    "test_tokenized_dataset = test_dataset.map(tokenize_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/datasets/load.py:753: FutureWarning: The repository for accuracy contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.17.0/metrics/accuracy/accuracy.py\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# https://huggingface.co/docs/transformers/training\n",
    "metric = load_metric(\"accuracy\")\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    label_ids = np.argmax(labels, axis=-1)\n",
    "    return metric.compute(predictions=predictions, references=label_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at cl-tohoku/bert-base-japanese-whole-word-masking and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(checkpoint, num_labels=num_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install accelerate transformers[torch] -U\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='28' max='28' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [28/28 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.379911</td>\n",
       "      <td>0.160000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.369718</td>\n",
       "      <td>0.146667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=28, training_loss=0.36614915302821566, metrics={'train_runtime': 3.8327, 'train_samples_per_second': 58.444, 'train_steps_per_second': 7.306, 'total_flos': 58940051423232.0, 'train_loss': 0.36614915302821566, 'epoch': 1.0})"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Transformers の Trainer を用いる\n",
    "# https://huggingface.co/docs/transformers/v4.21.1/en/main_classes/trainer#transformers.TrainingArguments\n",
    "\n",
    "# 訓練時にerror → 上のコードセルをコメントアウト → 実行 → (仮想環境をdeactivate + restart vscode)もしくは(カーネルリスタート) → 上のコードセルをコメントアウト → run all the cells againで解決\n",
    "\n",
    "# 訓練時の設定を修正\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"test_trainer\",\n",
    "    per_device_train_batch_size=8, # originally 8\n",
    "    num_train_epochs=1.0, # originally 1\n",
    "    evaluation_strategy=\"steps\", eval_steps=10)  # 10ステップ毎に検証データで評価する\n",
    "\n",
    "# Trainerのインスタンス化\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_tokenized_dataset,\n",
    "    eval_dataset=valid_tokenized_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "# 訓練を実行\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.delftstack.com/ja/howto/numpy/numpy-softmax/\n",
    "def np_softmax(x):\n",
    "    f_x = np.exp(x) / np.sum(np.exp(x))\n",
    "    return f_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# テキストを感情解析する関数\n",
    "def analyze_emotion(text):\n",
    "    # 推論モード\n",
    "    model.eval()\n",
    "\n",
    "    # 入力データ変換 + 推論\n",
    "    tokens = tokenizer(text, truncation=True, return_tensors=\"pt\")\n",
    "    tokens.to(model.device)\n",
    "    preds = model(**tokens)\n",
    "    prob = np_softmax(preds.logits.cpu().detach().numpy()[0])\n",
    "    out_dict = {n: p for n, p in zip(emotion_names_jp, prob)}\n",
    "    out_list = list(out_dict.values())\n",
    "    return out_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 結果を保存する空のリストを作成\n",
    "predicted_labels = []\n",
    "\n",
    "# test_tokenized_datasetからSentenceカラムのデータを取得\n",
    "sentences = test_tokenized_dataset['Sentence']\n",
    "\n",
    "# 各テキストにanalyze_emotion関数を適用し、結果をリストに保存\n",
    "for text in sentences:\n",
    "    result = analyze_emotion(text)\n",
    "    predicted_labels.append(result)\n",
    "\n",
    "true_labels = test_tokenized_dataset['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 予測結果と真のラベルをDataFrameに変換\n",
    "predicted_df = pd.DataFrame(predicted_labels, columns=emotion_names_jp)\n",
    "true_df = pd.DataFrame(true_labels, columns=emotion_names_jp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>喜び</th>\n",
       "      <th>悲しみ</th>\n",
       "      <th>期待</th>\n",
       "      <th>驚き</th>\n",
       "      <th>怒り</th>\n",
       "      <th>恐れ</th>\n",
       "      <th>嫌悪</th>\n",
       "      <th>信頼</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.123901</td>\n",
       "      <td>0.134909</td>\n",
       "      <td>0.133190</td>\n",
       "      <td>0.122655</td>\n",
       "      <td>0.115807</td>\n",
       "      <td>0.137655</td>\n",
       "      <td>0.111521</td>\n",
       "      <td>0.120361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.123715</td>\n",
       "      <td>0.134854</td>\n",
       "      <td>0.129580</td>\n",
       "      <td>0.131150</td>\n",
       "      <td>0.102251</td>\n",
       "      <td>0.128790</td>\n",
       "      <td>0.113987</td>\n",
       "      <td>0.135671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.119426</td>\n",
       "      <td>0.133836</td>\n",
       "      <td>0.130413</td>\n",
       "      <td>0.121691</td>\n",
       "      <td>0.106651</td>\n",
       "      <td>0.133787</td>\n",
       "      <td>0.117834</td>\n",
       "      <td>0.136362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.136457</td>\n",
       "      <td>0.128723</td>\n",
       "      <td>0.157675</td>\n",
       "      <td>0.122087</td>\n",
       "      <td>0.109651</td>\n",
       "      <td>0.124035</td>\n",
       "      <td>0.108002</td>\n",
       "      <td>0.113371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.136299</td>\n",
       "      <td>0.104186</td>\n",
       "      <td>0.188281</td>\n",
       "      <td>0.116786</td>\n",
       "      <td>0.085835</td>\n",
       "      <td>0.116474</td>\n",
       "      <td>0.109730</td>\n",
       "      <td>0.142409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>0.121955</td>\n",
       "      <td>0.138370</td>\n",
       "      <td>0.143971</td>\n",
       "      <td>0.124927</td>\n",
       "      <td>0.121022</td>\n",
       "      <td>0.136234</td>\n",
       "      <td>0.118408</td>\n",
       "      <td>0.095111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>0.124824</td>\n",
       "      <td>0.139044</td>\n",
       "      <td>0.130428</td>\n",
       "      <td>0.122932</td>\n",
       "      <td>0.123088</td>\n",
       "      <td>0.120874</td>\n",
       "      <td>0.119115</td>\n",
       "      <td>0.119695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>0.115283</td>\n",
       "      <td>0.143093</td>\n",
       "      <td>0.133416</td>\n",
       "      <td>0.117486</td>\n",
       "      <td>0.108497</td>\n",
       "      <td>0.134517</td>\n",
       "      <td>0.119981</td>\n",
       "      <td>0.127727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>0.123758</td>\n",
       "      <td>0.130461</td>\n",
       "      <td>0.131758</td>\n",
       "      <td>0.126298</td>\n",
       "      <td>0.107859</td>\n",
       "      <td>0.127195</td>\n",
       "      <td>0.130747</td>\n",
       "      <td>0.121924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>0.136299</td>\n",
       "      <td>0.104186</td>\n",
       "      <td>0.188281</td>\n",
       "      <td>0.116786</td>\n",
       "      <td>0.085835</td>\n",
       "      <td>0.116474</td>\n",
       "      <td>0.109730</td>\n",
       "      <td>0.142409</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>75 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          喜び       悲しみ        期待        驚き        怒り        恐れ        嫌悪  \\\n",
       "0   0.123901  0.134909  0.133190  0.122655  0.115807  0.137655  0.111521   \n",
       "1   0.123715  0.134854  0.129580  0.131150  0.102251  0.128790  0.113987   \n",
       "2   0.119426  0.133836  0.130413  0.121691  0.106651  0.133787  0.117834   \n",
       "3   0.136457  0.128723  0.157675  0.122087  0.109651  0.124035  0.108002   \n",
       "4   0.136299  0.104186  0.188281  0.116786  0.085835  0.116474  0.109730   \n",
       "..       ...       ...       ...       ...       ...       ...       ...   \n",
       "70  0.121955  0.138370  0.143971  0.124927  0.121022  0.136234  0.118408   \n",
       "71  0.124824  0.139044  0.130428  0.122932  0.123088  0.120874  0.119115   \n",
       "72  0.115283  0.143093  0.133416  0.117486  0.108497  0.134517  0.119981   \n",
       "73  0.123758  0.130461  0.131758  0.126298  0.107859  0.127195  0.130747   \n",
       "74  0.136299  0.104186  0.188281  0.116786  0.085835  0.116474  0.109730   \n",
       "\n",
       "          信頼  \n",
       "0   0.120361  \n",
       "1   0.135671  \n",
       "2   0.136362  \n",
       "3   0.113371  \n",
       "4   0.142409  \n",
       "..       ...  \n",
       "70  0.095111  \n",
       "71  0.119695  \n",
       "72  0.127727  \n",
       "73  0.121924  \n",
       "74  0.142409  \n",
       "\n",
       "[75 rows x 8 columns]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataFrameの各行を更新して、最大値に1、それ以外に0を持つようにする\n",
    "def update_dataframe(df):\n",
    "    for index, row in df.iterrows():\n",
    "        max_value = row.max()\n",
    "        df.loc[index] = (row == max_value).astype(int)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_process_values = update_dataframe(predicted_df)\n",
    "true_process_values = update_dataframe(true_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 各DataFrameから最大の感情を抽出\n",
    "def get_max_emotions(df):\n",
    "    max_emotions = []\n",
    "    for index, row in df.iterrows():\n",
    "        max_emotions.append(row.index[row == 1].tolist())\n",
    "    return pd.DataFrame({'Emotions': max_emotions})\n",
    "\n",
    "predicted_emotions = get_max_emotions(predicted_df)\n",
    "true_emotions = get_max_emotions(true_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# true_emotionsのリストサイズが2以上の場合、以下の2つを実行\n",
    "# 1:predリストの感情がtrueリストにある場合は、predリストと一致する感情を除いてtrueリスト内の感情を削除 \n",
    "# 2:predリストの感情がtrueリストにない場合は、両リストの感情をすべて削除して空リストにする→混同行列・F1スコア計算には含まないエントリとして扱う\n",
    "def remove_extra_emotions(predicted_emotions, true_emotions):\n",
    "    for idx, (pred, true) in zip(predicted_emotions.index, zip(predicted_emotions['Emotions'], true_emotions['Emotions'])):\n",
    "        if len(true) >= 2:\n",
    "            true_emotions.at[idx, 'Emotions'] = [emotion for emotion in true if emotion in pred] if any(emotion in pred for emotion in true) else []\n",
    "\n",
    "remove_extra_emotions(predicted_emotions, true_emotions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 混同行列の作成\n",
    "confusion_matrix_data = pd.DataFrame(0, index=emotion_labels, columns=emotion_labels)\n",
    "for pred, true in zip(predicted_emotions['Emotions'], true_emotions['Emotions']):\n",
    "    for pred_label in pred:\n",
    "        if pred_label in emotion_labels:\n",
    "            for true_label in true:\n",
    "                if true_label in emotion_labels:\n",
    "                    confusion_matrix_data.at[true_label, pred_label] += 1\n",
    "\n",
    "# 各列と各行に合計値を追加\n",
    "confusion_matrix_data['合計'] = confusion_matrix_data.sum(axis=1)\n",
    "confusion_matrix_data.loc['合計'] = confusion_matrix_data.sum()\n",
    "\n",
    "# 混同行列に明記\n",
    "confusion_matrix_data.index.name = '予測値'\n",
    "confusion_matrix_data.columns.name = '正解値'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>正解値</th>\n",
       "      <th>悲しみ</th>\n",
       "      <th>驚き</th>\n",
       "      <th>喜び</th>\n",
       "      <th>期待</th>\n",
       "      <th>期待</th>\n",
       "      <th>悲しみ</th>\n",
       "      <th>恐れ</th>\n",
       "      <th>信頼</th>\n",
       "      <th>期待</th>\n",
       "      <th>期待</th>\n",
       "      <th>...</th>\n",
       "      <th>悲しみ</th>\n",
       "      <th>恐れ</th>\n",
       "      <th>喜び</th>\n",
       "      <th>恐れ</th>\n",
       "      <th>恐れ</th>\n",
       "      <th>喜び</th>\n",
       "      <th>喜び</th>\n",
       "      <th>期待</th>\n",
       "      <th>喜び</th>\n",
       "      <th>合計</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>予測値</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>悲しみ</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>17959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>驚き</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>26941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>喜び</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>30556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>期待</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>43430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>期待</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>43430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>喜び</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>30556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>喜び</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>30556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>期待</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>43430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>喜び</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>30556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>合計</th>\n",
       "      <td>41462</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>92653</td>\n",
       "      <td>92653</td>\n",
       "      <td>41462</td>\n",
       "      <td>10966</td>\n",
       "      <td>225</td>\n",
       "      <td>92653</td>\n",
       "      <td>92653</td>\n",
       "      <td>...</td>\n",
       "      <td>41462</td>\n",
       "      <td>10966</td>\n",
       "      <td>0</td>\n",
       "      <td>10966</td>\n",
       "      <td>10966</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>92653</td>\n",
       "      <td>0</td>\n",
       "      <td>513219440</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16207 rows × 16207 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "正解値    悲しみ  驚き  喜び     期待     期待    悲しみ     恐れ   信頼     期待     期待  ...    悲しみ  \\\n",
       "予測値                                                                ...          \n",
       "悲しみ      2   0   0      3      3      2      0    0      3      3  ...      2   \n",
       "驚き       4   0   0      3      3      4      2    0      3      3  ...      4   \n",
       "喜び       3   0   0      5      5      3      1    0      5      5  ...      3   \n",
       "期待       1   0   0     10     10      1      0    0     10     10  ...      1   \n",
       "期待       1   0   0     10     10      1      0    0     10     10  ...      1   \n",
       "..     ...  ..  ..    ...    ...    ...    ...  ...    ...    ...  ...    ...   \n",
       "喜び       3   0   0      5      5      3      1    0      5      5  ...      3   \n",
       "喜び       3   0   0      5      5      3      1    0      5      5  ...      3   \n",
       "期待       1   0   0     10     10      1      0    0     10     10  ...      1   \n",
       "喜び       3   0   0      5      5      3      1    0      5      5  ...      3   \n",
       "合計   41462   0   0  92653  92653  41462  10966  225  92653  92653  ...  41462   \n",
       "\n",
       "正解値     恐れ  喜び     恐れ     恐れ  喜び  喜び     期待  喜び         合計  \n",
       "予測値                                                         \n",
       "悲しみ      0   0      0      0   0   0      3   0      17959  \n",
       "驚き       2   0      2      2   0   0      3   0      26941  \n",
       "喜び       1   0      1      1   0   0      5   0      30556  \n",
       "期待       0   0      0      0   0   0     10   0      43430  \n",
       "期待       0   0      0      0   0   0     10   0      43430  \n",
       "..     ...  ..    ...    ...  ..  ..    ...  ..        ...  \n",
       "喜び       1   0      1      1   0   0      5   0      30556  \n",
       "喜び       1   0      1      1   0   0      5   0      30556  \n",
       "期待       0   0      0      0   0   0     10   0      43430  \n",
       "喜び       1   0      1      1   0   0      5   0      30556  \n",
       "合計   10966   0  10966  10966   0   0  92653   0  513219440  \n",
       "\n",
       "[16207 rows x 16207 columns]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The truth value of a DataFrame is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2222/2831165927.py\u001b[0m in \u001b[0;36m?\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0memotion_label\u001b[0m \u001b[0;32min\u001b[0m \u001b[0memotion_names_jp\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mtp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfusion_matrix_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0memotion_label\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0memotion_label\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfusion_matrix_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0memotion_label\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'合計'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mfn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfusion_matrix_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'合計'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0memotion_label\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mprecision\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtp\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtp\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtp\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mrecall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtp\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtp\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtp\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mf1_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mprecision\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mrecall\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mprecision\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mrecall\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mprecision\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mrecall\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mf1_scores\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0memotion_label\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'Precision'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mprecision\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Recall'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mrecall\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'F1 Score'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf1_score\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1574\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mfinal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1575\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__nonzero__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mNoReturn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1576\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m   1577\u001b[0m             \u001b[0;34mf\"The truth value of a {type(self).__name__} is ambiguous. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1578\u001b[0m             \u001b[0;34m\"Use a.empty, a.bool(), a.item(), a.any() or a.all().\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1579\u001b[0m         )\n",
      "\u001b[0;31mValueError\u001b[0m: The truth value of a DataFrame is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all()."
     ]
    }
   ],
   "source": [
    "# 各感情ラベルのPrecision、Recall、F1スコアを計算\n",
    "f1_scores = {}\n",
    "for emotion_label in emotion_names_jp:\n",
    "    tp = confusion_matrix_data.at[emotion_label, emotion_label]\n",
    "    fp = confusion_matrix_data.loc[emotion_label, '合計'] - tp\n",
    "    fn = confusion_matrix_data.loc['合計', emotion_label] - tp\n",
    "    precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "    recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "    f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "    f1_scores[emotion_label] = {'Precision': precision, 'Recall': recall, 'F1 Score': f1_score}\n",
    "\n",
    "# 結果を表示\n",
    "f1_scores_df = pd.DataFrame.from_dict(f1_scores, orient='index')\n",
    "print(\"各感情ラベルのPrecision、Recall、F1スコア:\")\n",
    "print(f1_scores_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
